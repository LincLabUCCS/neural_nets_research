{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from translating_trees import *\n",
    "from for_prog_dataset import ForDataset\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi2277/Documents/HarveyMuddWork/Neural_Nets_Research/neural_nets_research\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets_library import training\n",
    "from ANC import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     4,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class TreeCell(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Cell which takes in arbitrary numbers of hidden and cell states (one per child).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_children):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM cell.\n",
    "        \n",
    "        :param input_size: length of input vector\n",
    "        :param hidden_size: length of hidden vector (and cell state)\n",
    "        :param num_children: number of children = number of hidden/cell states passed in\n",
    "        \"\"\"\n",
    "        super(TreeCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Gates = input, output, memory + one forget gate per child\n",
    "        numGates = 3 + num_children\n",
    "        \n",
    "        self.gates_value = torch.nn.ModuleList()\n",
    "        self.gates_children = torch.nn.ModuleList()\n",
    "        for _ in range(numGates):\n",
    "            # One linear layer to handle the value of the node\n",
    "            value_linear = nn.Linear(input_size, hidden_size, bias = True)\n",
    "            children_linear = torch.nn.ModuleList()\n",
    "            # One per child of the node\n",
    "            for _ in range(num_children):\n",
    "                children_linear.append(nn.Linear(hidden_size, hidden_size, bias = False))\n",
    "            self.gates_value.append(value_linear)\n",
    "            self.gates_children.append(children_linear)\n",
    "            \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of num_children hidden states.\n",
    "        :param cell_states: A list of num_children cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_sums = []\n",
    "\n",
    "        for i in range(len(self.gates_value)):\n",
    "            data_sum = self.gates_value[i](input)\n",
    "            for j in range(len(hidden_states)):\n",
    "                data_sum += self.gates_children[i][j](hidden_states[j])\n",
    "            data_sums.append(data_sum)\n",
    "        \n",
    "        # First gate is the input gate\n",
    "        i = self.sigmoid(data_sums[0])\n",
    "        # Next output gate\n",
    "        o = self.sigmoid(data_sums[1])\n",
    "        # Next memory gate\n",
    "        m = self.tanh(data_sums[2])\n",
    "        # All the rest are forget gates\n",
    "        forget_data = 0\n",
    "        for i in range(len(cell_states)):\n",
    "            forget_data += self.sigmoid(data_sums[3 + i]) * cell_states[i]\n",
    "\n",
    "        # Put it all together!\n",
    "        new_state = i * m + forget_data\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "        \n",
    "                \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     9,
     21
    ]
   },
   "outputs": [],
   "source": [
    "class TreeLSTM(nn.Module):\n",
    "    '''\n",
    "    TreeLSTM\n",
    "\n",
    "    Takes in a tree where each node has a value and a list of children.\n",
    "    Produces a tree of the same size where the value of each node is now encoded.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, valid_num_children):\n",
    "        \"\"\"\n",
    "        Initialize tree cells we'll need later.\n",
    "        \"\"\"\n",
    "        super(TreeLSTM, self).__init__()\n",
    "        \n",
    "        self.valid_num_children = [0] + valid_num_children\n",
    "        self.lstm_list = torch.nn.ModuleList()\n",
    "        \n",
    "        for size in self.valid_num_children:\n",
    "            self.lstm_list.append(TreeCell(input_size, hidden_size, size))\n",
    "        \n",
    "    def forward(self, node):\n",
    "        \"\"\"\n",
    "        Creates a tree where each node's value is the encoded version of the original value.\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return a tuple - (root of encoded tree, cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        # List of tuples: (node, cell state)\n",
    "        children = []\n",
    "        \n",
    "        # Recursively encode children\n",
    "        for child in node.children:\n",
    "            encoded_child = self.forward(child)\n",
    "            children.append(encoded_child)\n",
    "\n",
    "        # Extract the TreeCell inputs\n",
    "        inputH = [vec[0].value for vec in children]\n",
    "        inputC = [vec[1] for vec in children]\n",
    "\n",
    "        value = node.value\n",
    "\n",
    "        found = False\n",
    "        \n",
    "        # Feed the inputs into the TreeCell with the appropriate number of children.        \n",
    "        for i in range(len(self.valid_num_children)):\n",
    "            if self.valid_num_children[i] == len(children):\n",
    "                newH, newC = self.lstm_list[i](value, inputH, inputC)\n",
    "                found = True\n",
    "                break\n",
    "                \n",
    "        if not found:\n",
    "            print(\"WHAAAAAT?\")\n",
    "            raise ValueError(\"Beware.  Something has gone horribly wrong.  You may not have long to live.\")\n",
    "        \n",
    "        # Set our encoded vector as the root of the new tree\n",
    "        rootNode = Node(newH)\n",
    "        rootNode.children = [vec[0] for vec in children]\n",
    "        return (rootNode, newC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SeqEncoder(nn.Module):\n",
    "    # If you are using an end of sequence token that should be accounted for in input_size.\n",
    "    def __init__(self, input_size, hidden_size, num_layers, attention=True, \n",
    "                 use_embedding=True, embedding_size=256):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "        \n",
    "        self.use_embedding = use_embedding\n",
    "        \n",
    "        if use_embedding:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "            self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "        self.attention = attention\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.use_embedding:\n",
    "            input = self.embedding(input)\n",
    "        outputs, (hiddens, cell_states) = self.lstm(input.unsqueeze(1))\n",
    "        outputs, hiddens, cell_states = outputs.squeeze(1), hiddens.squeeze(1), cell_states.squeeze(1)\n",
    "        \n",
    "        if self.attention:\n",
    "            return outputs, hiddens, cell_states\n",
    "        else:\n",
    "            return hiddens, cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     5,
     24
    ]
   },
   "outputs": [],
   "source": [
    "class TreeEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in a tree where each node has a value vector and a list of children\n",
    "    Produces a sequence encoding of the tree\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, valid_num_children, \n",
    "                 attention=True, use_embedding=True, embedding_size=256):\n",
    "        super(TreeEncoder, self).__init__()\n",
    "        \n",
    "        self.lstm_list = torch.nn.ModuleList()\n",
    "        self.use_embedding = use_embedding\n",
    "        \n",
    "        if use_embedding:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "            self.lstm_list.append(TreeLSTM(embedding_size, hidden_size, valid_num_children))\n",
    "        else:\n",
    "            self.lstm_list.append(TreeLSTM(input_size, hidden_size, valid_num_children))\n",
    "        \n",
    "        # All TreeLSTMs have input of hidden_size except the first.\n",
    "        for i in range(num_layers-1):\n",
    "            self.lstm_list.append(TreeLSTM(hidden_size, hidden_size, valid_num_children))\n",
    "        \n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, tree):\n",
    "        \"\"\"\n",
    "        Encodes nodes of a tree in the rows of a matrix.\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return a matrix where each row represents the encoded output of a single node and also\n",
    "                the hidden/cell states of the root node.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.use_embedding:\n",
    "            tree = map_tree(lambda node: self.embedding(node).squeeze(0), tree)\n",
    "        \n",
    "        hiddens = []\n",
    "        cell_states = []\n",
    "        \n",
    "        for lstm in self.lstm_list:\n",
    "            tree, cell_state = lstm(tree)\n",
    "            hiddens.append(tree.value)\n",
    "            cell_states.append(cell_state)\n",
    "        \n",
    "        \n",
    "        hiddens = torch.stack(hiddens)\n",
    "        cell_states = torch.stack(cell_states)\n",
    "        \n",
    "        if self.attention:\n",
    "            return torch.stack(tree_to_list(tree)), hiddens, cell_states\n",
    "        else:\n",
    "            return hiddens, cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     30,
     31,
     66,
     70,
     73,
     99
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "'''\n",
    "class Tree_to_Sequence_Model(nn.Module):\n",
    "    \"\"\"\n",
    "      For the decoder this expects something like an lstm cell or a gru cell and not an lstm/gru.\n",
    "      Batch size is not supported at all. More precisely the encoder expects an input that does not\n",
    "      appear in batches and most also output non-batched tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size):\n",
    "        super(Tree_to_Sequence_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # nclass + 2 to include end of sequence and trash\n",
    "        self.output_log_odds = nn.Linear(hidden_size, nclass+2)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=0)\n",
    "\n",
    "        self.register_buffer('SOS_token', torch.LongTensor([[nclass+2]]))\n",
    "        self.EOS_value = nclass + 1\n",
    "\n",
    "        # nclass + 3 to include start of sequence, end of sequence, and trash.\n",
    "        # n + 2 - start of sequence, end of sequence - n + 1, trash - n.\n",
    "        # The first n correspond to the alphabet in order.\n",
    "        self.embedding = nn.Embedding(nclass+3, embedding_size)\n",
    "\n",
    "        # nclass is the trash category to avoid penalties after target's EOS token\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=nclass)\n",
    "\n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the input should be a pair. The first part\n",
    "               should correspond to the hidden state of the root. The second part\n",
    "               should correspond to the cell state of the root. They both should be\n",
    "               [num_layers, hidden_size].\n",
    "        target: The target should have dimension, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, teacher_forcing=True):\n",
    "        # root hidden state/cell state\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input) # num_layers x hidden_size\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "                                                            \n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "\n",
    "        target_length, = target.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(target_length):\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states)) # num_layers x 1 x hidden_size\n",
    "            decoder_hidden = decoder_hiddens[-1] # 1 x hidden_size\n",
    "            log_odds = self.output_log_odds(decoder_hidden)\n",
    "\n",
    "            loss += self.loss_func(log_odds, target[i])\n",
    "\n",
    "            if teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(1)\n",
    "            else:\n",
    "                _, next_input = log_odds.topk(1)\n",
    "\n",
    "            decoder_input = self.embedding(next_input).squeeze(1) # 1 x embedding_size\n",
    "                \n",
    "        return loss\n",
    "\n",
    "    \"\"\"\n",
    "        This is just an alias for point_wise_prediction, so that training code that assumes the presence\n",
    "        of a forward_train and forward_prediction works.\n",
    "    \"\"\"\n",
    "    def forward_prediction(self, input, maximum_length=20):\n",
    "        return self.point_wise_prediction(input, maximum_length)\n",
    "    \n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "        \n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        output_so_far = []\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            log_odds = self.output_log_odds(decoder_hidden)\n",
    "\n",
    "            _, next_input = log_odds.topk(1)\n",
    "            output_so_far.append(int(next_input))\n",
    "            \n",
    "            if int(next_input) == self.EOS_value:\n",
    "                break\n",
    "                \n",
    "            decoder_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "        \n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        word_inputs = []\n",
    "\n",
    "        for _ in range(beam_width):\n",
    "            word_inputs.append((0, [], True, [decoder_input, decoder_hiddens, decoder_cell_states]))\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            new_word_inputs = []\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                if not word_inputs[i][2]:\n",
    "                    new_word_inputs.append(word_inputs[i])\n",
    "                    continue\n",
    "\n",
    "                decoder_input, decoder_hiddens, decoder_cell_states = word_inputs[i][3]\n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "                decoder_hidden = decoder_hiddens[-1]\n",
    "                log_odds = self.output_log_odds(decoder_hidden).squeeze(0) # nclasses\n",
    "                log_probs = self.log_softmax(log_odds)\n",
    "\n",
    "                log_value, next_input = log_probs.topk(beam_width) # beam_width, beam_width\n",
    "                decoder_input = self.embedding(next_input.unsqueeze(1)) # beam_width x 1 x embedding size\n",
    "\n",
    "                new_word_inputs.extend((word_inputs[i][0] + float(log_value[k]), word_inputs[i][1] + [int(next_input[k])],\n",
    "                                        int(next_input[k]) != self.EOS_value, [decoder_input[k], decoder_hiddens, decoder_cell_states])\n",
    "                                        for k in range(beam_width))\n",
    "                    \n",
    "            word_inputs = sorted(new_word_inputs, key=lambda word_input: word_input[0])[-beam_width:]\n",
    "        return word_inputs[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     19,
     70,
     73,
     113,
     164
    ]
   },
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_Model(Tree_to_Sequence_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 alignment_size=50, align_type=1):\n",
    "        super(Tree_to_Sequence_Attention_Model, self).__init__(encoder, decoder, hidden_size, nclass, embedding_size)\n",
    "        \n",
    "        self.attention_presoftmax = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        if align_type == 0:\n",
    "            self.attention_hidden = nn.Linear(hidden_size, alignment_size)\n",
    "            self.attention_context = nn.Linear(hidden_size, alignment_size, bias=False)\n",
    "            self.attention_alignment_vector = nn.Linear(alignment_size, 1)\n",
    "        elif align_type == 1:\n",
    "            self.attention_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "            \n",
    "        self.align_type = align_type\n",
    "        self.register_buffer('et', torch.zeros(1, hidden_size))\n",
    "        \n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the tree should have be a triple. The first \n",
    "               part of the triple should be the annotations and have dimensions, \n",
    "               number_of_nodes x hidden_size. The second triple of the pair should be the hidden \n",
    "               representations of the root and should have dimensions, num_layers x hidden_size.\n",
    "               The third part should correspond to the cell states of the root and should\n",
    "               have dimensions, num_layers x hidden_size.\n",
    "        target: The target should have dimensions, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, teacher_forcing=True):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "\n",
    "        target_length, = target.size()\n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "\n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(target_length):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x embedding_size + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            log_odds = self.output_log_odds(et)\n",
    "            loss += self.loss_func(log_odds, target[i])\n",
    "\n",
    "            if teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(1)\n",
    "            else:\n",
    "                _, next_input = log_odds.topk(1)\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "        return loss        \n",
    "\n",
    "    \"\"\"\n",
    "        This is just an alias for point_wise_prediction, so that training code that assumes the presence\n",
    "        of a forward_train and forward_prediction works.\n",
    "    \"\"\"\n",
    "    def forward_prediction(self, input, maximum_length=150):\n",
    "        return self.point_wise_prediction(input, maximum_length)\n",
    "    \n",
    "    def point_wise_prediction(self, input, maximum_length=150):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        \n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        \n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        \n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        output_so_far = []\n",
    "        \n",
    "        for i in range(maximum_length):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x embedding_size + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            log_odds = self.output_log_odds(et)\n",
    "            _, next_input = log_odds.topk(1)\n",
    "\n",
    "            output_so_far.append(int(next_input))\n",
    "            \n",
    "            if int(next_input) == self.EOS_value:\n",
    "                break\n",
    "                \n",
    "            word_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        \n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        \n",
    "        decoder_input = torch.cat((word_input, et), dim=1)\n",
    "        word_inputs = []\n",
    "\n",
    "        for _ in range(beam_width):\n",
    "            word_inputs.append((0, [], True, [decoder_input, decoder_hiddens, decoder_cell_states]))\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            new_word_inputs = []\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                if not word_inputs[i][2]:\n",
    "                    new_word_inputs.append(word_inputs[i])\n",
    "                    continue\n",
    "\n",
    "                decoder_input, decoder_hiddens, decoder_cell_states = word_inputs[i][3]\n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "                decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "                attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "                attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "                context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "                et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1))) # 1 x hidden_size\n",
    "                log_odds = self.output_log_odds(et).squeeze(0) # nclasses\n",
    "                log_probs = self.log_softmax(log_odds)\n",
    "\n",
    "                log_value, next_input = log_probs.topk(beam_width) # beam_width, beam_width\n",
    "                word_input = self.embedding(next_input.unsqueeze(1)) # beam_width x 1 x embedding size\n",
    "                decoder_input = torch.cat((word_input, et.unsqueeze(0).repeat(beam_width, 1, 1)), dim=2)\n",
    "\n",
    "                new_word_inputs.extend((word_inputs[i][0] + float(log_value[k]), word_inputs[i][1] + [int(next_input[k])],\n",
    "                                        int(next_input[k]) != self.EOS_value, [word_input[k], decoder_hiddens, decoder_cell_states])\n",
    "                                        for k in range(beam_width))\n",
    "            word_inputs = sorted(new_word_inputs, key=lambda word_input: word_input[0])[-beam_width:]\n",
    "        return word_inputs[-1][1]\n",
    "    \n",
    "    def attention_logits(self, attention_hidden_values, decoder_hidden):\n",
    "        if self.align_type == 0:\n",
    "            return self.attention_alignment_vector(self.tanh(self.attention_context(decoder_hidden) + attention_hidden_values))\n",
    "        else:\n",
    "            return (decoder_hidden * attention_hidden_values).sum(1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_ANC_Model(Tree_to_Sequence_Attention_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size, M, R,\n",
    "                 alignment_size=50, align_type=1, N=11):\n",
    "        super(Tree_to_Sequence_Attention_ANC_Model, self).__init__(encoder, decoder, hidden_size, nclass, embedding_size\n",
    "                                                                   alignment_size=alignment_size, align_type=align_type)\n",
    "        # the initial registers all have value 0 with probability 1\n",
    "        prob_dist = torch.zeroes(R, M)\n",
    "        prob_dist[:, 0] = 1\n",
    "        \n",
    "        self.register_buffer('initial_registers', prob_dist)\n",
    "        \n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        self.N = N\n",
    "        \n",
    "        self.initial_word_input = nn.Parameter(1, N + 3*R)\n",
    "        self.output_log_odds = nn.Linear(hidden_size, N + 3*R)\n",
    "        \n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the tree should have be a triple. The first \n",
    "               part of the triple should be the annotations and have dimensions, \n",
    "               number_of_nodes x hidden_size. The second triple of the pair should be the hidden \n",
    "               representations of the root and should have dimensions, num_layers x hidden_size.\n",
    "               The third part should correspond to the cell states of the root and should\n",
    "               have dimensions, num_layers x hidden_size.\n",
    "        target: The target should be a list of triples, where the first element of any triple is\n",
    "                the input matrix, the second element is the output matrix corresponding to the expected\n",
    "                output based on the input and the third element is a mask that specifies the area\n",
    "                of memory where the output is.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "\n",
    "        num_layers, _, _ = decoder_hiddens.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "\n",
    "        word_input = initial_word_input # 1 x N + 3*R\n",
    "        et = Variable(self.et)\n",
    "        \n",
    "        output_words = []\n",
    "\n",
    "        for i in range(self.M):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x N + 3*R + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            word_input = self.output_log_odds(et)\n",
    "            \n",
    "            output_words.append(word_input)\n",
    "            \n",
    "        controller_params = torch.stack(output_words, dim=2).squeeze(0) # N + 3*R x M\n",
    "        instruction = controller_params[0:N]\n",
    "        first_arg = controller_params[N:N+R]\n",
    "        second_arg = controller_params[N+R:N+2*R]\n",
    "        output_arg = controller_params[N+2*R:-1]\n",
    "        \n",
    "        Controller\n",
    "            \n",
    "        return loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MultilayerLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, bias=True):\n",
    "        super(MultilayerLSTMCell, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        \n",
    "        if isinstance(hidden_sizes, int):\n",
    "            temp = []\n",
    "            \n",
    "            for _ in range(num_layers):\n",
    "                temp.append(hidden_sizes)\n",
    "            \n",
    "            hidden_sizes = temp\n",
    "            \n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            curr_lstm = nn.LSTMCell(hidden_sizes[i], hidden_sizes[i+1], bias=bias)\n",
    "            self.lstm_layers.append(curr_lstm)\n",
    "    \n",
    "    def forward(self, input, past_states):\n",
    "        hiddens, cell_states = past_states\n",
    "        result_hiddens, result_cell_states = [], []\n",
    "        curr_input = input\n",
    "        \n",
    "        for lstm_cell, curr_hidden, curr_cell_state in zip(self.lstm_layers, hiddens, cell_states):\n",
    "            curr_input, new_cell_state = lstm_cell(curr_input, (curr_hidden, curr_cell_state))\n",
    "            result_hiddens.append(curr_input)\n",
    "            result_cell_states.append(new_cell_state)\n",
    "        \n",
    "        return torch.stack(result_hiddens), torch.stack(result_cell_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     3,
     19
    ]
   },
   "outputs": [],
   "source": [
    "num_vars = 10\n",
    "num_ints = 11\n",
    "\n",
    "for_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"Assign\": 7,\n",
    "    \"If\": 8,\n",
    "    \"Seq\": 9,\n",
    "    \"For\": 10\n",
    "}\n",
    "\n",
    "for_ops = {\"<\" + k.upper() + \">\": v for k,v in for_ops.items()}\n",
    "\n",
    "lambda_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"If\": 7,\n",
    "    \"Let\": 8,\n",
    "    \"Unit\": 9,\n",
    "    \"Letrec\": 10,\n",
    "    \"App\": 11\n",
    "}\n",
    "\n",
    "lambda_ops = {\"<\" + k.upper() + \">\": v for k,v in lambda_ops.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "input_eos_token = False\n",
    "input_as_seq = False\n",
    "use_embedding = True\n",
    "eos_bonus = 1 if input_eos_token and input_as_seq else 0\n",
    "long_base_case = True\n",
    "binarize = True\n",
    "\n",
    "for_lambda_dset = ForDataset('ANC/Hard-arbitraryForList.json', binarize=binarize, \n",
    "                             input_eos_token=input_eos_token, input_as_seq=input_as_seq, \n",
    "                             use_embedding=use_embedding, long_base_case=long_base_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_all_parameters_uniform(model, stdev):\n",
    "    for param in model.parameters():\n",
    "        nn.init.uniform(param, -stdev, stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 256\n",
    "nclass = num_vars + num_ints + len(lambda_ops.keys())\n",
    "num_layers = 1\n",
    "attention = True\n",
    "alignment_size = 50\n",
    "align_type = 1\n",
    "encoder_input_size = num_vars + num_ints + len(for_ops.keys()) + eos_bonus\n",
    "\n",
    "if input_as_seq:\n",
    "    encoder = SeqEncoder(encoder_input_size, hidden_size, num_layers, attention=attention, use_embedding=use_embedding)\n",
    "else:\n",
    "    encoder = TreeEncoder(encoder_input_size, hidden_size, num_layers, [1, 2], attention=attention, use_embedding=use_embedding)\n",
    "\n",
    "if attention:\n",
    "    decoder = MultilayerLSTMCell(embedding_size + hidden_size, hidden_size, num_layers)\n",
    "    program_model = Tree_to_Sequence_Attention_Model(encoder, decoder, hidden_size, nclass, embedding_size, alignment_size=alignment_size, align_type=align_type)\n",
    "else:\n",
    "    decoder = MultilayerLSTMCell(embedding_size, hidden_size, num_layers)\n",
    "    program_model = Tree_to_Sequence_Model(encoder, decoder, hidden_size, nclass, embedding_size)\n",
    "    \n",
    "reset_all_parameters_uniform(program_model, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_model = program_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_model.load_state_dict(torch.load('for_lambda_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_accuracy(prediction, target):\n",
    "    return 1 if list(target.data) == prediction else 0\n",
    "\n",
    "def token_accuracy(prediction, target):\n",
    "    pass\n",
    "\n",
    "optimizer = torch.optim.Adam(program_model.parameters(), lr=0.005)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=100, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Epoch Number: 0, Batch Number: 200, Validation Metric: 0.4650\n",
      "Epoch Number: 0, Batch Number: 200, Training Loss: 218.4726\n",
      "Time so far is 0m 15s\n",
      "Epoch Number: 0, Batch Number: 400, Validation Metric: 0.5550\n",
      "Epoch Number: 0, Batch Number: 400, Training Loss: 221.7012\n",
      "Time so far is 0m 28s\n",
      "Epoch Number: 0, Batch Number: 600, Validation Metric: 0.5500\n",
      "Epoch Number: 0, Batch Number: 600, Training Loss: 169.1935\n",
      "Time so far is 0m 41s\n",
      "Epoch Number: 0, Batch Number: 800, Validation Metric: 0.5000\n",
      "Epoch Number: 0, Batch Number: 800, Training Loss: 193.4087\n",
      "Time so far is 0m 55s\n",
      "Epoch Number: 0, Batch Number: 1000, Validation Metric: 0.5000\n",
      "Epoch Number: 0, Batch Number: 1000, Training Loss: 161.2553\n",
      "Time so far is 1m 9s\n",
      "Epoch Number: 0, Batch Number: 1200, Validation Metric: 0.5000\n",
      "Epoch Number: 0, Batch Number: 1200, Training Loss: 154.9450\n",
      "Time so far is 1m 22s\n",
      "Epoch Number: 0, Batch Number: 1400, Validation Metric: 0.5350\n",
      "Epoch Number: 0, Batch Number: 1400, Training Loss: 113.5496\n",
      "Time so far is 1m 34s\n",
      "Epoch Number: 0, Batch Number: 1600, Validation Metric: 0.3600\n",
      "Epoch Number: 0, Batch Number: 1600, Training Loss: 116.3659\n",
      "Time so far is 1m 47s\n",
      "Epoch Number: 0, Batch Number: 1800, Validation Metric: 0.1300\n",
      "Epoch Number: 0, Batch Number: 1800, Training Loss: 137.6365\n",
      "Time so far is 2m 0s\n",
      "Epoch Number: 0, Batch Number: 2000, Validation Metric: 0.1000\n",
      "Epoch Number: 0, Batch Number: 2000, Training Loss: 130.9293\n",
      "Time so far is 2m 15s\n",
      "Epoch Number: 0, Batch Number: 2200, Validation Metric: 0.0600\n",
      "Epoch Number: 0, Batch Number: 2200, Training Loss: 114.1471\n",
      "Time so far is 2m 29s\n",
      "Epoch Number: 0, Batch Number: 2400, Validation Metric: 0.0450\n",
      "Epoch Number: 0, Batch Number: 2400, Training Loss: 104.3343\n",
      "Time so far is 2m 45s\n",
      "Epoch Number: 0, Batch Number: 2600, Validation Metric: 0.0300\n",
      "Epoch Number: 0, Batch Number: 2600, Training Loss: 96.5739\n",
      "Time so far is 2m 59s\n",
      "Epoch Number: 0, Batch Number: 2800, Validation Metric: 0.0150\n",
      "Epoch Number: 0, Batch Number: 2800, Training Loss: 102.5381\n",
      "Time so far is 3m 15s\n",
      "Epoch Number: 0, Batch Number: 3000, Validation Metric: 0.0100\n",
      "Epoch Number: 0, Batch Number: 3000, Training Loss: 89.0377\n",
      "Time so far is 3m 31s\n",
      "Epoch Number: 0, Batch Number: 3200, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 3200, Training Loss: 100.5692\n",
      "Time so far is 3m 50s\n",
      "Epoch Number: 0, Batch Number: 3400, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 3400, Training Loss: 105.8515\n",
      "Time so far is 4m 9s\n",
      "Epoch Number: 0, Batch Number: 3600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 3600, Training Loss: 88.8436\n",
      "Time so far is 4m 27s\n",
      "Epoch Number: 0, Batch Number: 3800, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 3800, Training Loss: 95.4488\n",
      "Time so far is 4m 46s\n",
      "Epoch Number: 0, Batch Number: 4000, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 4000, Training Loss: 107.5929\n",
      "Time so far is 5m 5s\n",
      "Epoch Number: 0, Batch Number: 4200, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 4200, Training Loss: 86.6532\n",
      "Time so far is 5m 22s\n",
      "Epoch Number: 0, Batch Number: 4400, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 4400, Training Loss: 94.6884\n",
      "Time so far is 5m 40s\n",
      "Epoch Number: 0, Batch Number: 4600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 4600, Training Loss: 79.2206\n",
      "Time so far is 5m 55s\n",
      "Epoch Number: 0, Batch Number: 4800, Validation Metric: 0.0200\n",
      "Epoch Number: 0, Batch Number: 4800, Training Loss: 72.8958\n",
      "Time so far is 6m 11s\n",
      "Epoch Number: 0, Batch Number: 5000, Validation Metric: 0.0300\n",
      "Epoch Number: 0, Batch Number: 5000, Training Loss: 82.6892\n",
      "Time so far is 6m 27s\n",
      "Epoch Number: 0, Batch Number: 5200, Validation Metric: 0.0250\n",
      "Epoch Number: 0, Batch Number: 5200, Training Loss: 78.7821\n",
      "Time so far is 6m 42s\n",
      "Epoch Number: 0, Batch Number: 5400, Validation Metric: 0.0150\n",
      "Epoch Number: 0, Batch Number: 5400, Training Loss: 71.7989\n",
      "Time so far is 6m 58s\n",
      "Epoch Number: 0, Batch Number: 5600, Validation Metric: 0.0250\n",
      "Epoch Number: 0, Batch Number: 5600, Training Loss: 76.4574\n",
      "Time so far is 7m 14s\n",
      "Epoch Number: 0, Batch Number: 5800, Validation Metric: 0.0350\n",
      "Epoch Number: 0, Batch Number: 5800, Training Loss: 80.9418\n",
      "Time so far is 7m 31s\n",
      "Epoch Number: 0, Batch Number: 6000, Validation Metric: 0.0200\n",
      "Epoch Number: 0, Batch Number: 6000, Training Loss: 84.0693\n",
      "Time so far is 7m 49s\n",
      "Epoch Number: 0, Batch Number: 6200, Validation Metric: 0.0650\n",
      "Epoch Number: 0, Batch Number: 6200, Training Loss: 73.2383\n",
      "Time so far is 8m 9s\n",
      "Epoch Number: 0, Batch Number: 6400, Validation Metric: 0.0250\n",
      "Epoch Number: 0, Batch Number: 6400, Training Loss: 79.8270\n",
      "Time so far is 8m 27s\n",
      "Epoch Number: 0, Batch Number: 6600, Validation Metric: 0.0600\n",
      "Epoch Number: 0, Batch Number: 6600, Training Loss: 70.4635\n",
      "Time so far is 8m 44s\n",
      "Epoch Number: 0, Batch Number: 6800, Validation Metric: 0.0100\n",
      "Epoch Number: 0, Batch Number: 6800, Training Loss: 70.7728\n",
      "Time so far is 9m 2s\n",
      "Epoch Number: 0, Batch Number: 7000, Validation Metric: 0.1050\n",
      "Epoch Number: 0, Batch Number: 7000, Training Loss: 64.3330\n",
      "Time so far is 9m 19s\n",
      "Epoch Number: 0, Batch Number: 7200, Validation Metric: 0.0800\n",
      "Epoch Number: 0, Batch Number: 7200, Training Loss: 56.2149\n",
      "Time so far is 9m 34s\n",
      "Epoch Number: 0, Batch Number: 7400, Validation Metric: 0.0800\n",
      "Epoch Number: 0, Batch Number: 7400, Training Loss: 69.8716\n",
      "Time so far is 9m 50s\n",
      "Epoch Number: 0, Batch Number: 7600, Validation Metric: 0.0600\n",
      "Epoch Number: 0, Batch Number: 7600, Training Loss: 60.0865\n",
      "Time so far is 10m 4s\n",
      "Epoch Number: 0, Batch Number: 7800, Validation Metric: 0.0500\n",
      "Epoch Number: 0, Batch Number: 7800, Training Loss: 69.8171\n",
      "Time so far is 10m 20s\n",
      "Epoch Number: 0, Batch Number: 8000, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 8000, Training Loss: 54.6515\n",
      "Time so far is 10m 34s\n",
      "Epoch Number: 0, Batch Number: 8200, Validation Metric: 0.0900\n",
      "Epoch Number: 0, Batch Number: 8200, Training Loss: 55.4603\n",
      "Time so far is 10m 53s\n",
      "Epoch Number: 0, Batch Number: 8400, Validation Metric: 0.0900\n",
      "Epoch Number: 0, Batch Number: 8400, Training Loss: 54.0514\n",
      "Time so far is 11m 9s\n",
      "Epoch Number: 0, Batch Number: 8600, Validation Metric: 0.0650\n",
      "Epoch Number: 0, Batch Number: 8600, Training Loss: 51.3093\n",
      "Time so far is 11m 25s\n",
      "Epoch Number: 0, Batch Number: 8800, Validation Metric: 0.0950\n",
      "Epoch Number: 0, Batch Number: 8800, Training Loss: 45.6219\n",
      "Time so far is 11m 41s\n",
      "Epoch Number: 0, Batch Number: 9000, Validation Metric: 0.0950\n",
      "Epoch Number: 0, Batch Number: 9000, Training Loss: 49.9443\n",
      "Time so far is 11m 57s\n",
      "Epoch Number: 0, Batch Number: 9200, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 9200, Training Loss: 53.8228\n",
      "Time so far is 12m 15s\n",
      "Epoch Number: 0, Batch Number: 9400, Validation Metric: 0.1200\n",
      "Epoch Number: 0, Batch Number: 9400, Training Loss: 50.5615\n",
      "Time so far is 12m 33s\n",
      "Epoch Number: 0, Batch Number: 9600, Validation Metric: 0.1300\n",
      "Epoch Number: 0, Batch Number: 9600, Training Loss: 35.2412\n",
      "Time so far is 12m 47s\n",
      "Epoch Number: 0, Batch Number: 9800, Validation Metric: 0.0950\n",
      "Epoch Number: 0, Batch Number: 9800, Training Loss: 48.7401\n",
      "Time so far is 13m 4s\n",
      "Epoch Number: 0, Batch Number: 10000, Validation Metric: 0.0800\n",
      "Epoch Number: 0, Batch Number: 10000, Training Loss: 49.4963\n",
      "Time so far is 13m 21s\n",
      "Epoch Number: 0, Batch Number: 10200, Validation Metric: 0.0650\n",
      "Epoch Number: 0, Batch Number: 10200, Training Loss: 51.7469\n",
      "Time so far is 13m 42s\n",
      "Epoch Number: 0, Batch Number: 10400, Validation Metric: 0.1000\n",
      "Epoch Number: 0, Batch Number: 10400, Training Loss: 44.4296\n",
      "Time so far is 13m 59s\n",
      "Epoch Number: 0, Batch Number: 10600, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 10600, Training Loss: 54.8719\n",
      "Time so far is 14m 18s\n",
      "Epoch Number: 0, Batch Number: 10800, Validation Metric: 0.0800\n",
      "Epoch Number: 0, Batch Number: 10800, Training Loss: 46.3640\n",
      "Time so far is 14m 34s\n",
      "Epoch Number: 0, Batch Number: 11000, Validation Metric: 0.0750\n",
      "Epoch Number: 0, Batch Number: 11000, Training Loss: 47.8581\n",
      "Time so far is 14m 52s\n",
      "Epoch Number: 0, Batch Number: 11200, Validation Metric: 0.1000\n",
      "Epoch Number: 0, Batch Number: 11200, Training Loss: 47.3796\n",
      "Time so far is 15m 8s\n",
      "Epoch Number: 0, Batch Number: 11400, Validation Metric: 0.1000\n",
      "Epoch Number: 0, Batch Number: 11400, Training Loss: 45.6573\n",
      "Time so far is 15m 24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0, Batch Number: 11600, Validation Metric: 0.0900\n",
      "Epoch Number: 0, Batch Number: 11600, Training Loss: 41.3852\n",
      "Time so far is 15m 38s\n",
      "Epoch Number: 0, Batch Number: 11800, Validation Metric: 0.0350\n",
      "Epoch Number: 0, Batch Number: 11800, Training Loss: 49.4788\n",
      "Time so far is 15m 54s\n",
      "Epoch Number: 0, Batch Number: 12000, Validation Metric: 0.0150\n",
      "Epoch Number: 0, Batch Number: 12000, Training Loss: 50.2702\n",
      "Time so far is 16m 9s\n",
      "Epoch Number: 0, Batch Number: 12200, Validation Metric: 0.0350\n",
      "Epoch Number: 0, Batch Number: 12200, Training Loss: 46.4678\n",
      "Time so far is 16m 26s\n",
      "Epoch Number: 0, Batch Number: 12400, Validation Metric: 0.0650\n",
      "Epoch Number: 0, Batch Number: 12400, Training Loss: 51.7591\n",
      "Time so far is 16m 41s\n",
      "Epoch Number: 0, Batch Number: 12600, Validation Metric: 0.0950\n",
      "Epoch Number: 0, Batch Number: 12600, Training Loss: 47.3339\n",
      "Time so far is 16m 57s\n",
      "Epoch Number: 0, Batch Number: 12800, Validation Metric: 0.0750\n",
      "Epoch Number: 0, Batch Number: 12800, Training Loss: 46.1382\n",
      "Time so far is 17m 11s\n",
      "Epoch Number: 0, Batch Number: 13000, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 13000, Training Loss: 42.9591\n",
      "Time so far is 17m 26s\n",
      "Epoch Number: 0, Batch Number: 13200, Validation Metric: 0.1450\n",
      "Epoch Number: 0, Batch Number: 13200, Training Loss: 42.9811\n",
      "Time so far is 17m 40s\n",
      "Epoch Number: 0, Batch Number: 13400, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 13400, Training Loss: 44.7829\n",
      "Time so far is 17m 54s\n",
      "Epoch Number: 0, Batch Number: 13600, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 13600, Training Loss: 50.1421\n",
      "Time so far is 18m 10s\n",
      "Epoch Number: 0, Batch Number: 13800, Validation Metric: 0.0750\n",
      "Epoch Number: 0, Batch Number: 13800, Training Loss: 44.1034\n",
      "Time so far is 18m 26s\n",
      "Epoch Number: 0, Batch Number: 14000, Validation Metric: 0.0400\n",
      "Epoch Number: 0, Batch Number: 14000, Training Loss: 46.0762\n",
      "Time so far is 18m 42s\n",
      "Epoch Number: 0, Batch Number: 14200, Validation Metric: 0.0450\n",
      "Epoch Number: 0, Batch Number: 14200, Training Loss: 49.3765\n",
      "Time so far is 18m 59s\n",
      "Epoch Number: 0, Batch Number: 14400, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 14400, Training Loss: 44.7912\n",
      "Time so far is 19m 17s\n",
      "Epoch Number: 0, Batch Number: 14600, Validation Metric: 0.0150\n",
      "Epoch Number: 0, Batch Number: 14600, Training Loss: 48.2822\n",
      "Time so far is 19m 32s\n",
      "Epoch Number: 0, Batch Number: 14800, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 14800, Training Loss: 50.3966\n",
      "Time so far is 19m 48s\n",
      "Epoch Number: 0, Batch Number: 15000, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 15000, Training Loss: 47.8928\n",
      "Time so far is 20m 3s\n",
      "Epoch Number: 0, Batch Number: 15200, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 15200, Training Loss: 43.2096\n",
      "Time so far is 20m 17s\n",
      "Epoch Number: 0, Batch Number: 15400, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 15400, Training Loss: 47.3831\n",
      "Time so far is 20m 33s\n",
      "Epoch Number: 0, Batch Number: 15600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 15600, Training Loss: 50.6682\n",
      "Time so far is 20m 50s\n",
      "Epoch Number: 0, Batch Number: 15800, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 15800, Training Loss: 45.9578\n",
      "Time so far is 21m 5s\n",
      "Epoch Number: 0, Batch Number: 16000, Validation Metric: 0.0100\n",
      "Epoch Number: 0, Batch Number: 16000, Training Loss: 46.4498\n",
      "Time so far is 21m 21s\n",
      "Epoch Number: 0, Batch Number: 16200, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 16200, Training Loss: 50.2938\n",
      "Time so far is 21m 37s\n",
      "Epoch Number: 0, Batch Number: 16400, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 16400, Training Loss: 44.5672\n",
      "Time so far is 21m 55s\n",
      "Epoch Number: 0, Batch Number: 16600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 16600, Training Loss: 45.6425\n",
      "Time so far is 22m 11s\n",
      "Epoch Number: 0, Batch Number: 16800, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 16800, Training Loss: 48.4295\n",
      "Time so far is 22m 27s\n",
      "Epoch Number: 0, Batch Number: 17000, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 17000, Training Loss: 44.5911\n",
      "Time so far is 22m 42s\n",
      "Epoch Number: 0, Batch Number: 17200, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 17200, Training Loss: 44.3095\n",
      "Time so far is 22m 57s\n",
      "Epoch Number: 0, Batch Number: 17400, Validation Metric: 0.0050\n",
      "Epoch Number: 0, Batch Number: 17400, Training Loss: 44.2022\n",
      "Time so far is 23m 14s\n",
      "Epoch Number: 0, Batch Number: 17600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 17600, Training Loss: 44.7389\n",
      "Time so far is 23m 31s\n",
      "Epoch Number: 0, Batch Number: 17800, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 17800, Training Loss: 48.8613\n",
      "Time so far is 23m 50s\n",
      "Epoch Number: 0, Batch Number: 18000, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 18000, Training Loss: 46.0265\n",
      "Time so far is 24m 6s\n",
      "Epoch Number: 0, Batch Number: 18200, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 18200, Training Loss: 50.0599\n",
      "Time so far is 24m 22s\n",
      "Epoch Number: 0, Batch Number: 18400, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 18400, Training Loss: 47.4234\n",
      "Time so far is 24m 41s\n",
      "Epoch Number: 0, Batch Number: 18600, Validation Metric: 0.0000\n",
      "Epoch Number: 0, Batch Number: 18600, Training Loss: 47.7388\n",
      "Time so far is 24m 56s\n",
      "Epoch Number: 0, Batch Number: 18800, Validation Metric: 0.0400\n",
      "Epoch Number: 0, Batch Number: 18800, Training Loss: 57.8024\n",
      "Time so far is 25m 14s\n",
      "Epoch Number: 0, Batch Number: 19000, Validation Metric: 0.0700\n",
      "Epoch Number: 0, Batch Number: 19000, Training Loss: 50.0418\n",
      "Time so far is 25m 32s\n",
      "Epoch Number: 0, Batch Number: 19200, Validation Metric: 0.0300\n",
      "Epoch Number: 0, Batch Number: 19200, Training Loss: 50.1737\n",
      "Time so far is 25m 52s\n",
      "Epoch Number: 0, Batch Number: 19400, Validation Metric: 0.0750\n",
      "Epoch Number: 0, Batch Number: 19400, Training Loss: 37.7878\n",
      "Time so far is 26m 8s\n",
      "Epoch   195: reducing learning rate of group 0 to 3.2000e-03.\n",
      "Epoch Number: 0, Batch Number: 19600, Validation Metric: 0.0650\n",
      "Epoch Number: 0, Batch Number: 19600, Training Loss: 38.5009\n",
      "Time so far is 26m 25s\n",
      "Epoch Number: 0, Batch Number: 19800, Validation Metric: 0.0850\n",
      "Epoch Number: 0, Batch Number: 19800, Training Loss: 49.2502\n",
      "Time so far is 26m 41s\n",
      "Epoch Number: 0, Batch Number: 20000, Validation Metric: 0.1650\n",
      "Epoch Number: 0, Batch Number: 20000, Training Loss: 45.3956\n",
      "Time so far is 26m 57s\n",
      "Epoch Number: 0, Batch Number: 20200, Validation Metric: 0.0700\n",
      "Epoch Number: 0, Batch Number: 20200, Training Loss: 49.9390\n",
      "Time so far is 27m 14s\n",
      "Epoch Number: 0, Batch Number: 20400, Validation Metric: 0.0250\n",
      "Epoch Number: 0, Batch Number: 20400, Training Loss: 47.7703\n",
      "Time so far is 27m 33s\n",
      "Epoch Number: 0, Batch Number: 20600, Validation Metric: 0.0600\n",
      "Epoch Number: 0, Batch Number: 20600, Training Loss: 53.2006\n",
      "Time so far is 27m 50s\n",
      "Epoch Number: 0, Batch Number: 20800, Validation Metric: 0.0350\n",
      "Epoch Number: 0, Batch Number: 20800, Training Loss: 42.3253\n",
      "Time so far is 28m 5s\n",
      "Epoch Number: 0, Batch Number: 21000, Validation Metric: 0.0600\n",
      "Epoch Number: 0, Batch Number: 21000, Training Loss: 45.2815\n",
      "Time so far is 28m 21s\n",
      "Epoch Number: 0, Batch Number: 21200, Validation Metric: 0.0800\n",
      "Epoch Number: 0, Batch Number: 21200, Training Loss: 37.2481\n",
      "Time so far is 28m 35s\n",
      "Epoch Number: 0, Batch Number: 21400, Validation Metric: 0.0750\n",
      "Epoch Number: 0, Batch Number: 21400, Training Loss: 46.9813\n",
      "Time so far is 28m 52s\n",
      "Epoch Number: 0, Batch Number: 21600, Validation Metric: 0.1000\n",
      "Epoch Number: 0, Batch Number: 21600, Training Loss: 48.8975\n",
      "Time so far is 29m 9s\n",
      "Epoch Number: 0, Batch Number: 21800, Validation Metric: 0.1100\n",
      "Epoch Number: 0, Batch Number: 21800, Training Loss: 43.0710\n",
      "Time so far is 29m 26s\n",
      "Epoch Number: 0, Batch Number: 22000, Validation Metric: 0.1100\n",
      "Epoch Number: 0, Batch Number: 22000, Training Loss: 41.4341\n",
      "Time so far is 29m 42s\n",
      "Epoch Number: 0, Batch Number: 22200, Validation Metric: 0.1500\n",
      "Epoch Number: 0, Batch Number: 22200, Training Loss: 43.7429\n",
      "Time so far is 29m 58s\n",
      "Epoch Number: 0, Batch Number: 22400, Validation Metric: 0.1350\n",
      "Epoch Number: 0, Batch Number: 22400, Training Loss: 46.5238\n",
      "Time so far is 30m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0, Batch Number: 22600, Validation Metric: 0.1400\n",
      "Epoch Number: 0, Batch Number: 22600, Training Loss: 42.8876\n",
      "Time so far is 30m 35s\n",
      "Epoch Number: 0, Batch Number: 22800, Validation Metric: 0.1550\n",
      "Epoch Number: 0, Batch Number: 22800, Training Loss: 40.2877\n",
      "Time so far is 30m 52s\n",
      "Epoch Number: 0, Batch Number: 23000, Validation Metric: 0.1600\n",
      "Epoch Number: 0, Batch Number: 23000, Training Loss: 43.4876\n",
      "Time so far is 31m 9s\n",
      "Epoch Number: 0, Batch Number: 23200, Validation Metric: 0.1800\n",
      "Epoch Number: 0, Batch Number: 23200, Training Loss: 43.8584\n",
      "Time so far is 31m 26s\n",
      "Epoch Number: 0, Batch Number: 23400, Validation Metric: 0.1700\n",
      "Epoch Number: 0, Batch Number: 23400, Training Loss: 44.4051\n",
      "Time so far is 31m 43s\n",
      "Epoch Number: 0, Batch Number: 23600, Validation Metric: 0.2050\n",
      "Epoch Number: 0, Batch Number: 23600, Training Loss: 39.6261\n",
      "Time so far is 31m 60s\n",
      "Epoch Number: 0, Batch Number: 23800, Validation Metric: 0.1750\n",
      "Epoch Number: 0, Batch Number: 23800, Training Loss: 38.6328\n",
      "Time so far is 32m 16s\n",
      "Epoch Number: 0, Batch Number: 24000, Validation Metric: 0.1300\n",
      "Epoch Number: 0, Batch Number: 24000, Training Loss: 38.0527\n",
      "Time so far is 32m 33s\n",
      "Epoch Number: 0, Batch Number: 24200, Validation Metric: 0.1450\n",
      "Epoch Number: 0, Batch Number: 24200, Training Loss: 40.2576\n",
      "Time so far is 32m 52s\n",
      "Epoch Number: 0, Batch Number: 24400, Validation Metric: 0.0900\n",
      "Epoch Number: 0, Batch Number: 24400, Training Loss: 41.5633\n",
      "Time so far is 33m 10s\n",
      "Epoch Number: 0, Batch Number: 24600, Validation Metric: 0.1050\n",
      "Epoch Number: 0, Batch Number: 24600, Training Loss: 43.2331\n",
      "Time so far is 33m 27s\n",
      "Epoch Number: 0, Batch Number: 24800, Validation Metric: 0.1350\n",
      "Epoch Number: 0, Batch Number: 24800, Training Loss: 40.3045\n",
      "Time so far is 33m 44s\n",
      "Epoch Number: 0, Batch Number: 25000, Validation Metric: 0.1250\n",
      "Epoch Number: 0, Batch Number: 25000, Training Loss: 41.8191\n",
      "Time so far is 34m 1s\n",
      "Epoch Number: 0, Batch Number: 25200, Validation Metric: 0.1750\n",
      "Epoch Number: 0, Batch Number: 25200, Training Loss: 35.9305\n",
      "Time so far is 34m 16s\n",
      "Epoch Number: 0, Batch Number: 25400, Validation Metric: 0.1300\n",
      "Epoch Number: 0, Batch Number: 25400, Training Loss: 37.7139\n",
      "Time so far is 34m 33s\n",
      "Epoch Number: 0, Batch Number: 25600, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 25600, Training Loss: 36.4810\n",
      "Time so far is 34m 49s\n",
      "Epoch Number: 0, Batch Number: 25800, Validation Metric: 0.1900\n",
      "Epoch Number: 0, Batch Number: 25800, Training Loss: 36.3116\n",
      "Time so far is 35m 5s\n",
      "Epoch Number: 0, Batch Number: 26000, Validation Metric: 0.2300\n",
      "Epoch Number: 0, Batch Number: 26000, Training Loss: 38.5085\n",
      "Time so far is 35m 22s\n",
      "Epoch Number: 0, Batch Number: 26200, Validation Metric: 0.1650\n",
      "Epoch Number: 0, Batch Number: 26200, Training Loss: 34.5679\n",
      "Time so far is 35m 41s\n",
      "Epoch Number: 0, Batch Number: 26400, Validation Metric: 0.2050\n",
      "Epoch Number: 0, Batch Number: 26400, Training Loss: 36.7028\n",
      "Time so far is 35m 58s\n",
      "Epoch Number: 0, Batch Number: 26600, Validation Metric: 0.1350\n",
      "Epoch Number: 0, Batch Number: 26600, Training Loss: 34.8269\n",
      "Time so far is 36m 14s\n",
      "Epoch Number: 0, Batch Number: 26800, Validation Metric: 0.1600\n",
      "Epoch Number: 0, Batch Number: 26800, Training Loss: 36.0598\n",
      "Time so far is 36m 32s\n",
      "Epoch Number: 0, Batch Number: 27000, Validation Metric: 0.1300\n",
      "Epoch Number: 0, Batch Number: 27000, Training Loss: 39.1811\n",
      "Time so far is 36m 49s\n",
      "Epoch Number: 0, Batch Number: 27200, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 27200, Training Loss: 35.0697\n",
      "Time so far is 37m 5s\n",
      "Epoch Number: 0, Batch Number: 27400, Validation Metric: 0.2600\n",
      "Epoch Number: 0, Batch Number: 27400, Training Loss: 34.4814\n",
      "Time so far is 37m 21s\n",
      "Epoch Number: 0, Batch Number: 27600, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 27600, Training Loss: 36.5558\n",
      "Time so far is 37m 37s\n",
      "Epoch Number: 0, Batch Number: 27800, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 27800, Training Loss: 38.0013\n",
      "Time so far is 37m 55s\n",
      "Epoch Number: 0, Batch Number: 28000, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 28000, Training Loss: 36.7121\n",
      "Time so far is 38m 16s\n",
      "Epoch Number: 0, Batch Number: 28200, Validation Metric: 0.1750\n",
      "Epoch Number: 0, Batch Number: 28200, Training Loss: 34.2859\n",
      "Time so far is 38m 33s\n",
      "Epoch Number: 0, Batch Number: 28400, Validation Metric: 0.2000\n",
      "Epoch Number: 0, Batch Number: 28400, Training Loss: 32.8889\n",
      "Time so far is 38m 51s\n",
      "Epoch Number: 0, Batch Number: 28600, Validation Metric: 0.2450\n",
      "Epoch Number: 0, Batch Number: 28600, Training Loss: 35.3413\n",
      "Time so far is 39m 8s\n",
      "Epoch Number: 0, Batch Number: 28800, Validation Metric: 0.2650\n",
      "Epoch Number: 0, Batch Number: 28800, Training Loss: 30.3464\n",
      "Time so far is 39m 23s\n",
      "Epoch Number: 0, Batch Number: 29000, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 29000, Training Loss: 34.4735\n",
      "Time so far is 39m 41s\n",
      "Epoch Number: 0, Batch Number: 29200, Validation Metric: 0.1700\n",
      "Epoch Number: 0, Batch Number: 29200, Training Loss: 31.2005\n",
      "Time so far is 39m 57s\n",
      "Epoch Number: 0, Batch Number: 29400, Validation Metric: 0.2500\n",
      "Epoch Number: 0, Batch Number: 29400, Training Loss: 34.2551\n",
      "Time so far is 40m 16s\n",
      "Epoch Number: 0, Batch Number: 29600, Validation Metric: 0.2600\n",
      "Epoch Number: 0, Batch Number: 29600, Training Loss: 30.7381\n",
      "Time so far is 40m 32s\n",
      "Epoch Number: 0, Batch Number: 29800, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 29800, Training Loss: 39.6315\n",
      "Time so far is 40m 51s\n",
      "Epoch Number: 0, Batch Number: 30000, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 30000, Training Loss: 31.2632\n",
      "Time so far is 41m 10s\n",
      "Epoch Number: 0, Batch Number: 30200, Validation Metric: 0.2050\n",
      "Epoch Number: 0, Batch Number: 30200, Training Loss: 34.3717\n",
      "Time so far is 41m 28s\n",
      "Epoch Number: 0, Batch Number: 30400, Validation Metric: 0.2800\n",
      "Epoch Number: 0, Batch Number: 30400, Training Loss: 29.8695\n",
      "Time so far is 41m 43s\n",
      "Epoch Number: 0, Batch Number: 30600, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 30600, Training Loss: 34.4571\n",
      "Time so far is 41m 60s\n",
      "Epoch Number: 0, Batch Number: 30800, Validation Metric: 0.1900\n",
      "Epoch Number: 0, Batch Number: 30800, Training Loss: 33.6303\n",
      "Time so far is 42m 17s\n",
      "Epoch Number: 0, Batch Number: 31000, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 31000, Training Loss: 36.5059\n",
      "Time so far is 42m 35s\n",
      "Epoch Number: 0, Batch Number: 31200, Validation Metric: 0.1800\n",
      "Epoch Number: 0, Batch Number: 31200, Training Loss: 36.2575\n",
      "Time so far is 42m 52s\n",
      "Epoch Number: 0, Batch Number: 31400, Validation Metric: 0.2700\n",
      "Epoch Number: 0, Batch Number: 31400, Training Loss: 30.1884\n",
      "Time so far is 43m 7s\n",
      "Epoch Number: 0, Batch Number: 31600, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 31600, Training Loss: 33.8881\n",
      "Time so far is 43m 22s\n",
      "Epoch Number: 0, Batch Number: 31800, Validation Metric: 0.2600\n",
      "Epoch Number: 0, Batch Number: 31800, Training Loss: 32.1201\n",
      "Time so far is 43m 38s\n",
      "Epoch Number: 0, Batch Number: 32000, Validation Metric: 0.1900\n",
      "Epoch Number: 0, Batch Number: 32000, Training Loss: 35.6926\n",
      "Time so far is 43m 58s\n",
      "Epoch Number: 0, Batch Number: 32200, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 32200, Training Loss: 33.4826\n",
      "Time so far is 44m 14s\n",
      "Epoch Number: 0, Batch Number: 32400, Validation Metric: 0.2000\n",
      "Epoch Number: 0, Batch Number: 32400, Training Loss: 38.4031\n",
      "Time so far is 44m 32s\n",
      "Epoch Number: 0, Batch Number: 32600, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 32600, Training Loss: 31.9526\n",
      "Time so far is 44m 48s\n",
      "Epoch Number: 0, Batch Number: 32800, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 32800, Training Loss: 30.7642\n",
      "Time so far is 45m 4s\n",
      "Epoch Number: 0, Batch Number: 33000, Validation Metric: 0.2150\n",
      "Epoch Number: 0, Batch Number: 33000, Training Loss: 33.4787\n",
      "Time so far is 45m 20s\n",
      "Epoch Number: 0, Batch Number: 33200, Validation Metric: 0.2800\n",
      "Epoch Number: 0, Batch Number: 33200, Training Loss: 30.4807\n",
      "Time so far is 45m 35s\n",
      "Epoch Number: 0, Batch Number: 33400, Validation Metric: 0.1800\n",
      "Epoch Number: 0, Batch Number: 33400, Training Loss: 32.3340\n",
      "Time so far is 45m 50s\n",
      "Epoch Number: 0, Batch Number: 33600, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 33600, Training Loss: 31.7420\n",
      "Time so far is 46m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0, Batch Number: 33800, Validation Metric: 0.1950\n",
      "Epoch Number: 0, Batch Number: 33800, Training Loss: 35.5178\n",
      "Time so far is 46m 21s\n",
      "Epoch Number: 0, Batch Number: 34000, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 34000, Training Loss: 35.0745\n",
      "Time so far is 46m 40s\n",
      "Epoch Number: 0, Batch Number: 34200, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 34200, Training Loss: 35.8931\n",
      "Time so far is 46m 58s\n",
      "Epoch Number: 0, Batch Number: 34400, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 34400, Training Loss: 32.0017\n",
      "Time so far is 47m 15s\n",
      "Epoch Number: 0, Batch Number: 34600, Validation Metric: 0.2500\n",
      "Epoch Number: 0, Batch Number: 34600, Training Loss: 28.8750\n",
      "Time so far is 47m 31s\n",
      "Epoch Number: 0, Batch Number: 34800, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 34800, Training Loss: 30.8994\n",
      "Time so far is 47m 46s\n",
      "Epoch Number: 0, Batch Number: 35000, Validation Metric: 0.2150\n",
      "Epoch Number: 0, Batch Number: 35000, Training Loss: 33.1754\n",
      "Time so far is 48m 2s\n",
      "Epoch Number: 0, Batch Number: 35200, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 35200, Training Loss: 34.3425\n",
      "Time so far is 48m 18s\n",
      "Epoch Number: 0, Batch Number: 35400, Validation Metric: 0.2050\n",
      "Epoch Number: 0, Batch Number: 35400, Training Loss: 35.6554\n",
      "Time so far is 48m 36s\n",
      "Epoch Number: 0, Batch Number: 35600, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 35600, Training Loss: 29.6728\n",
      "Time so far is 48m 52s\n",
      "Epoch Number: 0, Batch Number: 35800, Validation Metric: 0.2150\n",
      "Epoch Number: 0, Batch Number: 35800, Training Loss: 31.7022\n",
      "Time so far is 49m 11s\n",
      "Epoch Number: 0, Batch Number: 36000, Validation Metric: 0.1850\n",
      "Epoch Number: 0, Batch Number: 36000, Training Loss: 34.2307\n",
      "Time so far is 49m 28s\n",
      "Epoch Number: 0, Batch Number: 36200, Validation Metric: 0.2050\n",
      "Epoch Number: 0, Batch Number: 36200, Training Loss: 32.6519\n",
      "Time so far is 49m 44s\n",
      "Epoch Number: 0, Batch Number: 36400, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 36400, Training Loss: 28.2124\n",
      "Time so far is 49m 59s\n",
      "Epoch Number: 0, Batch Number: 36600, Validation Metric: 0.1950\n",
      "Epoch Number: 0, Batch Number: 36600, Training Loss: 32.5604\n",
      "Time so far is 50m 17s\n",
      "Epoch Number: 0, Batch Number: 36800, Validation Metric: 0.2600\n",
      "Epoch Number: 0, Batch Number: 36800, Training Loss: 27.8229\n",
      "Time so far is 50m 32s\n",
      "Epoch Number: 0, Batch Number: 37000, Validation Metric: 0.1800\n",
      "Epoch Number: 0, Batch Number: 37000, Training Loss: 31.4349\n",
      "Time so far is 50m 49s\n",
      "Epoch Number: 0, Batch Number: 37200, Validation Metric: 0.2100\n",
      "Epoch Number: 0, Batch Number: 37200, Training Loss: 28.2435\n",
      "Time so far is 51m 6s\n",
      "Epoch Number: 0, Batch Number: 37400, Validation Metric: 0.2650\n",
      "Epoch Number: 0, Batch Number: 37400, Training Loss: 30.1953\n",
      "Time so far is 51m 22s\n",
      "Epoch Number: 0, Batch Number: 37600, Validation Metric: 0.2000\n",
      "Epoch Number: 0, Batch Number: 37600, Training Loss: 34.9916\n",
      "Time so far is 51m 41s\n",
      "Epoch Number: 0, Batch Number: 37800, Validation Metric: 0.2650\n",
      "Epoch Number: 0, Batch Number: 37800, Training Loss: 27.1924\n",
      "Time so far is 51m 60s\n",
      "Epoch Number: 0, Batch Number: 38000, Validation Metric: 0.2800\n",
      "Epoch Number: 0, Batch Number: 38000, Training Loss: 28.5259\n",
      "Time so far is 52m 17s\n",
      "Epoch Number: 0, Batch Number: 38200, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 38200, Training Loss: 26.7117\n",
      "Time so far is 52m 33s\n",
      "Epoch Number: 0, Batch Number: 38400, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 38400, Training Loss: 28.6008\n",
      "Time so far is 52m 51s\n",
      "Epoch Number: 0, Batch Number: 38600, Validation Metric: 0.3000\n",
      "Epoch Number: 0, Batch Number: 38600, Training Loss: 28.2443\n",
      "Time so far is 53m 8s\n",
      "Epoch Number: 0, Batch Number: 38800, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 38800, Training Loss: 29.1351\n",
      "Time so far is 53m 23s\n",
      "Epoch Number: 0, Batch Number: 39000, Validation Metric: 0.2200\n",
      "Epoch Number: 0, Batch Number: 39000, Training Loss: 29.8659\n",
      "Time so far is 53m 40s\n",
      "Epoch Number: 0, Batch Number: 39200, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 39200, Training Loss: 27.9920\n",
      "Time so far is 53m 55s\n",
      "Epoch Number: 0, Batch Number: 39400, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 39400, Training Loss: 29.4804\n",
      "Time so far is 54m 13s\n",
      "Epoch Number: 0, Batch Number: 39600, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 39600, Training Loss: 30.0642\n",
      "Time so far is 54m 29s\n",
      "Epoch Number: 0, Batch Number: 39800, Validation Metric: 0.2250\n",
      "Epoch Number: 0, Batch Number: 39800, Training Loss: 28.5488\n",
      "Time so far is 54m 48s\n",
      "Epoch Number: 0, Batch Number: 40000, Validation Metric: 0.2350\n",
      "Epoch Number: 0, Batch Number: 40000, Training Loss: 24.3166\n",
      "Time so far is 55m 3s\n",
      "Epoch Number: 0, Batch Number: 40200, Validation Metric: 0.2400\n",
      "Epoch Number: 0, Batch Number: 40200, Training Loss: 24.9578\n",
      "Time so far is 55m 17s\n",
      "Epoch Number: 0, Batch Number: 40400, Validation Metric: 0.2750\n",
      "Epoch Number: 0, Batch Number: 40400, Training Loss: 26.1310\n",
      "Time so far is 55m 32s\n",
      "Epoch Number: 0, Batch Number: 40600, Validation Metric: 0.2650\n",
      "Epoch Number: 0, Batch Number: 40600, Training Loss: 23.3838\n",
      "Time so far is 55m 45s\n",
      "Epoch Number: 0, Batch Number: 40800, Validation Metric: 0.2450\n",
      "Epoch Number: 0, Batch Number: 40800, Training Loss: 28.0374\n",
      "Time so far is 56m 1s\n",
      "Epoch Number: 0, Batch Number: 41000, Validation Metric: 0.2500\n",
      "Epoch Number: 0, Batch Number: 41000, Training Loss: 30.2415\n",
      "Time so far is 56m 18s\n",
      "Epoch Number: 0, Batch Number: 41200, Validation Metric: 0.3050\n",
      "Epoch Number: 0, Batch Number: 41200, Training Loss: 27.1758\n",
      "Time so far is 56m 34s\n",
      "Epoch Number: 0, Batch Number: 41400, Validation Metric: 0.2700\n",
      "Epoch Number: 0, Batch Number: 41400, Training Loss: 25.1177\n",
      "Time so far is 56m 49s\n",
      "Epoch Number: 0, Batch Number: 41600, Validation Metric: 0.3200\n",
      "Epoch Number: 0, Batch Number: 41600, Training Loss: 26.6510\n",
      "Time so far is 57m 5s\n",
      "Epoch Number: 0, Batch Number: 41800, Validation Metric: 0.3000\n",
      "Epoch Number: 0, Batch Number: 41800, Training Loss: 24.8108\n",
      "Time so far is 57m 22s\n",
      "Epoch Number: 0, Batch Number: 42000, Validation Metric: 0.3600\n",
      "Epoch Number: 0, Batch Number: 42000, Training Loss: 27.3147\n",
      "Time so far is 57m 37s\n",
      "Epoch Number: 0, Batch Number: 42200, Validation Metric: 0.2900\n",
      "Epoch Number: 0, Batch Number: 42200, Training Loss: 24.0819\n",
      "Time so far is 57m 52s\n",
      "Epoch Number: 0, Batch Number: 42400, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 42400, Training Loss: 22.9243\n",
      "Time so far is 58m 5s\n",
      "Epoch Number: 0, Batch Number: 42600, Validation Metric: 0.3650\n",
      "Epoch Number: 0, Batch Number: 42600, Training Loss: 24.9933\n",
      "Time so far is 58m 20s\n",
      "Epoch Number: 0, Batch Number: 42800, Validation Metric: 0.3250\n",
      "Epoch Number: 0, Batch Number: 42800, Training Loss: 24.0826\n",
      "Time so far is 58m 35s\n",
      "Epoch Number: 0, Batch Number: 43000, Validation Metric: 0.3750\n",
      "Epoch Number: 0, Batch Number: 43000, Training Loss: 19.4344\n",
      "Time so far is 58m 48s\n",
      "Epoch Number: 0, Batch Number: 43200, Validation Metric: 0.2600\n",
      "Epoch Number: 0, Batch Number: 43200, Training Loss: 29.5469\n",
      "Time so far is 59m 3s\n",
      "Epoch Number: 0, Batch Number: 43400, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 43400, Training Loss: 22.8237\n",
      "Time so far is 59m 17s\n",
      "Epoch Number: 0, Batch Number: 43600, Validation Metric: 0.2900\n",
      "Epoch Number: 0, Batch Number: 43600, Training Loss: 30.0338\n",
      "Time so far is 59m 34s\n",
      "Epoch Number: 0, Batch Number: 43800, Validation Metric: 0.2800\n",
      "Epoch Number: 0, Batch Number: 43800, Training Loss: 27.6016\n",
      "Time so far is 59m 49s\n",
      "Epoch Number: 0, Batch Number: 44000, Validation Metric: 0.3350\n",
      "Epoch Number: 0, Batch Number: 44000, Training Loss: 23.5067\n",
      "Time so far is 60m 6s\n",
      "Epoch Number: 0, Batch Number: 44200, Validation Metric: 0.3200\n",
      "Epoch Number: 0, Batch Number: 44200, Training Loss: 25.6553\n",
      "Time so far is 60m 20s\n",
      "Epoch Number: 0, Batch Number: 44400, Validation Metric: 0.3550\n",
      "Epoch Number: 0, Batch Number: 44400, Training Loss: 22.9009\n",
      "Time so far is 60m 34s\n",
      "Epoch Number: 0, Batch Number: 44600, Validation Metric: 0.2950\n",
      "Epoch Number: 0, Batch Number: 44600, Training Loss: 26.6964\n",
      "Time so far is 60m 49s\n",
      "Epoch Number: 0, Batch Number: 44800, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 44800, Training Loss: 27.3666\n",
      "Time so far is 61m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0, Batch Number: 45000, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 45000, Training Loss: 30.1143\n",
      "Time so far is 61m 21s\n",
      "Epoch Number: 0, Batch Number: 45200, Validation Metric: 0.3400\n",
      "Epoch Number: 0, Batch Number: 45200, Training Loss: 25.6660\n",
      "Time so far is 61m 36s\n",
      "Epoch Number: 0, Batch Number: 45400, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 45400, Training Loss: 24.6572\n",
      "Time so far is 61m 52s\n",
      "Epoch Number: 0, Batch Number: 45600, Validation Metric: 0.3850\n",
      "Epoch Number: 0, Batch Number: 45600, Training Loss: 24.3045\n",
      "Time so far is 62m 6s\n",
      "Epoch Number: 0, Batch Number: 45800, Validation Metric: 0.3850\n",
      "Epoch Number: 0, Batch Number: 45800, Training Loss: 26.8374\n",
      "Time so far is 62m 22s\n",
      "Epoch Number: 0, Batch Number: 46000, Validation Metric: 0.3800\n",
      "Epoch Number: 0, Batch Number: 46000, Training Loss: 23.5481\n",
      "Time so far is 62m 36s\n",
      "Epoch Number: 0, Batch Number: 46200, Validation Metric: 0.3550\n",
      "Epoch Number: 0, Batch Number: 46200, Training Loss: 24.6384\n",
      "Time so far is 62m 53s\n",
      "Epoch Number: 0, Batch Number: 46400, Validation Metric: 0.3800\n",
      "Epoch Number: 0, Batch Number: 46400, Training Loss: 25.0373\n",
      "Time so far is 63m 8s\n",
      "Epoch Number: 0, Batch Number: 46600, Validation Metric: 0.3750\n",
      "Epoch Number: 0, Batch Number: 46600, Training Loss: 23.1275\n",
      "Time so far is 63m 21s\n",
      "Epoch Number: 0, Batch Number: 46800, Validation Metric: 0.4250\n",
      "Epoch Number: 0, Batch Number: 46800, Training Loss: 22.5904\n",
      "Time so far is 63m 35s\n",
      "Epoch Number: 0, Batch Number: 47000, Validation Metric: 0.3600\n",
      "Epoch Number: 0, Batch Number: 47000, Training Loss: 26.3873\n",
      "Time so far is 63m 50s\n",
      "Epoch Number: 0, Batch Number: 47200, Validation Metric: 0.4200\n",
      "Epoch Number: 0, Batch Number: 47200, Training Loss: 22.4311\n",
      "Time so far is 64m 4s\n",
      "Epoch Number: 0, Batch Number: 47400, Validation Metric: 0.3450\n",
      "Epoch Number: 0, Batch Number: 47400, Training Loss: 26.1926\n",
      "Time so far is 64m 20s\n",
      "Epoch Number: 0, Batch Number: 47600, Validation Metric: 0.3500\n",
      "Epoch Number: 0, Batch Number: 47600, Training Loss: 24.1587\n",
      "Time so far is 64m 35s\n",
      "Epoch Number: 0, Batch Number: 47800, Validation Metric: 0.3800\n",
      "Epoch Number: 0, Batch Number: 47800, Training Loss: 21.6398\n",
      "Time so far is 64m 49s\n",
      "Epoch Number: 0, Batch Number: 48000, Validation Metric: 0.3800\n",
      "Epoch Number: 0, Batch Number: 48000, Training Loss: 23.0063\n",
      "Time so far is 65m 3s\n",
      "Epoch Number: 0, Batch Number: 48200, Validation Metric: 0.3250\n",
      "Epoch Number: 0, Batch Number: 48200, Training Loss: 25.6565\n",
      "Time so far is 65m 21s\n",
      "Epoch Number: 0, Batch Number: 48400, Validation Metric: 0.3500\n",
      "Epoch Number: 0, Batch Number: 48400, Training Loss: 24.8815\n",
      "Time so far is 65m 35s\n",
      "Epoch Number: 0, Batch Number: 48600, Validation Metric: 0.4150\n",
      "Epoch Number: 0, Batch Number: 48600, Training Loss: 24.3909\n",
      "Time so far is 65m 49s\n",
      "Epoch Number: 0, Batch Number: 48800, Validation Metric: 0.3550\n",
      "Epoch Number: 0, Batch Number: 48800, Training Loss: 25.1637\n",
      "Time so far is 66m 4s\n",
      "Epoch Number: 0, Batch Number: 49000, Validation Metric: 0.3050\n",
      "Epoch Number: 0, Batch Number: 49000, Training Loss: 24.1344\n",
      "Time so far is 66m 19s\n",
      "Epoch Number: 0, Batch Number: 49200, Validation Metric: 0.3550\n",
      "Epoch Number: 0, Batch Number: 49200, Training Loss: 26.6056\n",
      "Time so far is 66m 34s\n",
      "Epoch Number: 0, Batch Number: 49400, Validation Metric: 0.3750\n",
      "Epoch Number: 0, Batch Number: 49400, Training Loss: 25.5101\n",
      "Time so far is 66m 49s\n",
      "Epoch Number: 0, Batch Number: 49600, Validation Metric: 0.3950\n",
      "Epoch Number: 0, Batch Number: 49600, Training Loss: 25.5576\n",
      "Time so far is 67m 4s\n"
     ]
    }
   ],
   "source": [
    "program_model, train_losses, validation_losses = \\\n",
    "    training.train_model_anc(program_model, for_lambda_dset, optimizer, \n",
    "                             lr_scheduler=lr_scheduler, \n",
    "                             num_epochs=10, validation_criterion=program_accuracy, batch_size=100, \n",
    "                             use_cuda=True, plateau_lr=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
