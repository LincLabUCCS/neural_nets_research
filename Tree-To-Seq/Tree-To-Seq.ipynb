{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Insert Useful Comments\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_children):\n",
    "        super(TreeCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Gates = input, output, memory + one forget gate per child\n",
    "        numGates = 3 + num_children\n",
    "        \n",
    "        self.gates_value = torch.nn.ModuleList()\n",
    "        self.gates_children = torch.nn.ModuleList()\n",
    "        for _ in range(numGates):\n",
    "            # One linear layer to handle the value of the node\n",
    "            value_linear = nn.Linear(input_size, hidden_size, bias = True)\n",
    "            children_linear = torch.nn.ModuleList()\n",
    "            # One per child of the node\n",
    "            for _ in range(num_children):\n",
    "                children_linear.append(nn.Linear(hidden_size, hidden_size, bias = False))\n",
    "            self.gates_value.append(value_linear)\n",
    "            self.gates_children.append(children_linear)\n",
    "            \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 2 hidden states.\n",
    "        :param cell_states: A list of 2 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_sums = []\n",
    "        for i in range(len(self.gates_value)):\n",
    "            data_sum = self.gates_value[i](input)\n",
    "            for j in range(len(hidden_states)):\n",
    "                data_sum += self.gates_children[i][j](hidden_states[j])\n",
    "            data_sums.append(data_sum)\n",
    "            \n",
    "        # First gate is the input gate\n",
    "        i = self.sigmoid(data_sums[0])\n",
    "        # Next output gate\n",
    "        o = self.sigmoid(data_sums[1])\n",
    "        # Next memory gate\n",
    "        m = self.tanh(data_sums[2])\n",
    "        # All the rest are forget gates\n",
    "        forget_data = 0\n",
    "        for i in range(len(cell_states)):\n",
    "            forget_data += data_sums[3 + i] * cell_states[i]\n",
    "        \n",
    "        # Put it all together!\n",
    "        new_state = i * m + forget_data\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "                \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerTreeCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_children, num_layers, bias=True):\n",
    "        super(MultilayerTreeCell, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        \n",
    "        if isinstance(hidden_sizes, int):\n",
    "            temp = [input_size]\n",
    "            \n",
    "            for _ in range(num_layers):\n",
    "                temp.append(hidden_sizes)\n",
    "            \n",
    "            hidden_sizes = temp\n",
    "            \n",
    "        else:\n",
    "            hidden_sizes = [input_size] + hidden_sizes\n",
    "        self.tree_cell = TreeCell(input_size, hidden_sizes[0], num_children)\n",
    "        for i in range(1, num_layers):\n",
    "            curr_lstm = nn.LSTMCell(hidden_sizes[i], hidden_sizes[i+1], bias=bias)\n",
    "            self.lstm_layers.append(curr_lstm)\n",
    "    \n",
    "    def forward(self, input, hiddens, cell_states):\n",
    "        result_hiddens, result_cell_states = [], []\n",
    "        curr_input, new_cell_state = self.tree_cell(input, hiddens[0], cell_states[0])\n",
    "        result_hiddens.append(curr_input)\n",
    "        result_cell_states.append(new_cell_state)\n",
    "        for lstm_cell, curr_hidden, curr_cell_state in zip(self.lstm_layers, hiddens[1:], cell_states[1:]):\n",
    "            curr_input, new_cell_state = lstm_cell(curr_input, (curr_hidden, curr_cell_state))\n",
    "            result_hiddens.append(curr_input)\n",
    "            result_cell_states.append(new_cell_state)\n",
    "        \n",
    "        return result_hiddens, result_cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encoder\n",
    "\n",
    "Takes in a Tree where each node has a value (vector?) and a list of children\n",
    "Produces a vector of desired size with an encoding of the tree\n",
    "\n",
    "Recursively: For each node go left *then go middle* then go right, pass the necessary values\n",
    "into an lstm cell along with values from each child (0 if at leaf) Output the result of the lstm cell\n",
    "at the root.\n",
    "\n",
    "'''\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in a tree where each node has a value vector and a list of children\n",
    "    Produces a sequence encoding of the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, numLayers, valid_num_children):\n",
    "        \"\"\"\n",
    "        Initialize variables we'll need later.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        test = [0] + valid_num_children\n",
    "        temp = torch.IntTensor(test)\n",
    "        self.valid_num_children = Variable(temp)\n",
    "        self.numLayers = numLayers\n",
    "        self.lstm_list = torch.nn.ModuleList()\n",
    "        # We'll always need 0 for leaf nodes\n",
    "        #self.lstm_list.append(MultilayerTreeCell(input_size, hidden_size, 0, numLayers))\n",
    "        self.lstm_list.append(TreeCell(input_size, hidden_size, 0))\n",
    "        \n",
    "        for size in valid_num_children:\n",
    "   #         self.lstm_list.append(MultilayerTreeCell(input_size, hidden_size, size, numLayers))\n",
    "            self.lstm_list.append(TreeCell(input_size, hidden_size, size))\n",
    "\n",
    "        self.encoding = Variable(torch.FloatTensor(1, hidden_size))\n",
    "        \n",
    "    def forward(self, tree):\n",
    "        \"\"\"\n",
    "        Starts off the entire encoding process\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return self.encoding, a matrix where each row represents the encoded output of a single node\n",
    "        \"\"\"\n",
    "        embeddings = [p[0] for p in self.encode(tree)]\n",
    "        return torch.cat(embeddings, 0)\n",
    "        \n",
    "    def encode(self, node):\n",
    "        \"\"\"\n",
    "        Recursively a node and all its children as sequence vectors\n",
    "        \n",
    "        :param node: The root of the tree (or subtree)\n",
    "        :return A tuple (new hidden vector, new cell state).  The new hidden vector is an endoding of node\n",
    "        \"\"\"\n",
    "        \n",
    "        # List of tuples: (h, c), each of which are size hidden_size\n",
    "        descendents = []\n",
    "        children = []\n",
    "        \n",
    "        for child in node.children:\n",
    "            current_descendents = self.encode(child)\n",
    "            descendents += current_descendents\n",
    "            children.append(current_descendents[-1])\n",
    "\n",
    "        # Vector of size input_size x len(children)\n",
    "        inputH = [vec[0] for vec in children]\n",
    "        inputC = [vec[1] for vec in children]\n",
    "        \n",
    "        \n",
    "        value = Variable(node.value.unsqueeze(0))\n",
    "        \n",
    "        found = False\n",
    "        for i in range(len(self.lstm_list)):\n",
    "            if self.valid_num_children[i].data[0] == len(children):\n",
    "                newH, newC = self.lstm_list[i](value, inputH, inputH)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(\"WHAAAAAT?\")\n",
    "            raise ValueError(\"Beware.  Something has gone horribly wrong.  You may not have long to live.\")\n",
    "            \n",
    "        # Add the new encoding to the end of our list\n",
    "        descendents.append((newH, newC))\n",
    "        return descendents\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 5\n",
    "\n",
    "test_vec = torch.FloatTensor(input_size)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node class just made for testing\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self. value = value\n",
    "        self.children = []\n",
    "    \n",
    "\n",
    "child_len = [2, 3, 2, 3]   \n",
    "def makeNodes(children):\n",
    "    \"\"\"\n",
    "    Loop through the passes-in array and build a tree where each node in the i^th layer has children[i] nodes\n",
    "\n",
    "    \"\"\"\n",
    "    if len(children) == 0:\n",
    "        return Node(test_vec) # Make them all the same vec\n",
    "    else: \n",
    "        newNode = Node(test_vec)\n",
    "        for i in range(children[0]):\n",
    "            newNode.children.append(makeNodes(children[1:]))\n",
    "        return newNode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODEDVEC Variable containing:\n",
      " 2.2863e-02  6.5662e-03  1.1763e-02  2.8647e-02 -5.4916e-02\n",
      " 4.6569e-02  7.1402e-03 -1.0319e-02  3.8583e-02 -4.6100e-02\n",
      " 3.2813e-03 -1.0021e-03  2.1564e-05 -2.7582e-03  7.4565e-03\n",
      "-1.8096e-02  2.1923e-02 -8.4839e-02  1.5602e-01  7.5357e-02\n",
      " 5.2191e-02  2.9534e-02  4.0366e-03  3.6444e-02  1.3136e-02\n",
      "-1.4336e-02 -1.9640e-02  5.6897e-02  6.3062e-02 -3.2052e-03\n",
      "-9.9474e-04  2.1714e-03 -6.6700e-04 -3.6863e-03  5.0313e-04\n",
      " 7.9014e-02  5.2478e-02 -1.0640e-01  2.1987e-02 -5.6953e-02\n",
      "-5.9615e-03  3.0944e-03  3.8092e-02  5.4920e-02 -4.1653e-02\n",
      "-1.2267e-02  4.1403e-02  1.2829e-02  6.8995e-02 -5.5225e-02\n",
      "-7.4902e-04 -4.8250e-03 -4.1882e-06 -4.7838e-03  9.7149e-03\n",
      " 8.6297e-02  4.4594e-02 -9.6374e-02  1.1192e-02 -4.9746e-02\n",
      "-1.6625e-03 -3.9217e-04  5.3452e-03 -3.5707e-04 -1.6696e-03\n",
      " 5.3520e-02  5.7091e-02  9.6964e-02  1.7505e-01  6.0116e-02\n",
      " 1.2860e-01  1.1356e-01  5.5452e-02  1.0455e-01 -1.8374e-03\n",
      " 1.3199e-02 -1.5690e-02  4.5331e-04 -6.2073e-03  1.1502e-05\n",
      "[torch.FloatTensor of size 16x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonString = \"{\\\"tag\\\":\\\"If\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"GeFor\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":5},{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":3}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"X\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":1}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"Y\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":2}]}]}\"\n",
    "jsonObj = json.loads(jsonString)\n",
    "for_list_json = json.load(open('/Users/ericweiner/Documents/neural_nets_research/ANC/arbitraryForList.json'))\n",
    "num_vars = 5\n",
    "num_ints = 7\n",
    "for_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"Assign\": 7,\n",
    "    \"If\": 8,\n",
    "    \"Seq\": 9,\n",
    "    \"For\": 10\n",
    "}\n",
    "var_dict = {}\n",
    "\n",
    "def vectorize(val):\n",
    "    vector = torch.zeros(num_vars + num_ints + len(for_ops.keys()))\n",
    "    if type(val) is int:\n",
    "        vector[val] = 1\n",
    "    elif type(val) is str:\n",
    "        index = len(var_dict.keys())\n",
    "        if val in var_dict:\n",
    "            index = var_dict[val]\n",
    "        else:\n",
    "            var_dict[val] = index\n",
    "        vector[index + num_ints] = 1\n",
    "    else:\n",
    "        index = for_ops[val]\n",
    "        vector[num_ints + num_vars + index] = 1\n",
    "    return vector\n",
    "            \n",
    "        \n",
    "\n",
    "def makeTree(json):\n",
    "    if type(json) is str:\n",
    "        parentNode = Node(vectorize(\"Var\"))\n",
    "        childNode = Node(vectorize(json))\n",
    "        parentNode.children.append(childNode)\n",
    "        return parentNode \n",
    "    \n",
    "    if type(json) is int:\n",
    "        return Node(vectorize(json))\n",
    "\n",
    "    tag = json[\"tag\"]\n",
    "    children = json[\"contents\"]\n",
    "    parentNode = Node(vectorize(tag))\n",
    "    \n",
    "    currNode = parentNode\n",
    "    \n",
    "    if type(children) is list:\n",
    "        for child in children:\n",
    "            newChild = makeTree(child)\n",
    "            currNode.children.append(newChild)\n",
    "            currNode = newChild\n",
    "    else:\n",
    "        parentNode.children.append(makeTree(children))\n",
    "        \n",
    "    return parentNode\n",
    "\n",
    "\n",
    "\n",
    "def printTree(tree):\n",
    "    print(tree.value)\n",
    "    for child in tree.children:\n",
    "        printTree(child)\n",
    "    \n",
    "    \n",
    "tree = makeTree(jsonObj)\n",
    "numLayers = 3\n",
    "encoder = Encoder(num_vars + num_ints + len(for_ops.keys()), hidden_size, numLayers,[1,2,3])\n",
    "encoded_vec = encoder(tree)\n",
    "print(\"ENCODEDVEC\", encoded_vec)\n",
    "\n",
    "\n",
    "# kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "'''\n",
    "class Tree_to_Sequence_Model(nn.Module):\n",
    "    \"\"\"\n",
    "      For the decoder this expects something like an lstm cell or a gru cell and not an lstm/gru.\n",
    "      If you don't use teacher forcing, batches are forbidden/lead to bad behavior\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 use_lstm=False, use_cuda=True):\n",
    "        super(Tree_to_Sequence_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # nclass + 2 to include end of sequence and trash\n",
    "        self.output_log_probs = nn.Linear(hidden_size, nclass+2)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        self.SOS_token = Variable(torch.LongTensor([[0]]))\n",
    "        self.EOS_value = 1\n",
    "\n",
    "        if use_cuda:\n",
    "            self.SOS_token = self.SOS_token.cuda()\n",
    "\n",
    "        self.embedding = nn.Embedding(nclass, embedding_size)\n",
    "\n",
    "        self.use_lstm = use_lstm\n",
    "        # nclass + 1 is the trash category to avoid penalties after target's EOS token\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=nclass+1)\n",
    "\n",
    "        if use_lstm:\n",
    "            self.decoder_initial_cell_state = Variable(torch.zeros(1, hidden_size))\n",
    "\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        # encoded features\n",
    "        encoded_features = Variable(self.encoder(input)) # [w, c]\n",
    "        decoder_hidden = encoded_features[-1, :]\n",
    "\n",
    "        target_length = target.size()[0]\n",
    "        decoder_input = self.embedding(self.SOS_token).transpose(0,1).repeat(1, batch_size, 1)\n",
    "        loss = 0\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(target_length):\n",
    "            if self.use_lstm:\n",
    "                decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            log_probs = self.output_log_probs(decoder_output)\n",
    "            loss += self.loss_func(log_probs, target[i, :])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = self.embedding(target[i, :].unsqueeze(1)).squeeze(1)\n",
    "            else:\n",
    "                _, topi = log_probs.data.topk(1)\n",
    "                ni = topi[0, 0]\n",
    "\n",
    "                if ni == self.EOS_value:\n",
    "                    break\n",
    "\n",
    "                decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "#     \"\"\"\n",
    "#       Inputs must be of batch size 1\n",
    "#     \"\"\"\n",
    "#     def point_wise_prediction(self, input, maximum_length=20):\n",
    "#       # encoded features\n",
    "#       encoded_features = self.encoder(input).squeeze(1) # [w, c]\n",
    "#       decoder_hidden = encoded_features[-1, :]\n",
    "#       decoder_input = self.embedding(self.SOS_token).squeeze(0)\n",
    "#       output_so_far = []\n",
    "\n",
    "#       if self.use_lstm:\n",
    "#           decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "#       for i in range(maximum_length):\n",
    "#           if self.use_lstm:\n",
    "#               decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "#           else:\n",
    "#               decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "#           log_probs = self.output_log_probs(decoder_output)\n",
    "\n",
    "#           _, topi = log_probs.data.topk(1)\n",
    "#           ni = topi[0, 0]\n",
    "\n",
    "#           if ni == self.EOS_value:\n",
    "#               break\n",
    "\n",
    "#           output_so_far.append(ni)\n",
    "#           decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#           if self.use_cuda:\n",
    "#               decoder_input = decoder_input.cuda()\n",
    "\n",
    "#       return output_so_far\n",
    "\n",
    "\n",
    "#     def beam_search_prediction(self, input, maximum_length=20):\n",
    "#       pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_Model(Tree_to_Sequence_Model):\n",
    "    def __init__(self, encoder, decoder, num_decoder_layers, hidden_size, nclass, embedding_size,\n",
    "                 alignment_size, decoder_cell_state_shape=None, use_lstm=False, use_cuda=True):\n",
    "        super(Tree_to_Sequence_Attention_Model, self).__init__(encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                                                               use_lstm=use_lstm, use_cuda=use_cuda)\n",
    "        self.attention_hidden = nn.Linear(hidden_size, alignment_size)\n",
    "        self.attention_context = nn.Linear(hidden_size, alignment_size, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attention_alignment_vector = nn.Linear(alignment_size, 1)\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "\n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the input should have dimensions, (seq_len x batch_size x input_size)\n",
    "        target: The target should have dimensions, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        encoded_features = self.encoder(input) # sequence x encoder hidden\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hiddens = [encoded_features[-1, :].unsqueeze(0) for _ in range(num_decoder_layers)]\n",
    "        decoder_hidden = decoder_hiddens[-1]\n",
    "        target_length = target.size()[0] # sequence x decoder hidden\n",
    "        word_input = self.embedding(self.SOS_token).squeeze(0) # batch x decoder hidden\n",
    "\n",
    "        loss = 0\n",
    "        \n",
    "        if self.use_lstm:\n",
    "            decoder_cell_states = [self.decoder_initial_cell_state for x in range(num_decoder_layers)]\n",
    "\n",
    "        for i in range(target_length):\n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # decoder hidden \n",
    "            decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "            if self.use_lstm:     \n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, decoder_hiddens, decoder_cell_states)\n",
    "            else:\n",
    "                decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            log_probs = self.output_log_probs(decoder_hidden)\n",
    "            loss += self.loss_func(log_probs, target[i])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(0)\n",
    "            else:\n",
    "                _, next_input = log_probs.topk(1)\n",
    "                if next_input.data[0,0] == self.EOS_value:\n",
    "                    break\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(0) # batch x decoder hidden\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "      Inputs must be of batch size 1\n",
    "    \"\"\"\n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "        \n",
    "        encoded_features = self.encoder(input) # sequence x encoder hidden\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "        decoder_hiddens = [encoded_features[-1, :].unsqueeze(0) for _ in range(num_decoder_layers)]\n",
    "        decoder_hidden = decoder_hiddens[-1]\n",
    "        word_input = self.embedding(self.SOS_token).squeeze(0) # batch x decoder hidden\n",
    "\n",
    "        output_so_far = []\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_states = [self.decoder_initial_cell_state for x in range(num_decoder_layers)]\n",
    "\n",
    "            \n",
    "        for i in range(maximum_length):\n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # decoder hidden \n",
    "            decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "            if self.use_lstm:     \n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, decoder_hiddens, decoder_cell_states)\n",
    "            else:\n",
    "                decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            log_probs = self.output_log_probs(decoder_hidden)\n",
    "            \n",
    "\n",
    "            _, next_input = log_probs.topk(1)\n",
    "            output_so_far.append(next_input[0][0])\n",
    "            \n",
    "            if next_input.data[0, 0] == self.EOS_value:\n",
    "                break\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(0) # batch x hidden\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        # encoded features\n",
    "        encoded_features = self.encoder(input) # sequence x hidden\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hiddens = [encoded_features[-1, :].unsqueeze(0) for _ in range(num_decoder_layers)]\n",
    "        decoder_hidden = decoder_hiddens[-1]\n",
    "        word_inputs = []\n",
    "        for _ in range(beam_width):\n",
    "            word_inputs.append((0, [self.SOS_token], True))\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_states = [self.decoder_initial_cell_state for x in range(num_decoder_layers)]\n",
    "\n",
    "        for i in range(maximum_length):\n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # hidden \n",
    "            \n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # decoder hidden \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            newWordInputs = []\n",
    "            \n",
    "            for j in range(beam_width):\n",
    "                if not word_inputs[j][2]:\n",
    "                    newWordInputs.append(word_inputs[j])\n",
    "                    continue\n",
    "                    \n",
    "                word_input = self.embedding(word_inputs[j][1][-1]).squeeze(0)\n",
    "                decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "                if self.use_lstm:\n",
    "                    decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, decoder_hiddens, decoder_cell_states)\n",
    " #               else:\n",
    " #                   decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                              \n",
    "                \n",
    "                \n",
    "                log_probs = self.output_log_probs(decoder_hiddens[-1]).squeeze(0)\n",
    "                value, index = self.softmax(log_probs).topk(beam_width)\n",
    "                log_value = value.log()\n",
    "                print(\"index i\", index[i].unsqueeze(0))\n",
    "                print(\"wordinputs beamsize*1 -1\", word_inputs[-1][1])\n",
    "                print(\"combined\", word_inputs[-1][1] + [index[j].unsqueeze(0)])\n",
    "                newWordInputs.extend((word_inputs[k][0] + log_value[k], word_inputs[k][1] + [index[k].unsqueeze(0)], \n",
    "                                      (index[k].data == self.EOS_value)[0]) for k in range(beam_width))\n",
    "            #Get the new words in the beam.\n",
    "            word_inputs = sorted(newWordInputs, key=lambda word_pair: word_pair[1][-1].data[0][0])[-beam_width:]\n",
    "        outputs = [word_inputs[-i][1] for i in range(beam_width)]\n",
    "        return outputs\n",
    "    \n",
    "    def train_with_validation(self, train_loader, validation_loader,\n",
    "                                optimizer, lr_scheduler, num_fake_batches=10, num_epochs=20, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        Trains a model while printing updates on loss and accuracy. Once training is complete,\n",
    "        it is tested on the validation data set.\n",
    "        \"\"\"\n",
    "        since = time.time()\n",
    "\n",
    "        best_model = model\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "            optimizer = lr_scheduler(optimizer, epoch)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            current_batch = 0\n",
    "            loss = Variable(torch.FloatTensor([0]))\n",
    "            # Iterate over data.\n",
    "            for in_tree, out_seq in train_loader:\n",
    "                current_batch += 1\n",
    "\n",
    "                # wrap them in Variable\n",
    "                input_tree, expected_output_seq = Variable(in_tree), \\\n",
    "                                 Variable(out_seq)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                loss += self.forward_train(input, expected_output_seq, use_teacher_forcing)\n",
    "\n",
    "                # backward\n",
    "                if current_batch % num_fake_batches == 0:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "\n",
    "\n",
    "                if current_batch % 250 == 0:\n",
    "                    curr_loss = running_loss / (current_batch * train_loader.batch_size)\n",
    "                    time_elapsed = time.time() - since\n",
    "\n",
    "                    print('Epoch Number: {}, Batch Number: {}, Loss: {:.4f}, Acc: {:.4f}'.format(\n",
    "                        epoch, current_batch, curr_loss, curr_acc))\n",
    "                    print('Time so far is {:.0f}m {:.0f}s'.format(\n",
    "                        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "\n",
    "            validation_acc = test_model(model, validation_loader)\n",
    "            print('Epoch Number: {}, Validation Accuracy: {:.4f}'.format(epoch, validation_acc))\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, bias=True):\n",
    "        super(MultilayerLSTMCell, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        \n",
    "        if isinstance(hidden_sizes, int):\n",
    "            temp = [input_size]\n",
    "            \n",
    "            for _ in range(num_layers):\n",
    "                temp.append(hidden_sizes)\n",
    "            \n",
    "            hidden_sizes = temp\n",
    "            \n",
    "        else:\n",
    "            hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(num_layers):\n",
    "            curr_lstm = nn.LSTMCell(hidden_sizes[i], hidden_sizes[i+1], bias=bias)\n",
    "            self.lstm_layers.append(curr_lstm)\n",
    "    \n",
    "    def forward(self, input, hiddens, cell_states):\n",
    "        result_hiddens, result_cell_states = [], []\n",
    "        curr_input = input\n",
    "        \n",
    "        for lstm_cell, curr_hidden, curr_cell_state in zip(self.lstm_layers, hiddens, cell_states):\n",
    "            curr_input, new_cell_state = lstm_cell(curr_input, (curr_hidden, curr_cell_state))\n",
    "            result_hiddens.append(curr_input)\n",
    "            result_cell_states.append(new_cell_state)\n",
    "        \n",
    "        return result_hiddens, result_cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "hidden_size = 5\n",
    "nclass = 100\n",
    "alignment_size = 30\n",
    "num_decoder_layers = 3\n",
    "\n",
    "decoder = MultilayerLSTMCell(embedding_size + hidden_size, 5, 3)\n",
    "program_model = Tree_to_Sequence_Attention_Model(encoder, decoder, num_decoder_layers, hidden_size, nclass, embedding_size, alignment_size, use_lstm=True,\n",
    "                                                 use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_list(self, ast):\n",
    "    pass\n",
    "\n",
    "def list_to_tree(self, ls):\n",
    "    pass\n",
    "    \n",
    "def translate_from_for(self, ls):\n",
    "    if ls[0] == '<SEQ>':\n",
    "        t1 = self.translate_from_for(ls[1])\n",
    "        t2 = self.translate_from_for(ls[2])\n",
    "        if t1[0] == '<LET>' and t1[-1] == '<UNIT>':\n",
    "            t1[-1] = t2\n",
    "            return t1\n",
    "        else:\n",
    "            return ['<LET>', 'blank', t1, t2]\n",
    "    elif ls[0] == '<IF>':\n",
    "        cmp = ls[1]\n",
    "        t1 = self.translate_from_for(ls[2])\n",
    "        t2 = self.translate_from_for(ls[3])\n",
    "        return ['<IF>', cmp, t1, t2]\n",
    "    elif ls[0] == '<FOR>':\n",
    "        var = ls[1]\n",
    "        init = self.translate_from_for(ls[2])\n",
    "        cmp = self.translate_from_for(ls[3])\n",
    "        inc = self.translate_from_for(ls[4])\n",
    "        body = self.translate_from_for(ls[5])\n",
    "        tb = ['<LET>', 'blank', body, ['<APP>', 'func', inc]]\n",
    "        funcbody = ['<IF>', cmp, tb, '<UNIT>']\n",
    "        translate = ['<LETREC>', 'func', var, funcbody, ['<APP>', 'func', init]]\n",
    "        return translate\n",
    "    elif ls[0] == '<ASSIGN>':\n",
    "        return ['<LET>', ls[1], ls[2], '<UNIT>']\n",
    "    else:\n",
    "        return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index i Variable containing:\n",
      " 62\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "wordinputs beamsize*1 -1 [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "combined [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 62\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "index i Variable containing:\n",
      " 44\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "wordinputs beamsize*1 -1 [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "combined [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 62\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "index i Variable containing:\n",
      " 44\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "wordinputs beamsize*1 -1 [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "combined [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 62\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "index i Variable containing:\n",
      " 44\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "wordinputs beamsize*1 -1 [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "combined [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 101\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "index i Variable containing:\n",
      " 44\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "wordinputs beamsize*1 -1 [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "combined [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 14\n",
      "[torch.LongTensor of size 1x1]\n",
      "]\n",
      "[[Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 86\n",
      "[torch.LongTensor of size 1x1]\n",
      "], [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 101\n",
      "[torch.LongTensor of size 1x1]\n",
      "], [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 101\n",
      "[torch.LongTensor of size 1x1]\n",
      "], [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 101\n",
      "[torch.LongTensor of size 1x1]\n",
      "], [Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      ", Variable containing:\n",
      " 101\n",
      "[torch.LongTensor of size 1x1]\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Programs have more variables than are allowed for in the code, need to check how many \n",
    "\"\"\"\n",
    "for_prog_0 = makeTree(for_list_json[0])\n",
    "prediction = program_model.beam_search_prediction(for_prog_0)\n",
    "print(prediction)\n",
    "#for_trees = [makeTree(for_prog_json) for for_prog_json in for_list_json]\n",
    "#lambdaProgList = [translate_from_for(for_prog) for for_prog in for_list_json]\n",
    "#loss = Variable(torch.FloatTensor([0]))\n",
    "#for in_tree, out_seq, i in zip(input_trees, expected_output_seqs, range(input_trees)):\n",
    "#    loss += program_model.forward_train(in_tree, out_seq)\n",
    "#    loss.backwards()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
