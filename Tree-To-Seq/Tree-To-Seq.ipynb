{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Insert Useful Comments\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_children):\n",
    "        super(TreeCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Gates = input, output, memory + one forget gate per child\n",
    "        numGates = 3 + num_children\n",
    "        \n",
    "        self.gates = []\n",
    "        for _ in range(numGates):\n",
    "            # One linear layer to handle the value of the node\n",
    "            valueLinear = nn.Linear(input_size, hidden_size, bias = True)\n",
    "            childrenLinear = []\n",
    "            # One per child of the node\n",
    "            for _ in range(num_children):\n",
    "                childrenLinear.append(nn.Linear(hidden_size, hidden_size, bias = False))\n",
    "            self.gates.append((valueLinear, childrenLinear))\n",
    "            \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 2 hidden states.\n",
    "        :param cell_states: A list of 2 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_sums = []\n",
    "        for gate in self.gates:\n",
    "            data_sum = gate[0](input)\n",
    "            for i in range(len(hidden_states)):\n",
    "                data_sum += gate[1][i](hidden_states[i])\n",
    "            data_sums.append(data_sum)\n",
    "            \n",
    "        # First gate is the input gate\n",
    "        i = self.sigmoid(data_sums[0])\n",
    "        # Next output gate\n",
    "        o = self.sigmoid(data_sums[1])\n",
    "        # Next memory gate\n",
    "        m = self.tanh(data_sums[2])\n",
    "        # All the rest are forget gates\n",
    "        forget_data = 0\n",
    "        for i in range(len(cell_states)):\n",
    "            forget_data += data_sums[3 + i] * cell_states[i]\n",
    "        \n",
    "        # Put it all together!\n",
    "        new_state = i * m + forget_data\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "                \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrinaryCell(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Cell which takes in 3 hidden states and 3 cell states.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Initialize all the gates\n",
    "        \n",
    "        :param input_size: The length of the input vector.\n",
    "        :param hidden_size: The length of the hidden state/output vector\n",
    "        \"\"\"\n",
    "        super(TrinaryCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Key:\n",
    "        #   I = Input\n",
    "        #   L = Left\n",
    "        #   M = Middle\n",
    "        #   R = Right\n",
    "        \n",
    "        # Initialize all the gates\n",
    "        self.inputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.inputGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.inputGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.inputGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.leftForgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.leftForgetGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.leftForgetGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.leftForgetGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.middleForgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.middleForgetGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.middleForgetGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.middleForgetGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.rightForgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.rightForgetGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.rightForgetGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.rightForgetGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.outputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.outputGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.outputGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.outputGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.memoryGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.memoryGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.memoryGateM = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.memoryGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        # Functions we'll use later\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 3 hidden states.\n",
    "        :param cell_states: A list of 3 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        hiddenL = hidden_states[0]\n",
    "        hiddenM = hidden_states[1]\n",
    "        hiddenR = hidden_states[2]\n",
    "        \n",
    "        stateL = cell_states[0]\n",
    "        stateM = cell_states[1]\n",
    "        stateR = cell_states[2]\n",
    "        \n",
    "        # Don't you love all this copy-pasting?\n",
    "        i = self.sigmoid(self.inputGateI(input) + \n",
    "                         self.inputGateL(hiddenL) + \n",
    "                         self.inputGateM(hiddenM) + \n",
    "                         self.inputGateR(hiddenR))\n",
    "        \n",
    "        f_left = self.sigmoid(self.leftForgetGateI(input) + \n",
    "                         self.leftForgetGateL(hiddenL) + \n",
    "                         self.leftForgetGateM(hiddenM) + \n",
    "                         self.leftForgetGateR(hiddenR))\n",
    "        \n",
    "        f_middle = self.sigmoid(self.middleForgetGateI(input) + \n",
    "                         self.middleForgetGateL(hiddenL) + \n",
    "                         self.middleForgetGateM(hiddenM) + \n",
    "                         self.middleForgetGateR(hiddenR))\n",
    "        \n",
    "        f_right = self.sigmoid(self.rightForgetGateI(input) + \n",
    "                         self.rightForgetGateL(hiddenL) + \n",
    "                         self.rightForgetGateM(hiddenM) + \n",
    "                         self.rightForgetGateR(hiddenR))\n",
    "        \n",
    "        o = self.sigmoid(self.outputGateI(input) + \n",
    "                         self.outputGateL(hiddenL) + \n",
    "                         self.outputGateM(hiddenM) + \n",
    "                         self.outputGateR(hiddenR))\n",
    "        \n",
    "        c = self.tanh(self.memoryGateI(input) + \n",
    "                         self.memoryGateL(hiddenL) + \n",
    "                         self.memoryGateM(hiddenM) + \n",
    "                         self.memoryGateR(hiddenR))\n",
    "        \n",
    "        new_state = i * c + f_left * stateL + f_middle * stateM + f_right * stateR\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "        \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Literally the same as TrinaryCell but with 2 inputs\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Key:\n",
    "        #   I = Input\n",
    "        #   L = Left\n",
    "        #   R = Right\n",
    "        \n",
    "        # Initialize all the gates\n",
    "        self.inputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.inputGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.inputGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.leftForgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.leftForgetGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.leftForgetGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.rightForgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.rightForgetGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.rightForgetGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.outputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.outputGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.outputGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.memoryGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.memoryGateL = nn.Linear(hidden_size, hidden_size, bias = False)\n",
    "        self.memoryGateR = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 2 hidden states.\n",
    "        :param cell_states: A list of 2 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        hiddenL = hidden_states[0]\n",
    "        hiddenR = hidden_states[1]\n",
    "        \n",
    "        stateL = cell_states[0]\n",
    "        stateR = cell_states[1]\n",
    "        \n",
    "        i = self.sigmoid(self.inputGateI(input) + \n",
    "                         self.inputGateL(hiddenL) + \n",
    "                         self.inputGateR(hiddenR))\n",
    "        \n",
    "        f_left = self.sigmoid(self.leftForgetGateI(input) + \n",
    "                         self.leftForgetGateL(hiddenL) + \n",
    "                         self.leftForgetGateR(hiddenR))\n",
    "        \n",
    "        f_right = self.sigmoid(self.rightForgetGateI(input) + \n",
    "                         self.rightForgetGateL(hiddenL) + \n",
    "                         self.rightForgetGateR(hiddenR))\n",
    "        \n",
    "        o = self.sigmoid(self.outputGateI(input) + \n",
    "                         self.outputGateL(hiddenL) + \n",
    "                         self.outputGateR(hiddenR))\n",
    "        \n",
    "        c = self.tanh(self.memoryGateI(input) + \n",
    "                         self.memoryGateL(hiddenL) + \n",
    "                         self.memoryGateR(hiddenR))\n",
    "        \n",
    "        new_state = i * c + f_left * stateL + f_right * stateR\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "        \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnaryCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Literally the same as BinaryCell but with 1 inputs\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(UnaryCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Key:\n",
    "        #   I = Input\n",
    "        \n",
    "        # Initialize all the gates\n",
    "        self.inputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.inputGate = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.forgetGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.forgetGate = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.outputGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.outputGate = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.memoryGateI = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.memoryGate = nn.Linear(hidden_size, hidden_size, bias = True)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 2 hidden states.\n",
    "        :param cell_states: A list of 2 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = hidden_states[0]\n",
    "        state = cell_states[0]\n",
    "        \n",
    "        i = self.sigmoid(self.inputGateI(input) + \n",
    "                         self.inputGate(hidden))\n",
    "        \n",
    "        f = self.sigmoid(self.forgetGateI(input) + \n",
    "                         self.forgetGate(hidden))\n",
    "        \n",
    "        o = self.sigmoid(self.outputGateI(input) +  \n",
    "                         self.outputGate(hidden))\n",
    "        \n",
    "        c = self.tanh(self.memoryGateI(input) +  \n",
    "                      self.memoryGate(hidden))\n",
    "        \n",
    "        new_state = i * c + f * state\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "        \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encoder\n",
    "\n",
    "Takes in a Tree where each node has a value (vector?) and a list of children\n",
    "Produces a vector of desired size with an encoding of the tree\n",
    "\n",
    "Recursively: For each node go left *then go middle* then go right, pass the necessary values\n",
    "into an lstm cell along with values from each child (0 if at leaf) Output the result of the lstm cell\n",
    "at the root.\n",
    "\n",
    "'''\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in a tree where each node has a value vector and a list of children\n",
    "    Produces a sequence encoding of the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, valid_num_children):\n",
    "        \"\"\"\n",
    "        Initialize variables we'll need later.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.lstm_dict = {}\n",
    "        # We'll always need 0 for leaf nodes\n",
    "        self.lstm_dict[0] = TreeCell(input_size, hidden_size, 0)\n",
    "        \n",
    "        for size in valid_num_children:\n",
    "            self.lstm_dict[size] = TreeCell(input_size, hidden_size, size)\n",
    "\n",
    "        self.encoding = Variable(torch.FloatTensor(1, hidden_size))\n",
    "        \n",
    "    def forward(self, tree):\n",
    "        \"\"\"\n",
    "        Starts off the entire encoding process\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return self.encoding, a matrix where each row represents the encoded output of a single node\n",
    "        \"\"\"\n",
    "        embeddings = [p[0] for p in self.encode(tree)]\n",
    "        return torch.cat(embeddings, 0)\n",
    "        \n",
    "    def encode(self, node):\n",
    "        \"\"\"\n",
    "        Recursively a node and all its children as sequence vectors\n",
    "        \n",
    "        :param node: The root of the tree (or subtree)\n",
    "        :return A tuple (new hidden vector, new cell state).  The new hidden vector is an endoding of node\n",
    "        \"\"\"\n",
    "        \n",
    "        # List of tuples: (h, c), each of which are size hidden_size\n",
    "        descendents = []\n",
    "        children = []\n",
    "        \n",
    "        for child in node.children:\n",
    "            current_descendents = self.encode(child)\n",
    "            descendents += current_descendents\n",
    "            children.append(current_descendents[-1])\n",
    "        \n",
    "        if len(children) == 0:\n",
    "            children = [(Variable(torch.zeros(hidden_size)), \n",
    "                         Variable(torch.zeros(hidden_size))),\n",
    "                        (Variable(torch.zeros(hidden_size)), \n",
    "                         Variable(torch.zeros(hidden_size)))]\n",
    "\n",
    "        # Vector of size input_size x len(children)\n",
    "        inputH = [vec[0] for vec in children]\n",
    "        inputC = [vec[1] for vec in children]\n",
    "        value = Variable(node.value.unsqueeze(0))\n",
    "        \n",
    "        if len(children) in self.lstm_dict:\n",
    "            newH, newC = self.lstm_dict[len(children)](value, inputH, inputH)\n",
    "        else:\n",
    "            print(\"WHAAAAAT?\")\n",
    "            raise ValueError(\"Beware.  Something has gone horribly wrong.  You may not have long to live.\")\n",
    "            \n",
    "        # Add the new encoding to the end of our list\n",
    "        descendents.append((newH, newC))\n",
    "        return descendents\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 5\n",
    "\n",
    "test_vec = torch.FloatTensor(input_size)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node class just made for testing\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self. value = value\n",
    "        self.children = []\n",
    "    \n",
    "\n",
    "child_len = [2, 3, 2, 3]   \n",
    "def makeNodes(children):\n",
    "    \"\"\"\n",
    "    Loop through the passes-in array and build a tree where each node in the i^th layer has children[i] nodes\n",
    "\n",
    "    \"\"\"\n",
    "    if len(children) == 0:\n",
    "        return Node(test_vec) # Make them all the same vec\n",
    "    else: \n",
    "        newNode = Node(test_vec)\n",
    "        for i in range(children[0]):\n",
    "            newNode.children.append(makeNodes(children[1:]))\n",
    "        return newNode \n",
    "\n",
    "# kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jsonString = \"{\\\"tag\\\":\\\"If\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"GeFor\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":5},{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":3}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"X\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":1}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"Y\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":2}]}]}\"\n",
    "jsonObj = json.loads(jsonString)\n",
    "\n",
    "num_vars = 5\n",
    "num_ints = 7\n",
    "for_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"Assign\": 7,\n",
    "    \"If\": 8,\n",
    "    \"Seq\": 9,\n",
    "    \"For\": 10\n",
    "}\n",
    "var_dict = {}\n",
    "\n",
    "def vectorize(val):\n",
    "    vector = torch.zeros(num_vars + num_ints + len(for_ops.keys()))\n",
    "    if type(val) is int:\n",
    "        vector[val] = 1\n",
    "    elif type(val) is str:\n",
    "        index = len(var_dict.keys())\n",
    "        if val in var_dict:\n",
    "            index = var_dict[val]\n",
    "        else:\n",
    "            var_dict[val] = index\n",
    "        vector[index + num_ints] = 1\n",
    "    else:\n",
    "        index = for_ops[val]\n",
    "        vector[num_ints + num_vars + index] = 1\n",
    "    return vector\n",
    "            \n",
    "        \n",
    "\n",
    "def makeTree(json):\n",
    "    if type(json) is str:\n",
    "        parentNode = Node(vectorize(\"Var\"))\n",
    "        childNode = Node(vectorize(json))\n",
    "        parentNode.children.append(childNode)\n",
    "        return parentNode \n",
    "    \n",
    "    if type(json) is int:\n",
    "        return Node(vectorize(json))\n",
    "\n",
    "    tag = json[\"tag\"]\n",
    "    children = json[\"contents\"]\n",
    "    parentNode = Node(vectorize(tag))\n",
    "    \n",
    "    currNode = parentNode\n",
    "    \n",
    "    if type(children) is list:\n",
    "        for child in children:\n",
    "            newChild = makeTree(child)\n",
    "            currNode.children.append(newChild)\n",
    "            currNode = newChild\n",
    "    else:\n",
    "        parentNode.children.append(makeTree(children))\n",
    "        \n",
    "    return parentNode\n",
    "\n",
    "\n",
    "\n",
    "def printTree(tree):\n",
    "    print(tree.value)\n",
    "    for child in tree.children:\n",
    "        printTree(child)\n",
    "    \n",
    "    \n",
    "tree = makeTree(jsonObj)\n",
    "\n",
    "encoder = Encoder(num_vars + num_ints + len(for_ops.keys()), hidden_size, [1,2,3])\n",
    "encoded_vec = encoder(tree)\n",
    "print(\"ENCODEDVEC\", encoded_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "class Tree_to_Sequence_Model(nn.Module):\n",
    "    \"\"\"\n",
    "      For the decoder this expects something like an lstm cell or a gru cell and not an lstm/gru.\n",
    "      If you don't use teacher forcing, batches are forbidden/lead to bad behavior\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 decoder_cell_state_shape=None, use_lstm=False, use_cuda=True):\n",
    "        super(Tree_to_Sequence_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        #nclass + 2 to include end of sequence and trash\n",
    "        self.output_log_probs = nn.Linear(hidden_size, nclass+2)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        self.SOS_token = Variable(torch.LongTensor([[0]]))\n",
    "        self.EOS_value = 1\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.SOS_token = self.SOS_token.cuda()\n",
    "\n",
    "        self.embedding = nn.Embedding(nclass, embedding_size)\n",
    "\n",
    "        self.use_lstm = use_lstm\n",
    "        #nclass + 1 is the trash category to avoid penalties after target's EOS token\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=nclass+1)\n",
    "\n",
    "        if use_lstm:\n",
    "            self.decoder_initial_cell_state = torch.zeros(decoder_initial_cell_state)\n",
    "\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        # encoded features\n",
    "        encoded_features = self.encoder(input) # [w, c]\n",
    "        decoder_hidden = encoded_features[-1, :]\n",
    "\n",
    "        target_length = target.size()\n",
    "        decoder_input = self.embedding(self.SOS_token).transpose(0,1).repeat(1, batch_size, 1)\n",
    "        loss = 0\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(target_length):\n",
    "            if self.use_lstm:\n",
    "                decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            log_probs = self.output_log_probs(decoder_output)\n",
    "            loss += self.loss_func(log_probs, target[i, :])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = self.embedding(target[i, :].unsqueeze(1)).squeeze(1)\n",
    "            else:\n",
    "                _, topi = log_probs.data.topk(1)\n",
    "                ni = topi[0, 0]\n",
    "\n",
    "                if ni == self.EOS_value:\n",
    "                    break\n",
    "\n",
    "                decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                if self.use_cuda:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    \"\"\"\n",
    "      Inputs must be of batch size 1\n",
    "    \"\"\"\n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "      # encoded features\n",
    "      encoded_features = self.encoder(input).squeeze(1) # [w, c]\n",
    "      decoder_hidden = encoded_features[-1, :]\n",
    "      decoder_input = self.embedding(self.SOS_token).squeeze(0)\n",
    "      output_so_far = []\n",
    "\n",
    "      if self.use_lstm:\n",
    "          decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "      for i in range(maximum_length):\n",
    "          if self.use_lstm:\n",
    "              decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "          else:\n",
    "              decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "          log_probs = self.output_log_probs(decoder_output)\n",
    "\n",
    "          _, topi = log_probs.data.topk(1)\n",
    "          ni = topi[0, 0]\n",
    "\n",
    "          if ni == self.EOS_value:\n",
    "              break\n",
    "\n",
    "          output_so_far.append(ni)\n",
    "          decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "          if self.use_cuda:\n",
    "              decoder_input = decoder_input.cuda()\n",
    "\n",
    "      return output_so_far\n",
    "\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20):\n",
    "      pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_Model(Tree_to_Sequence_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 alignment_size, decoder_cell_state_shape=None, use_lstm=False):\n",
    "        super(Sequence_to_Sequence_Attention_Model, self).__init__(encoder, decoder, hidden_size, nclass,\n",
    "                                                                   decoder_cell_state_shape=decoder_cell_state_shape,\n",
    "                                                                   use_lstm=use_lstm)\n",
    "\n",
    "        self.attention_hidden = nn.Linear(hidden_size, alignment_size)\n",
    "        self.attention_context = nn.Linear(hidden_size, alignment_size, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attention_alignment_vector = nn.Linear(encoded_size, 1)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the input should have dimensions, (seq_len x batch_size x input_size)\n",
    "        target: The target should have dimensions, (seq_len x batch_size), and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        # Think about what the dimensions should be in your case. Some of this code assumes batches are present.\n",
    "        encoded_features = self.encoder(input) # [w, c]\n",
    "\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hidden = encoded_features[0, hidden_size//2:] # This needs to be tweaked to corresponded to the root.\n",
    "        target_length, batch_size = target.size()\n",
    "        word_input = self.embedding(self.SOS_token)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(target_length):\n",
    "          attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden).unsqueeze(1)  + attention_hidden_values).squeeze(2)\n",
    "          attention_probs = self.softmax(attention_logits, 1) # B x W\n",
    "          context_vec = (attention_probs.unsqueeze(2) * encoded_features).sum(1) # B x C\n",
    "          decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "          if self.use_lstm:\n",
    "            decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "          else:\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "          log_probs = self.output_log_probs(decoder_output)\n",
    "          loss += self.loss_func(log_probs, target[i, :])\n",
    "\n",
    "          if use_teacher_forcing:\n",
    "            word_input = self.embedding(target[i, :].unsqueeze(1)).squeeze(1)\n",
    "          else:\n",
    "            _, topi = log_probs.data.topk(1)\n",
    "            ni = topi[0, 0]\n",
    "\n",
    "            if ni == self.EOS_value:\n",
    "              break\n",
    "\n",
    "            word_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            if self.use_cuda:\n",
    "              word_input = word_input.cuda()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "      Inputs must be of batch size 1\n",
    "    \"\"\"\n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "      # encoded features\n",
    "      encoded_features = self.encoder(input).squeeze(1) # [w, c]\n",
    "      attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "      decoder_hidden = encoded_features[0, hidden_size//2:].unsqueeze(0) # This needs to be tweaked to corresponded to the root.\n",
    "      word_input = self.embedding(self.SOS_token).squeeze(0)\n",
    "      output_so_far = []\n",
    "\n",
    "      if self.use_lstm:\n",
    "          decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "      for i in range(maximum_length):\n",
    "          attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "          attention_probs = self.softmax(attention_logits, 0) # W\n",
    "          context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0) # C\n",
    "          decoder_input = torch.cat((word_input, context_vec.unsqueeze(0)), dim=1)\n",
    "\n",
    "          if self.use_lstm:\n",
    "              decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "          else:\n",
    "              decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "          log_probs = self.output_log_probs(decoder_output)\n",
    "\n",
    "          _, topi = log_probs.data.topk(1)\n",
    "          ni = topi[0, 0]\n",
    "\n",
    "          if ni == self.EOS_value:\n",
    "              break\n",
    "\n",
    "          output_so_far.append(ni)\n",
    "          word_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "          if self.use_cuda:\n",
    "              word_input = word_input.cuda()\n",
    "\n",
    "      return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        \n",
    "        encoded_features = self.encoder(input).squeeze(1)  # [w, c]\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hidden = encoded_features[0, hidden_size // 2:].unsqueeze(\n",
    "            0)  # This needs to be tweaked to corresponded to the root.\n",
    "        word_inputs = [[0, self.embedding(self.SOS_token).squeeze(0)] for x in range(max_beam_width)]\n",
    "        output_so_far = []\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(maximum_length):\n",
    "            attention_logits = self.attention_alignment_vector(\n",
    "                self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits, 0)  # W\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0)  # C\n",
    "            newWordInputs = []\n",
    "            for i in range(beam_width):\n",
    "                word_input = word_inputs[i][1]\n",
    "                decoder_input = torch.cat((word_input, context_vec.unsqueeze(0)), dim=1)\n",
    "\n",
    "                if self.use_lstm:\n",
    "                    decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (\n",
    "                    decoder_hidden, decoder_cell_state))\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                log_probs = self.output_log_probs(decoder_output)\n",
    "\n",
    "                topk = log_probs.data.topk(beam_width)\n",
    "                newWordInputs.append([topk[i][1] + word_inputs[i][0], topk[i][0]] for i in range(beam_width))\n",
    "                \n",
    "            #Get the new top 5 words\n",
    "            ni = sorted(newWordInputs, key=lambda word_pair: word_pair[0])[:5]\n",
    "\n",
    "            word_inputs = [self.embedding(Variable([ni[i][1]]).unsqueeze(1)).squeeze(1) for i in range(beam_width)]\n",
    "\n",
    "\n",
    "            if self.use_cuda:\n",
    "                word_input = word_input.cuda()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}