{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TreeCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Insert Useful Comments\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_children):\n",
    "        super(TreeCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Gates = input, output, memory + one forget gate per child\n",
    "        numGates = 3 + num_children\n",
    "        \n",
    "        self.gates = []\n",
    "        for _ in range(numGates):\n",
    "            # One linear layer to handle the value of the node\n",
    "            valueLinear = nn.Linear(input_size, hidden_size, bias = True)\n",
    "            childrenLinear = []\n",
    "            # One per child of the node\n",
    "            for _ in range(num_children):\n",
    "                childrenLinear.append(nn.Linear(hidden_size, hidden_size, bias = False))\n",
    "            self.gates.append((valueLinear, childrenLinear))\n",
    "            \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of 2 hidden states.\n",
    "        :param cell_states: A list of 2 cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_sums = []\n",
    "        for gate in self.gates:\n",
    "            data_sum = gate[0](input)\n",
    "            for i in range(len(hidden_states)):\n",
    "                data_sum += gate[1][i](hidden_states[i])\n",
    "            data_sums.append(data_sum)\n",
    "            \n",
    "        # First gate is the input gate\n",
    "        i = self.sigmoid(data_sums[0])\n",
    "        # Next output gate\n",
    "        o = self.sigmoid(data_sums[1])\n",
    "        # Next memory gate\n",
    "        m = self.tanh(data_sums[2])\n",
    "        # All the rest are forget gates\n",
    "        forget_data = 0\n",
    "        for i in range(len(cell_states)):\n",
    "            forget_data += data_sums[3 + i] * cell_states[i]\n",
    "        \n",
    "        # Put it all together!\n",
    "        new_state = i * m + forget_data\n",
    "        new_hidden = o * self.tanh(new_state)\n",
    "                \n",
    "        return new_hidden, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Encoder\n",
    "\n",
    "Takes in a Tree where each node has a value (vector?) and a list of children\n",
    "Produces a vector of desired size with an encoding of the tree\n",
    "\n",
    "Recursively: For each node go left *then go middle* then go right, pass the necessary values\n",
    "into an lstm cell along with values from each child (0 if at leaf) Output the result of the lstm cell\n",
    "at the root.\n",
    "\n",
    "'''\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in a tree where each node has a value vector and a list of children\n",
    "    Produces a sequence encoding of the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, valid_num_children):\n",
    "        \"\"\"\n",
    "        Initialize variables we'll need later.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.lstm_dict = {}\n",
    "        # We'll always need 0 for leaf nodes\n",
    "        self.lstm_dict[0] = TreeCell(input_size, hidden_size, 0)\n",
    "        \n",
    "        for size in valid_num_children:\n",
    "            self.lstm_dict[size] = TreeCell(input_size, hidden_size, size)\n",
    "\n",
    "        self.encoding = Variable(torch.FloatTensor(1, hidden_size))\n",
    "        \n",
    "    def forward(self, tree):\n",
    "        \"\"\"\n",
    "        Starts off the entire encoding process\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return self.encoding, a matrix where each row represents the encoded output of a single node\n",
    "        \"\"\"\n",
    "        embeddings = [p[0] for p in self.encode(tree)]\n",
    "        return torch.cat(embeddings, 0)\n",
    "        \n",
    "    def encode(self, node):\n",
    "        \"\"\"\n",
    "        Recursively a node and all its children as sequence vectors\n",
    "        \n",
    "        :param node: The root of the tree (or subtree)\n",
    "        :return A tuple (new hidden vector, new cell state).  The new hidden vector is an endoding of node\n",
    "        \"\"\"\n",
    "        \n",
    "        # List of tuples: (h, c), each of which are size hidden_size\n",
    "        descendents = []\n",
    "        children = []\n",
    "        \n",
    "        for child in node.children:\n",
    "            current_descendents = self.encode(child)\n",
    "            descendents += current_descendents\n",
    "            children.append(current_descendents[-1])\n",
    "        \n",
    "        if len(children) == 0:\n",
    "            children = [(Variable(torch.zeros(hidden_size)), \n",
    "                         Variable(torch.zeros(hidden_size))),\n",
    "                        (Variable(torch.zeros(hidden_size)), \n",
    "                         Variable(torch.zeros(hidden_size)))]\n",
    "\n",
    "        # Vector of size input_size x len(children)\n",
    "        inputH = [vec[0] for vec in children]\n",
    "        inputC = [vec[1] for vec in children]\n",
    "        value = Variable(node.value.unsqueeze(0))\n",
    "        \n",
    "        if len(children) in self.lstm_dict:\n",
    "            newH, newC = self.lstm_dict[len(children)](value, inputH, inputH)\n",
    "        else:\n",
    "            print(\"WHAAAAAT?\")\n",
    "            raise ValueError(\"Beware.  Something has gone horribly wrong.  You may not have long to live.\")\n",
    "            \n",
    "        # Add the new encoding to the end of our list\n",
    "        descendents.append((newH, newC))\n",
    "        return descendents\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 5\n",
    "\n",
    "test_vec = torch.FloatTensor(input_size)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node class just made for testing\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self. value = value\n",
    "        self.children = []\n",
    "    \n",
    "\n",
    "child_len = [2, 3, 2, 3]   \n",
    "def makeNodes(children):\n",
    "    \"\"\"\n",
    "    Loop through the passes-in array and build a tree where each node in the i^th layer has children[i] nodes\n",
    "\n",
    "    \"\"\"\n",
    "    if len(children) == 0:\n",
    "        return Node(test_vec) # Make them all the same vec\n",
    "    else: \n",
    "        newNode = Node(test_vec)\n",
    "        for i in range(children[0]):\n",
    "            newNode.children.append(makeNodes(children[1:]))\n",
    "        return newNode \n",
    "\n",
    "# kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODEDVEC Variable containing:\n",
      "-0.1848 -0.1053 -0.0355  0.1507 -0.1044\n",
      "-0.1122  0.0519  0.0023  0.0359 -0.0757\n",
      "-0.0019 -0.0054 -0.0002  0.0056  0.0031\n",
      "-0.1563 -0.0816  0.1100  0.0366 -0.1411\n",
      " 0.0171 -0.0734 -0.0908  0.1049 -0.0942\n",
      "-0.1143 -0.0007 -0.0205  0.1564 -0.0322\n",
      "-0.0015  0.0000  0.0013  0.0238  0.0020\n",
      " 0.0143 -0.0174  0.0287 -0.0242 -0.1128\n",
      "-0.0374  0.0431  0.0504  0.1268 -0.0165\n",
      " 0.0061  0.0125 -0.0981  0.0004 -0.0423\n",
      " 0.0003 -0.0011  0.0067  0.0001  0.0032\n",
      " 0.0378 -0.0081  0.0136 -0.0122 -0.0980\n",
      " 0.0046  0.0006 -0.0003  0.0001 -0.0142\n",
      "-0.1192  0.0708  0.0547  0.0690 -0.0552\n",
      "-0.0811 -0.0181  0.0213  0.1985  0.0102\n",
      "-0.0010  0.0004  0.0006  0.0300  0.0009\n",
      "[torch.FloatTensor of size 16x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonString = \"{\\\"tag\\\":\\\"If\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"GeFor\\\",\\\"contents\\\":[{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":5},{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":3}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"X\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":1}]},{\\\"tag\\\":\\\"Assign\\\",\\\"contents\\\":[\\\"Y\\\",{\\\"tag\\\":\\\"Const\\\",\\\"contents\\\":2}]}]}\"\n",
    "jsonObj = json.loads(jsonString)\n",
    "\n",
    "num_vars = 5\n",
    "num_ints = 7\n",
    "for_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"Assign\": 7,\n",
    "    \"If\": 8,\n",
    "    \"Seq\": 9,\n",
    "    \"For\": 10\n",
    "}\n",
    "var_dict = {}\n",
    "\n",
    "def vectorize(val):\n",
    "    vector = torch.zeros(num_vars + num_ints + len(for_ops.keys()))\n",
    "    if type(val) is int:\n",
    "        vector[val] = 1\n",
    "    elif type(val) is str:\n",
    "        index = len(var_dict.keys())\n",
    "        if val in var_dict:\n",
    "            index = var_dict[val]\n",
    "        else:\n",
    "            var_dict[val] = index\n",
    "        vector[index + num_ints] = 1\n",
    "    else:\n",
    "        index = for_ops[val]\n",
    "        vector[num_ints + num_vars + index] = 1\n",
    "    return vector\n",
    "            \n",
    "        \n",
    "\n",
    "def makeTree(json):\n",
    "    if type(json) is str:\n",
    "        parentNode = Node(vectorize(\"Var\"))\n",
    "        childNode = Node(vectorize(json))\n",
    "        parentNode.children.append(childNode)\n",
    "        return parentNode \n",
    "    \n",
    "    if type(json) is int:\n",
    "        return Node(vectorize(json))\n",
    "\n",
    "    tag = json[\"tag\"]\n",
    "    children = json[\"contents\"]\n",
    "    parentNode = Node(vectorize(tag))\n",
    "    \n",
    "    currNode = parentNode\n",
    "    \n",
    "    if type(children) is list:\n",
    "        for child in children:\n",
    "            newChild = makeTree(child)\n",
    "            currNode.children.append(newChild)\n",
    "            currNode = newChild\n",
    "    else:\n",
    "        parentNode.children.append(makeTree(children))\n",
    "        \n",
    "    return parentNode\n",
    "\n",
    "\n",
    "\n",
    "def printTree(tree):\n",
    "    print(tree.value)\n",
    "    for child in tree.children:\n",
    "        printTree(child)\n",
    "    \n",
    "    \n",
    "tree = makeTree(jsonObj)\n",
    "\n",
    "encoder = Encoder(num_vars + num_ints + len(for_ops.keys()), hidden_size, [1,2,3])\n",
    "encoded_vec = encoder(tree)\n",
    "print(\"ENCODEDVEC\", encoded_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "'''\n",
    "class Tree_to_Sequence_Model(nn.Module):\n",
    "    \"\"\"\n",
    "      For the decoder this expects something like an lstm cell or a gru cell and not an lstm/gru.\n",
    "      If you don't use teacher forcing, batches are forbidden/lead to bad behavior\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 use_lstm=False, use_cuda=True):\n",
    "        super(Tree_to_Sequence_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # nclass + 2 to include end of sequence and trash\n",
    "        self.output_log_probs = nn.Linear(hidden_size, nclass+2)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        self.SOS_token = Variable(torch.LongTensor([[0]]))\n",
    "        self.EOS_value = 1\n",
    "\n",
    "        if use_cuda:\n",
    "            self.SOS_token = self.SOS_token.cuda()\n",
    "\n",
    "        self.embedding = nn.Embedding(nclass, embedding_size)\n",
    "\n",
    "        self.use_lstm = use_lstm\n",
    "        # nclass + 1 is the trash category to avoid penalties after target's EOS token\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=nclass+1)\n",
    "\n",
    "        if use_lstm:\n",
    "            self.decoder_initial_cell_state = torch.zeros(1, hidden_size)\n",
    "\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        # encoded features\n",
    "        encoded_features = self.encoder(input) # [w, c]\n",
    "        decoder_hidden = encoded_features[-1, :]\n",
    "\n",
    "        target_length = target.size()[0]\n",
    "        decoder_input = self.embedding(self.SOS_token).transpose(0,1).repeat(1, batch_size, 1)\n",
    "        loss = 0\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(target_length):\n",
    "            if self.use_lstm:\n",
    "                decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            log_probs = self.output_log_probs(decoder_output)\n",
    "            loss += self.loss_func(log_probs, target[i, :])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = self.embedding(target[i, :].unsqueeze(1)).squeeze(1)\n",
    "            else:\n",
    "                _, topi = log_probs.data.topk(1)\n",
    "                ni = topi[0, 0]\n",
    "\n",
    "                if ni == self.EOS_value:\n",
    "                    break\n",
    "\n",
    "                decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "#     \"\"\"\n",
    "#       Inputs must be of batch size 1\n",
    "#     \"\"\"\n",
    "#     def point_wise_prediction(self, input, maximum_length=20):\n",
    "#       # encoded features\n",
    "#       encoded_features = self.encoder(input).squeeze(1) # [w, c]\n",
    "#       decoder_hidden = encoded_features[-1, :]\n",
    "#       decoder_input = self.embedding(self.SOS_token).squeeze(0)\n",
    "#       output_so_far = []\n",
    "\n",
    "#       if self.use_lstm:\n",
    "#           decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "#       for i in range(maximum_length):\n",
    "#           if self.use_lstm:\n",
    "#               decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "#           else:\n",
    "#               decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "#           log_probs = self.output_log_probs(decoder_output)\n",
    "\n",
    "#           _, topi = log_probs.data.topk(1)\n",
    "#           ni = topi[0, 0]\n",
    "\n",
    "#           if ni == self.EOS_value:\n",
    "#               break\n",
    "\n",
    "#           output_so_far.append(ni)\n",
    "#           decoder_input = self.embedding(Variable([ni]).unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#           if self.use_cuda:\n",
    "#               decoder_input = decoder_input.cuda()\n",
    "\n",
    "#       return output_so_far\n",
    "\n",
    "\n",
    "#     def beam_search_prediction(self, input, maximum_length=20):\n",
    "#       pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_Model(Tree_to_Sequence_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 alignment_size, decoder_cell_state_shape=None, use_lstm=False, use_cuda=True):\n",
    "        super(Tree_to_Sequence_Attention_Model, self).__init__(encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                                                               use_lstm=use_lstm, use_cuda=use_cuda)\n",
    "        self.attention_hidden = nn.Linear(hidden_size, alignment_size)\n",
    "        self.attention_context = nn.Linear(hidden_size, alignment_size, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attention_alignment_vector = nn.Linear(alignment_size, 1)\n",
    "\n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the input should have dimensions, (seq_len x batch_size x input_size)\n",
    "        target: The target should have dimensions, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, use_teacher_forcing=False):\n",
    "        encoded_features = self.encoder(input) # sequence x encoder hidden\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hidden = encoded_features[-1, :].unsqueeze(0)\n",
    "        target_length = target.size()[0] # sequence x decoder hidden\n",
    "        word_input = self.embedding(self.SOS_token).squeeze(0) # batch x decoder hidden\n",
    "\n",
    "        loss = 0\n",
    "        \n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(target_length):\n",
    "            self.attention_context(decoder_hidden)\n",
    "            self.attention_context(decoder_hidden) + attention_hidden_values\n",
    "            self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values)\n",
    "            \n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # decoder hidden \n",
    "            decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "            if self.use_lstm:\n",
    "                print('i')\n",
    "                print(decoder_input)\n",
    "                \n",
    "                print('h')\n",
    "                print(decoder_hidden)\n",
    "                \n",
    "                print('c')\n",
    "                print(decoder_cell_state)\n",
    "                \n",
    "                decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            log_probs = self.output_log_probs(decoder_output)\n",
    "            loss += self.loss_func(log_probs, target[i])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(0)\n",
    "            else:\n",
    "                _, next_input = log_probs.topk(1)\n",
    "\n",
    "                if next_input[0, 0] == self.EOS_value:\n",
    "                    break\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(0) # batch x decoder hidden\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "      Inputs must be of batch size 1\n",
    "    \"\"\"\n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "        # encoded features\n",
    "        encoded_features = self.encoder(input) # sequence x hidden\n",
    "        print(encoded_features)\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hidden = encoded_features[-1, :].unsqueeze(0)\n",
    "        word_input = self.embedding(self.SOS_token).squeeze(0) # batch x hidden\n",
    "        output_so_far = []\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(maximum_length):\n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # hidden \n",
    "            decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "            if self.use_lstm:\n",
    "                decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            log_probs = self.output_log_probs(decoder_output)\n",
    "            _, next_input = log_probs.topk(1)\n",
    "            \n",
    "            output_so_far.append(next_input[0][0])\n",
    "            \n",
    "            if next_input[0, 0] == self.EOS_value:\n",
    "                break\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(0) # batch x hidden\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        # encoded features\n",
    "        encoded_features = self.encoder(input) # sequence x hidden\n",
    "        attention_hidden_values = self.attention_hidden(encoded_features)\n",
    "\n",
    "        decoder_hidden = encoded_features[-1, :].unsqueeze(0)\n",
    "        word_inputs = [(0, [self.SOS_token], True) for _ in range(max_beam_width)]\n",
    "\n",
    "        if self.use_lstm:\n",
    "            decoder_cell_state = self.decoder_initial_cell_state\n",
    "\n",
    "        for i in range(maximum_length):\n",
    "            attention_logits = self.attention_alignment_vector(self.attention_context(decoder_hidden) + attention_hidden_values).squeeze(1)\n",
    "            attention_probs = self.softmax(attention_logits) # w\n",
    "            context_vec = (attention_probs.unsqueeze(1) * encoded_features).sum(0).unsqueeze(0) # hidden \n",
    "            \n",
    "            newWordInputs = []\n",
    "            \n",
    "            for i in range(beam_width):                \n",
    "                if not word_inputs[i][2]:\n",
    "                    newWordInputs.append(word_inputs[i])\n",
    "                    continue\n",
    "                    \n",
    "                word_input = self.embedding(word_inputs[i][1][-1]).squeeze(0)\n",
    "                decoder_input = torch.cat((word_input, context_vec), dim=1)\n",
    "\n",
    "                if self.use_lstm:\n",
    "                    decoder_output, (decoder_hidden, decoder_cell_state) = self.decoder(decoder_input, (decoder_hidden, decoder_cell_state))\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                log_probs = self.output_log_probs(decoder_output).squeeze(0)\n",
    "                value, index = self.softmax(log_probs).topk(beam_width)\n",
    "                log_value = value.log()\n",
    "                \n",
    "                newWordInputs.extend((word_inputs[i][0] + log_value[i], word_inputs[i][1].append(index[i]), \n",
    "                                      index[i,0] == self.EOS_Value) for i in range(beam_width))\n",
    "                \n",
    "            #Get the new words in the beam.\n",
    "            word_inputs = sorted(newWordInputs, key=lambda word_pair: word_pair[0])[-beam_width:]\n",
    "\n",
    "        outputs = [word_inputs[i][1][0][0] for i in range(beam_width)]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "hidden_size = 5\n",
    "nclass = 100\n",
    "alignment_size = 30\n",
    "\n",
    "decoder = nn.LSTMCell(embedding_size + hidden_size, 5)\n",
    "program_model = Tree_to_Sequence_Attention_Model(encoder, decoder, hidden_size, nclass, embedding_size, alignment_size, use_lstm=True,\n",
    "                                                 use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.2146 -0.4223  0.2160 -0.4057 -0.5137 -1.2001  0.0252  1.5605  0.9259  1.0601\n",
      "\n",
      "Columns 10 to 19 \n",
      " 0.9424 -0.0404  0.9510 -0.7113  1.3665 -0.5405  0.7011  1.1401  1.1159  0.3539\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.5552 -1.6007  0.2998 -0.2021  2.2639  0.8223  1.2482 -1.0407 -0.1205 -0.7811\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.8677  0.6044 -1.1734  0.6653  0.8041 -0.0141 -0.1219  0.5598  0.7022  1.0724\n",
      "\n",
      "Columns 40 to 49 \n",
      "-1.3424  0.0706  1.6218  0.7883 -0.1021  1.6576 -0.3728  0.6833  1.9102  1.0823\n",
      "\n",
      "Columns 50 to 54 \n",
      "-0.0448 -0.0084  0.0022  0.0558 -0.0479\n",
      "[torch.FloatTensor of size 1x55]\n",
      "\n",
      "h\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.0959  0.0376  0.0615  2.9981  0.0860\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n",
      "c\n",
      "\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mul() received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:\n * (float other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (Variable other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-153f073e0b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogram_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-7101e90e2cb3>\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, input, target, use_teacher_forcing)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         )\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mul() received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:\n * (float other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (Variable other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "loss = program_model.forward_train(tree, Variable(torch.LongTensor([1,2,3,4,5,6,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
