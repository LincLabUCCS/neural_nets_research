{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from six import string_types\n",
    "from translating_trees import Node\n",
    "from translating_trees import pretty_print_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_out_csharp(json_lists):\n",
    "#     print(len(json_lists))\n",
    "    all_tokens = set()\n",
    "    children = {}\n",
    "    parents = {}\n",
    "    max_vars = 0\n",
    "    max_consts = 0\n",
    "    max_chars = 0\n",
    "    max_strings = 0\n",
    "    \n",
    "    def tally_tokens(prog, parent=None):\n",
    "        all_vars = set()\n",
    "        all_consts = set()\n",
    "        all_chars = set()\n",
    "        all_strings = set()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ugly special cases\n",
    "        if parent == \"ArgumentList\" and type(prog) == type(\"\") and prog[0] == \"(\" and prog[-1] == \")\":\n",
    "            root_val = \"()\"\n",
    "          \n",
    "        if type(prog) == type(\"\") or type(prog) == type(1): #TODO: is this second case necesary?\n",
    "            # Add to parents\n",
    "            if prog in parents:\n",
    "                parents[prog].add(parent)\n",
    "            else:\n",
    "                parents[prog] = set([parent])\n",
    "                \n",
    "            return all_vars, all_consts, all_chars, all_strings\n",
    "        \n",
    "        for key in prog.keys():\n",
    "             \n",
    "            root_val = key\n",
    "            \n",
    "            if not type(root_val) == type(\"\"):\n",
    "                print(\"AAAAAAA\")\n",
    "\n",
    "            all_tokens.add(root_val)\n",
    "            # Add to parents\n",
    "            if root_val in parents:\n",
    "                parents[root_val].add(parent)\n",
    "            else:\n",
    "                parents[root_val] = set([parent])\n",
    "            # Add to children\n",
    "            if parent in children:\n",
    "                children[parent].add(root_val)\n",
    "            else:\n",
    "                children[parent] = set([root_val])\n",
    "                \n",
    "            if root_val == \"IdentifierName\":\n",
    "                all_vars.add(prog[key])\n",
    "            elif root_val == \"NumericLiteralExpression\":\n",
    "                all_consts.add(prog[key])\n",
    "            elif root_val == \"CharacterLiteralExpression\":\n",
    "                all_chars.add(prog[key])\n",
    "            elif root_val == \"StringLiteralExpression\":\n",
    "                all_strings.add(prog[key])\n",
    "            elif root_val == \"VariableDeclarator\" and type(prog[key]) == type(\"\"):\n",
    "                all_vars.add(prog[key])\n",
    "            else:\n",
    "                child_keys = []\n",
    "                \n",
    "                if type(prog[key]) == type([]):\n",
    "                    for child in prog[key]:\n",
    "                        for child_key in child.keys():\n",
    "                            child_keys.append((child_key, child))\n",
    "                elif type(prog[key]) == type(\"\"):\n",
    "                    child_keys.append((prog[key], prog[key]))\n",
    "                else:\n",
    "                    print(\"something weird is going on\", prog)\n",
    "                \n",
    "                # Add to children\n",
    "                for c in child_keys:\n",
    "                    child_key, child = c\n",
    "                            \n",
    "                    child_vars, child_consts, child_chars, child_strings = tally_tokens(child, root_val)\n",
    "                    all_vars |= child_vars\n",
    "                    all_consts |= child_consts\n",
    "                    all_chars |= child_chars\n",
    "                    all_strings |= child_strings\n",
    "                    \n",
    "            return all_vars, all_consts, all_chars, all_strings\n",
    "    \n",
    "    i = 0\n",
    "    for json_list in json_lists:\n",
    "        print(\"new list\")\n",
    "        for prog in json_list:\n",
    "            i += 1\n",
    "            all_vars, all_consts, all_chars, all_strings = tally_tokens(prog)\n",
    "            max_vars = max(max_vars, len(all_vars))\n",
    "            max_consts = max(max_consts, len(all_consts))\n",
    "            max_chars = max(max_chars, len(all_chars))\n",
    "            max_strings = max(max_strings, len(all_strings))\n",
    "#             if len(all_strings) > 1000:\n",
    "#                 print(\"UH OH ON\", i)\n",
    "#                 print(all_consts)\n",
    "#                 print(all_strings)\n",
    "#                 print(\"======\")\n",
    "#                 print(prog)\n",
    "                \n",
    "#     print(all_tokens)\n",
    "#     print(children)\n",
    "#     print(parents)\n",
    "#     print(max_vars)\n",
    "#     print(max_consts)\n",
    "#     print(max_chars)\n",
    "#     print(max_strings)\n",
    "    return all_tokens, children, parents, max_vars, max_consts, max_chars, max_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_tokens, children, parents, max_vars, max_consts, max_chars, max_strings = figure_out_csharp(json_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(folder, suffix):\n",
    "    matching_files = []\n",
    "    for path, dirs, files in os.walk(folder):\n",
    "        for name in files:\n",
    "            if name[-len(suffix):] == suffix:\n",
    "                matching_files.append(name)\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haskell_voodoo():\n",
    "    files = get_files(\"filtered_data\", \"cs.txt\")\n",
    "    os.system(\"mkdir jsonified\")\n",
    "    os.system(\"ghc CleanCSharpData.hs -main-is CleanCSharpData.main -o CleanCSharpData;\")\n",
    "    for file in files:\n",
    "        os.system(\"./CleanCSharpData filtered_data/{} > jsonified/{}\".format(file, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the C# datasets\n",
    "def load_data(folder, extension):\n",
    "    all_files = get_files(folder, extension)\n",
    "\n",
    "    i = 0\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    json_lists = []\n",
    "    for file in all_files:\n",
    "        print(\"processing file\", file)\n",
    "        j_list = []\n",
    "        with open(folder + \"/\" + file) as f:\n",
    "            lines = f.readlines()\n",
    "            print(len(lines))\n",
    "            for line in lines:\n",
    "                total_count += 1\n",
    "                try:\n",
    "                    prog = json.loads(line)\n",
    "                    correct_count += 1\n",
    "                    if not prog == []:\n",
    "                        j_list.append(prog)\n",
    "                except:\n",
    "                    pass\n",
    "                i += 1\n",
    "        json_lists.append(j_list)\n",
    "            \n",
    "    print(\"TOTAL:\", total_count)\n",
    "    print(\"CORRECT:\", correct_count)\n",
    "    print(correct_count/total_count)\n",
    "    return json_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haskell_voodoo()\n",
    "# all_tokens, children, parents, max_vars, max_consts, max_chars, max_strings = figure_out_csharp(json_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blatantly copied from ProgramMatching.py\n",
    "def isMatch(jprog, cprog):\n",
    "    if not (len(jprog) == 3 and len(cprog) == 3):\n",
    "        return False\n",
    "    if jprog[2] == \"[]\" or cprog[2] == \"[]\":\n",
    "        return False\n",
    "    try:\n",
    "        jName = jprog[1].replace('_','').lower()\n",
    "        cName = cprog[1].replace('_','').lower()\n",
    "        jFile = jprog[0][:jprog[0].index('.')].lower()\n",
    "        if \"/\" in jFile:\n",
    "            jFile = jFile.split(\"/\")[-1]\n",
    "        cFile = cprog[0][:cprog[0].index('.')].lower()\n",
    "        if \"/\" in cFile:\n",
    "            cFile = cFile.split(\"/\")[-1]\n",
    "        return (jName == cName) and (jFile == cFile)\n",
    "    except:\n",
    "        print(\"======JJJJJJJ======\")\n",
    "        print(jprog)\n",
    "        print(\"=======CCCCCCC========\")\n",
    "        print(cprog)\n",
    "        return \"weirdness\"\n",
    "\n",
    "def filter_files(jfile, cfile, orig_folder, save_folder):\n",
    "    d = {}\n",
    "    \n",
    "    jlist = []\n",
    "    clist = []\n",
    "    with open(orig_folder + \"/\" + jfile) as f:\n",
    "        jlist = [line.split(\"\\t\") for line in f.readlines()]\n",
    "        \n",
    "    with open(orig_folder + \"/\" + cfile) as f:\n",
    "        clist = [line.split(\"\\t\") for line in f.readlines()]\n",
    "        \n",
    "    i = 0\n",
    "    for jprog in jlist:\n",
    "        if not i%1000:\n",
    "            print(\"i is \", i)\n",
    "        i+=1\n",
    "        for cprog in clist:\n",
    "            match = isMatch(jprog,cprog)\n",
    "            if match == \"weirdness\":\n",
    "                return\n",
    "            elif match:\n",
    "                d[jprog[2]] = cprog[2]\n",
    "    all_files = [(k,v) for k,v in d.items()]\n",
    "    print(\"ok\", len(all_files))\n",
    "    # Write java\n",
    "    with open(save_folder + \"/\" + jfile, \"w\") as f:\n",
    "        for file in all_files:\n",
    "            f.write(file[0])\n",
    "    \n",
    "    # Write C#\n",
    "    with open(save_folder + \"/\" + cfile, \"w\") as f:\n",
    "        for file in all_files:\n",
    "            f.write(file[1])\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter():\n",
    "    csharp_files = sorted(get_files(\"j2c-raw-data\", \"cs.txt\"))\n",
    "    java_files = sorted(get_files(\"j2c-raw-data\", \"java.txt\"))[3:]\n",
    "\n",
    "    print(csharp_files)\n",
    "    print(java_files)\n",
    "\n",
    "    for i in range(len(csharp_files)):\n",
    "        print(\"file\", java_files[i])\n",
    "        filter_files(java_files[i], csharp_files[i], \"j2c-raw-data\", \"filtered_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree_java(json, long_base_case=True):\n",
    "    if general_base_cases(json) is not None:\n",
    "        return general_base_cases(json)\n",
    "    \n",
    "    # hopefully just one\n",
    "    for key in json.keys():\n",
    "        \n",
    "        # I could put angle brackets by why bother?\n",
    "        tag = key.upper()\n",
    "        if not long_base_case:\n",
    "            if tag == \"identifier\" or tag == \"value\":\n",
    "                return make_tree_csharp(json[key])\n",
    "        else:\n",
    "            parentNode = Node(tag)\n",
    "            children = json[key]\n",
    "            if type(children) is list:\n",
    "                parentNode.children.extend(map(lambda child: \n",
    "                                       make_tree_csharp(child, long_base_case=long_base_case), \n",
    "                                       children))\n",
    "            else:\n",
    "                parentNode.children.append(make_tree_csharp(children, long_base_case=long_base_case))\n",
    "    return parentNode \n",
    "\n",
    "def canonicalize_java(tree):\n",
    "    var_names = {}\n",
    "    value_names = {} # could be string, int, char, bool\n",
    "    \n",
    "    def make_generic(node, dict, symbol):\n",
    "        if node.value in dict:\n",
    "            node.value = dict[node.value]\n",
    "        else:\n",
    "            new_symbol = symbol + str(len(dict) + 1)\n",
    "            dict[node.value] = new_symbol\n",
    "            node.value = new_symbol\n",
    "\n",
    "    \n",
    "    def canonicalize_java_helper(tree):\n",
    "        if tree.value == \"IDENTIFIER\":\n",
    "            make_generic(tree.children[0], num_names, \"a\")\n",
    "        elif tree.value == \"VALUE\":\n",
    "            make_generic(tree.children[0], var_names, \"v\")\n",
    "        else:\n",
    "            for child in tree.children:\n",
    "                canonicalize_java_helper(child)\n",
    "                \n",
    "    canonicalize_java_helper(tree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "\"arguments\":[{\"name\":{\"identifier\":\"bytes\"}},{\"name\":{\"identifier\":\"length\"},\"scope\":{\"name\":{\"identifier\":\"bytes\"}}}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree_csharp(json, long_base_case=True):\n",
    "    print(json)\n",
    "    \n",
    "    if general_base_cases(json) is not None:\n",
    "        return general_base_cases(json)\n",
    "    \n",
    "    # There should really only be one\n",
    "    for key in json.keys():\n",
    "        \n",
    "        tag = \"<\" + key.upper() + \">\"\n",
    "        verbose_tokens = [\"<CHARACTERLITERALEXPRESSION>\", \"<NUMERICLITERALEXPRESSION>\", \"<STRINGLITERALEXPRESSION>\", \"<IDENTIFIERNAME>\"]\n",
    "        if not long_base_case and tag in verbose_tokens:\n",
    "            return make_tree_csharp(json[key])\n",
    "        else:\n",
    "            parentNode = Node(tag)\n",
    "            children = json[key]\n",
    "            if type(children) is list:\n",
    "                parentNode.children.extend(map(lambda child: \n",
    "                                       make_tree_csharp(child, long_base_case=long_base_case), \n",
    "                                       children))\n",
    "            else:\n",
    "                parentNode.children.append(make_tree_csharp(children, long_base_case=long_base_case))\n",
    "    return parentNode \n",
    "\n",
    "# identifier\n",
    "# value\n",
    "\n",
    "def canonicalize_csharp(tree):\n",
    "    num_names = {}\n",
    "    var_names = {}\n",
    "    char_names = {}\n",
    "    string_names = {}\n",
    "    \n",
    "    def make_generic(node, dict, symbol):\n",
    "        if node.value in dict:\n",
    "            node.value = dict[node.value]\n",
    "        else:\n",
    "            new_symbol = symbol + str(len(dict) + 1)\n",
    "            dict[node.value] = new_symbol\n",
    "            node.value = new_symbol\n",
    "\n",
    "    \n",
    "    def canonicalize_csharp_helper(tree):\n",
    "        if tree.value == \"<NUMERICLITERALEXPRESSION>\":\n",
    "            make_generic(tree.children[0], num_names, \"n\")\n",
    "        elif tree.value == \"<CHARACTERLITERALEXPRESSION>\":\n",
    "            make_generic(tree.children[0], var_names, \"c\")\n",
    "        elif tree.value == \"<STRINGLITERALEXPRESSION>\":\n",
    "            make_generic(tree.children[0], string_names, \"s\")\n",
    "        elif tree.value == \"<IDENTIFIERNAME>\":\n",
    "            make_generic(tree.children[0], var_names, \"v\") #TODO: deal with argumentlist\n",
    "        else:\n",
    "            for child in tree.children:\n",
    "                canonicalize_csharp_helper(child)\n",
    "                \n",
    "    canonicalize_csharp_helper(tree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "def general_base_cases(json):\n",
    "    # First base case - variable name\n",
    "    if isinstance(json, string_types):\n",
    "        return Node(make_var_name(json))\n",
    "\n",
    "    # Second base case - variable value\n",
    "    if type(json) is int:\n",
    "        return Node(json)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def make_var_name(var_name):\n",
    "    if var_name == 'h':\n",
    "        return '<HEAD>'\n",
    "    elif var_name == 't':\n",
    "        return '<TAIL>'\n",
    "    else:\n",
    "        return var_name\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csharp_json_lists = load_data(\"jsonified\", \"cs.txt\")\n",
    "java_json_lists = load_data(\"filtered_data\", \"java.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the moment, ignore the itext dataset\n",
    "file_indices = [0, 1, 3, 4, 5] \n",
    "\n",
    "for index in file_indices:\n",
    "    for i in range(5):\n",
    "        print(\"C#\")\n",
    "        prog = csharp_json_lists[index][i]\n",
    "        c_tree = make_tree_csharp(prog)\n",
    "        better_c_tree = canonicalize_csharp(c_tree)\n",
    "        pretty_print_tree(better_c_tree)\n",
    "        print(\"JAVA\")\n",
    "        prog = java_json_lists[index][i]\n",
    "        j_tree = make_tree_java(prog)\n",
    "        better_c_tree = canonicalize_csharp(j_tree)\n",
    "        pretty_print_tree(better_j_tree)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL TOKENS\n",
      "{0, 1, 2, 3, 4, 5, 6, 'a1', 8, 9, 7, '<EXPR>', 'a2', '<TIMES>', '<SIMPLECS>', '<WHILECOMPLEX>', '<CONST>', '<SIMPLEIF>', '<IFTHENELSE>', '<EQUAL>', '<PLUS>', '<SHORTSTATEMENTCS>', '<IFSIMPLE>', '<ASSIGN>', 'a3', '<SIMPLEWHILE>', '<VAR>', '<WHILE>', '<IFCOMPLEX>', '<IF>', '<WHILESIMPLE>', '<COMPLEXCS>', 'a0', '<IFELSE>', '<SIMPLESTATEMENT>'}\n",
      "MAX\n",
      "109\n",
      "60.74\n"
     ]
    }
   ],
   "source": [
    "from translating_trees import make_tree_lambda\n",
    "import json\n",
    "\n",
    "coffee_progs = []\n",
    "with open(\"examples_new2.txt\") as f:\n",
    "    json_lists = [f.readlines()[0]]\n",
    "    for json_list in json_lists:\n",
    "        json_progs = json.loads(json_list)\n",
    "        for prog in json_progs:\n",
    "            coffee_progs.append(prog)\n",
    "          \n",
    "        \n",
    "# print(\"=======\")            \n",
    "\n",
    "# with open(\"progs.txt\") as f:\n",
    "#     json_lists = f.readlines()\n",
    "#     json_lists = [json_lists[0], json_lists[2]]\n",
    "#     for json_list in json_lists:\n",
    "#         json_progs = json.loads(json.loads(json_list))\n",
    "#         for prog in json_progs:\n",
    "#             coffee_progs.append(prog)\n",
    "           \n",
    "\n",
    "node_list = [make_tree_lambda(prog) for prog in coffee_progs]\n",
    "# _ = [pretty_print_tree(prog) for prog in node_list]\n",
    "\n",
    "\n",
    "max_count = 0\n",
    "token_counts = []\n",
    "tokens = set()\n",
    "def all_tokens(node):\n",
    "    count = 1\n",
    "    tokens.add(node.value)\n",
    "    for child in node.children:\n",
    "        count += all_tokens(child)\n",
    "    return count\n",
    "    \n",
    "    \n",
    "for prog in node_list:\n",
    "    token_count = all_tokens(prog)\n",
    "    token_counts.append(token_count)\n",
    "    max_count = max(max_count, token_count)\n",
    "    \n",
    "print(\"ALL TOKENS\")\n",
    "print(tokens)\n",
    "print(\"MAX\")\n",
    "print(max_count)\n",
    "print(sum(token_counts)/len(token_counts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid(node, parent, child_index):\n",
    "    try:\n",
    "        category = parent_to_category_LAMBDA(num_vars, num_ints, parent)[child_index]\n",
    "    except:\n",
    "        print(\"AAA\", parent, child_index, node.value)\n",
    "    possible_outputs = category_to_child_LAMBDA(num_vars, num_ints, category)\n",
    "    if not int(node.value) in possible_outputs:\n",
    "        print(\"parent\", parent, \"child_index\", child_index)\n",
    "        print(\"ERROR\", int(node.value), category)\n",
    "        return False\n",
    "    for i in range(len(node.children)):\n",
    "        if not check_valid(node.children[i], int(node.value), i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Check all the programs in a dataset for syntactic accuracy\n",
    "# (this is a debugging function used to double check the accuracy of your grammar)\n",
    "def check_all():\n",
    "    i = 0\n",
    "    # Check grammar is right\n",
    "    for prog in for_lambda_dset:\n",
    "        correct = check_valid(prog[1], -1, 0)\n",
    "        if correct is False:\n",
    "            print(i)\n",
    "            pretty_print_tree(prog[1])\n",
    "            return\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "class CoffeeGrammar(IntEnum):\n",
    "    #... fill this in...\n",
    "\n",
    "    \n",
    "class Coffee(IntEnum):\n",
    "    VAR = 0\n",
    "    CONST = 1\n",
    "    PLUS = 2\n",
    "    TIMES = 3\n",
    "    EQUAL = 4\n",
    "    ASSIGN = 5\n",
    "    IF = 6\n",
    "    IFSIMPLE = 7\n",
    "    SIMPLEIF = 8\n",
    "    IFELSE = 9\n",
    "    IFTHENELSE = 10\n",
    "    IFCOMPLEX = 11\n",
    "    SIMPLECS = 12\n",
    "    COMPLEXCS = 13\n",
    "    EXPR = 14\n",
    "    SHORTSTATEMENTCS = 15\n",
    "    WHILE = 16\n",
    "    WHILESIMPLE = 17\n",
    "    SIMPLEWHILE = 18\n",
    "    WHILECOMPLEX = 19\n",
    "    SIMPLESTATEMENT = 20\n",
    "    \n",
    "    \n",
    "\n",
    "def parent_to_category_FOR(num_vars, num_ints, parent):\n",
    "    \"\"\"\n",
    "    Return the categories of output which can be produced by a certain parent node.\n",
    "    \n",
    "    :param num_vars: number of variables a program can use\n",
    "    :param num_ints: number of ints a program can use\n",
    "    :param parent: int, the value of the parent node \n",
    "    \"\"\"\n",
    "    \n",
    "    # If parent is an int or a variable name, we are done.\n",
    "    if int(parent) in range(num_ints + num_vars):\n",
    "        return []\n",
    "    \n",
    "    # If parent is an op, return the class of outputs it can return\n",
    "    op_index = int(parent) - num_vars - num_ints\n",
    "    for_grammar = {\n",
    "        For.ROOT: [ForGrammar.STATEMENT],\n",
    "        For.VAR: [ForGrammar.VAR_NAME], \n",
    "        For.CONST: [ForGrammar.INT], \n",
    "        For.PLUS: [ForGrammar.EXPR, ForGrammar.EXPR],\n",
    "        For.MINUS: [ForGrammar.EXPR, ForGrammar.EXPR],\n",
    "        For.EQUAL: [ForGrammar.EXPR, ForGrammar.EXPR],\n",
    "        For.LE: [ForGrammar.EXPR, ForGrammar.EXPR],\n",
    "        For.GE: [ForGrammar.EXPR, ForGrammar.EXPR],\n",
    "        For.ASSIGN: [ForGrammar.VAR, ForGrammar.EXPR],\n",
    "        For.IF: [ForGrammar.CMP, ForGrammar.STATEMENT, ForGrammar.STATEMENT],\n",
    "        For.SEQ: [ForGrammar.STATEMENT, ForGrammar.SINGLE],\n",
    "        For.FOR: [ForGrammar.VAR_NAME, ForGrammar.EXPR, ForGrammar.CMP, ForGrammar.EXPR, \n",
    "                  ForGrammar.STATEMENT]\n",
    "    }\n",
    "    \n",
    "    return for_grammar[op_index]\n",
    "    \n",
    "def category_to_child_FOR(num_vars, num_ints, category):\n",
    "    \"\"\"\n",
    "    Take a category of output, and return a list of new tokens which can be its children in the For \n",
    "    language.\n",
    "    \n",
    "    :param num_vars: number of variables a program can use\n",
    "    :param num_ints: number of ints a program can use\n",
    "    :param category: category of output generated next\n",
    "    \"\"\"\n",
    "    n = num_ints + num_vars\n",
    "    for_grammar = {\n",
    "        ForGrammar.INT: range(num_ints),\n",
    "        ForGrammar.VAR_NAME: range(num_ints, n),\n",
    "        ForGrammar.VAR: [x + n for x in [For.VAR]],\n",
    "        ForGrammar.EXPR: [x + n for x in [For.VAR, For.CONST, For.PLUS, For.MINUS]],\n",
    "        ForGrammar.CMP: [x + n for x in [For.EQUAL, For.LE, For.GE]],\n",
    "        ForGrammar.SINGLE: [x + n for x in [For.ASSIGN, For.IF, For.FOR]],\n",
    "        ForGrammar.STATEMENT: [x + n for x in [For.ASSIGN, For.IF, For.FOR, For.SEQ]],\n",
    "    }\n",
    "    \n",
    "    return for_grammar[category]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
