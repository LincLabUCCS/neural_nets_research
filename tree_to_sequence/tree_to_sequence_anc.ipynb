{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import json\n",
    "from translating_trees import *\n",
    "from for_prog_dataset import ForDataset\n",
    "from convert_to_tree_and_matrices import TreeANCDataset\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets_library import training, visualize\n",
    "from ANC import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TreeCell(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Cell which takes in arbitrary numbers of hidden and cell states (one per child).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_children):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM cell.\n",
    "        \n",
    "        :param input_size: length of input vector\n",
    "        :param hidden_size: length of hidden vector (and cell state)\n",
    "        :param num_children: number of children = number of hidden/cell states passed in\n",
    "        \"\"\"\n",
    "        super(TreeCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Gates = input, output, memory + one forget gate per child\n",
    "        numGates = 3 + num_children\n",
    "        \n",
    "        self.gates_value = torch.nn.ModuleList()\n",
    "        self.gates_children = torch.nn.ModuleList()\n",
    "        for _ in range(numGates):\n",
    "            # One linear layer to handle the value of the node\n",
    "            value_linear = nn.Linear(input_size, hidden_size, bias = True)\n",
    "            children_linear = torch.nn.ModuleList()\n",
    "            # One per child of the node\n",
    "            for _ in range(num_children):\n",
    "                children_linear.append(nn.Linear(hidden_size, hidden_size, bias = False))\n",
    "            self.gates_value.append(value_linear)\n",
    "            self.gates_children.append(children_linear)\n",
    "            \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input, hidden_states, cell_states):\n",
    "        \"\"\"\n",
    "        Calculate a new hidden state and a new cell state from the LSTM gates\n",
    "        \n",
    "        :param hidden_states: A list of num_children hidden states.\n",
    "        :param cell_states: A list of num_children cell states.\n",
    "        :return A tuple containing (new hidden state, new cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_sums = []\n",
    "\n",
    "        for i in range(len(self.gates_value)):\n",
    "            data_sum = self.gates_value[i](input)\n",
    "            for j in range(len(hidden_states)):\n",
    "                data_sum += self.gates_children[i][j](hidden_states[j])\n",
    "            data_sums.append(data_sum)\n",
    "        \n",
    "        # First gate is the input gate\n",
    "        input_val = self.sigmoid(data_sums[0])\n",
    "        # Next output gate\n",
    "        o = self.sigmoid(data_sums[1])\n",
    "        # Next memory gate\n",
    "        m = self.tanh(data_sums[2])\n",
    "        # All the rest are forget gates\n",
    "        forget_data = 0\n",
    "        for i in range(len(cell_states)):\n",
    "            forget_data += self.sigmoid(data_sums[3 + i]) * cell_states[i]\n",
    "\n",
    "        # Put it all together!\n",
    "        new_state = input_val * m + forget_data\n",
    "        new_hidden = o * self.tanh(new_state)  \n",
    "                \n",
    "        return new_hidden, new_state\n",
    "    \n",
    "    def initialize_forget_bias(self, bias_value):\n",
    "        for i in range(3, len(self.gates_value)):\n",
    "            torch.nn.init.constant(self.gates_value[i].bias, bias_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TreeLSTM(nn.Module):\n",
    "    '''\n",
    "    TreeLSTM\n",
    "\n",
    "    Takes in a tree where each node has a value and a list of children.\n",
    "    Produces a tree of the same size where the value of each node is now encoded.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, valid_num_children):\n",
    "        \"\"\"\n",
    "        Initialize tree cells we'll need later.\n",
    "        \"\"\"\n",
    "        super(TreeLSTM, self).__init__()\n",
    "        \n",
    "        self.valid_num_children = [0] + valid_num_children\n",
    "        self.lstm_list = torch.nn.ModuleList()\n",
    "        \n",
    "        for size in self.valid_num_children:\n",
    "            self.lstm_list.append(TreeCell(input_size, hidden_size, size))\n",
    "        \n",
    "    def forward(self, node):\n",
    "        \"\"\"\n",
    "        Creates a tree where each node's value is the encoded version of the original value.\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return a tuple - (root of encoded tree, cell state)\n",
    "        \"\"\"\n",
    "        \n",
    "        # List of tuples: (node, cell state)\n",
    "        children = []\n",
    "        \n",
    "        # Recursively encode children\n",
    "        for child in node.children:\n",
    "            encoded_child = self.forward(child)\n",
    "            children.append(encoded_child)\n",
    "\n",
    "        # Extract the TreeCell inputs\n",
    "        inputH = [vec[0].value for vec in children]\n",
    "        inputC = [vec[1] for vec in children]\n",
    "\n",
    "        value = node.value\n",
    "\n",
    "        found = False\n",
    "        \n",
    "        # Feed the inputs into the TreeCell with the appropriate number of children.        \n",
    "        for i in range(len(self.valid_num_children)):\n",
    "            if self.valid_num_children[i] == len(children):\n",
    "                newH, newC = self.lstm_list[i](value, inputH, inputC)\n",
    "                found = True\n",
    "                break\n",
    "                \n",
    "        if not found:\n",
    "            print(\"WHAAAAAT?\")\n",
    "            raise ValueError(\"Beware.  Something has gone horribly wrong.  You may not have long to live.\")\n",
    "        \n",
    "        # Set our encoded vector as the root of the new tree\n",
    "        rootNode = Node(newH)\n",
    "        rootNode.children = [vec[0] for vec in children]\n",
    "        return (rootNode, newC)\n",
    "    \n",
    "    def initialize_forget_bias(self, bias_value):\n",
    "        for lstm in self.lstm_list:\n",
    "            lstm.initialize_forget_bias(bias_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class SeqEncoder(nn.Module):\n",
    "    # If you are using an end of sequence token that should be accounted for in input_size.\n",
    "    def __init__(self, input_size, hidden_size, num_layers, attention=True, \n",
    "                 use_embedding=True, embedding_size=256):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "        \n",
    "        self.use_embedding = use_embedding\n",
    "        \n",
    "        if use_embedding:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "            self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "        self.attention = attention\n",
    "        \n",
    "    def initialize_forget_bias(self, bias_val):\n",
    "        for names in self.lstm._all_weights:\n",
    "            for name in filter(lambda n: \"bias\" in n,  names):\n",
    "                bias = getattr(self.lstm, name)\n",
    "                n = bias.size(0)\n",
    "                start, end = n//4, n//2\n",
    "                bias.data[start:end].fill_(bias_val)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.use_embedding:\n",
    "            input = self.embedding(input)\n",
    "        outputs, (hiddens, cell_states) = self.lstm(input.unsqueeze(1))\n",
    "        outputs, hiddens, cell_states = outputs.squeeze(1), hiddens.squeeze(1), cell_states.squeeze(1)\n",
    "        \n",
    "        if self.attention:\n",
    "            return outputs, hiddens, cell_states\n",
    "        else:\n",
    "            return hiddens, cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     24,
     29
    ]
   },
   "outputs": [],
   "source": [
    "class TreeEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in a tree where each node has a value vector and a list of children\n",
    "    Produces a sequence encoding of the tree\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, valid_num_children, \n",
    "                 attention=True, use_embedding=True, embedding_size=256):\n",
    "        super(TreeEncoder, self).__init__()\n",
    "        \n",
    "        self.lstm_list = torch.nn.ModuleList()\n",
    "        self.use_embedding = use_embedding\n",
    "        \n",
    "        if use_embedding:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "            self.lstm_list.append(TreeLSTM(embedding_size, hidden_size, valid_num_children))\n",
    "        else:\n",
    "            self.lstm_list.append(TreeLSTM(input_size, hidden_size, valid_num_children))\n",
    "        \n",
    "        # All TreeLSTMs have input of hidden_size except the first.\n",
    "        for i in range(num_layers-1):\n",
    "            self.lstm_list.append(TreeLSTM(hidden_size, hidden_size, valid_num_children))\n",
    "        \n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, tree):\n",
    "        \"\"\"\n",
    "        Encodes nodes of a tree in the rows of a matrix.\n",
    "        \n",
    "        :param tree: a tree where each node has a value vector and a list of children\n",
    "        :return a matrix where each row represents the encoded output of a single node and also\n",
    "                the hidden/cell states of the root node.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.use_embedding:\n",
    "            tree = map_tree(lambda node: self.embedding(node).squeeze(0), tree)\n",
    "        \n",
    "        hiddens = []\n",
    "        cell_states = []\n",
    "        \n",
    "        for lstm in self.lstm_list:\n",
    "            tree, cell_state = lstm(tree)\n",
    "            hiddens.append(tree.value)\n",
    "            cell_states.append(cell_state)\n",
    "        \n",
    "        \n",
    "        hiddens = torch.stack(hiddens)\n",
    "        cell_states = torch.stack(cell_states)\n",
    "        \n",
    "        if self.attention:\n",
    "            annotations = torch.stack(tree_to_list(tree))                \n",
    "            return annotations, hiddens, cell_states\n",
    "        else:\n",
    "            return hiddens, cell_states\n",
    "        \n",
    "    def initialize_forget_bias(self, bias_value):\n",
    "        for lstm in self.lstm_list:\n",
    "            lstm.initialize_forget_bias(bias_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     30,
     31,
     37,
     64,
     68,
     71,
     95
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "'''\n",
    "class Tree_to_Sequence_Model(nn.Module):\n",
    "    \"\"\"\n",
    "      For the decoder this expects something like an lstm cell or a gru cell and not an lstm/gru.\n",
    "      Batch size is not supported at all. More precisely the encoder expects an input that does not\n",
    "      appear in batches and most also output non-batched tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size):\n",
    "        super(Tree_to_Sequence_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # nclass + 2 to include end of sequence and trash\n",
    "        self.output_log_odds = nn.Linear(hidden_size, nclass+2)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=0)\n",
    "\n",
    "        self.register_buffer('SOS_token', torch.LongTensor([[nclass+2]]))\n",
    "        self.EOS_value = nclass + 1\n",
    "\n",
    "        # nclass + 3 to include start of sequence, end of sequence, and trash.\n",
    "        # n + 2 - start of sequence, end of sequence - n + 1, trash - n.\n",
    "        # The first n correspond to the alphabet in order.\n",
    "        self.embedding = nn.Embedding(nclass+3, embedding_size)\n",
    "\n",
    "        # nclass is the trash category to avoid penalties after target's EOS token\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=nclass)\n",
    "\n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the input should be a pair. The first part\n",
    "               should correspond to the hidden state of the root. The second part\n",
    "               should correspond to the cell state of the root. They both should be\n",
    "               [num_layers, hidden_size].\n",
    "        target: The target should have dimension, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, teacher_forcing=True):\n",
    "        # root hidden state/cell state\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input) # num_layers x hidden_size\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "                                                            \n",
    "        target_length, = target.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(target_length):\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states)) # num_layers x 1 x hidden_size\n",
    "            decoder_hidden = decoder_hiddens[-1] # 1 x hidden_size\n",
    "            log_odds = self.output_log_odds(decoder_hidden)\n",
    "\n",
    "            loss += self.loss_func(log_odds, target[i])\n",
    "\n",
    "            if teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(1)\n",
    "            else:\n",
    "                _, next_input = log_odds.topk(1)\n",
    "\n",
    "            decoder_input = self.embedding(next_input).squeeze(1) # 1 x embedding_size\n",
    "                \n",
    "        return loss\n",
    "\n",
    "    \"\"\"\n",
    "        This is just an alias for point_wise_prediction, so that training code that assumes the presence\n",
    "        of a forward_train and forward_prediction works.\n",
    "    \"\"\"\n",
    "    def forward_prediction(self, input, maximum_length=20):\n",
    "        return self.point_wise_prediction(input, maximum_length)\n",
    "    \n",
    "    def point_wise_prediction(self, input, maximum_length=20):\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "        \n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        output_so_far = []\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            log_odds = self.output_log_odds(decoder_hidden)\n",
    "\n",
    "            _, next_input = log_odds.topk(1)\n",
    "            output_so_far.append(int(next_input))\n",
    "            \n",
    "            if int(next_input) == self.EOS_value:\n",
    "                break\n",
    "                \n",
    "            decoder_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1)\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1)\n",
    "        \n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        decoder_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        word_inputs = []\n",
    "\n",
    "        for _ in range(beam_width):\n",
    "            word_inputs.append((0, [], True, [decoder_input, decoder_hiddens, decoder_cell_states]))\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            new_word_inputs = []\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                if not word_inputs[i][2]:\n",
    "                    new_word_inputs.append(word_inputs[i])\n",
    "                    continue\n",
    "\n",
    "                decoder_input, decoder_hiddens, decoder_cell_states = word_inputs[i][3]\n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "                decoder_hidden = decoder_hiddens[-1]\n",
    "                log_odds = self.output_log_odds(decoder_hidden).squeeze(0) # nclasses\n",
    "                log_probs = self.log_softmax(log_odds)\n",
    "\n",
    "                log_value, next_input = log_probs.topk(beam_width) # beam_width, beam_width\n",
    "                decoder_input = self.embedding(next_input.unsqueeze(1)) # beam_width x 1 x embedding size\n",
    "\n",
    "                new_word_inputs.extend((word_inputs[i][0] + float(log_value[k]), word_inputs[i][1] + [int(next_input[k])],\n",
    "                                        int(next_input[k]) != self.EOS_value, [decoder_input[k], decoder_hiddens, decoder_cell_states])\n",
    "                                        for k in range(beam_width))\n",
    "                    \n",
    "            word_inputs = sorted(new_word_inputs, key=lambda word_input: word_input[0])[-beam_width:]\n",
    "        return word_inputs[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     18,
     19,
     72,
     110,
     160
    ]
   },
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_Model(Tree_to_Sequence_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, nclass, embedding_size,\n",
    "                 alignment_size=50, align_type=1):\n",
    "        super(Tree_to_Sequence_Attention_Model, self).__init__(encoder, decoder, hidden_size, nclass, embedding_size)\n",
    "        \n",
    "        self.attention_presoftmax = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        if align_type == 0:\n",
    "            self.attention_hidden = nn.Linear(hidden_size, alignment_size)\n",
    "            self.attention_context = nn.Linear(hidden_size, alignment_size, bias=False)\n",
    "            self.attention_alignment_vector = nn.Linear(alignment_size, 1)\n",
    "        elif align_type == 1:\n",
    "            self.attention_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "            \n",
    "        self.align_type = align_type\n",
    "        self.register_buffer('et', torch.zeros(1, hidden_size))\n",
    "        \n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the tree should have be a triple. The first \n",
    "               part of the triple should be the annotations and have dimensions, \n",
    "               number_of_nodes x hidden_size. The second triple of the pair should be the hidden \n",
    "               representations of the root and should have dimensions, num_layers x hidden_size.\n",
    "               The third part should correspond to the cell states of the root and should\n",
    "               have dimensions, num_layers x hidden_size.\n",
    "        target: The target should have dimensions, seq_len, and should be a LongTensor.\n",
    "    \"\"\"\n",
    "    def forward_train(self, input, target, teacher_forcing=True):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "\n",
    "        target_length, = target.size()\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "\n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(target_length):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x embedding_size + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            log_odds = self.output_log_odds(et)\n",
    "            loss += self.loss_func(log_odds, target[i])\n",
    "\n",
    "            if teacher_forcing:\n",
    "                next_input = target[i].unsqueeze(1)\n",
    "            else:\n",
    "                _, next_input = log_odds.topk(1)\n",
    "\n",
    "            word_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "        return loss        \n",
    "\n",
    "    \"\"\"\n",
    "        This is just an alias for point_wise_prediction, so that training code that assumes the presence\n",
    "        of a forward_train and forward_prediction works.\n",
    "    \"\"\"\n",
    "    def forward_prediction(self, input, maximum_length=150):\n",
    "        return self.point_wise_prediction(input, maximum_length)\n",
    "    \n",
    "    def point_wise_prediction(self, input, maximum_length=150):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        \n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        \n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        output_so_far = []\n",
    "        \n",
    "        for i in range(maximum_length):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x embedding_size + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            log_odds = self.output_log_odds(et)\n",
    "            _, next_input = log_odds.topk(1)\n",
    "\n",
    "            output_so_far.append(int(next_input))\n",
    "            \n",
    "            if int(next_input) == self.EOS_value:\n",
    "                break\n",
    "                \n",
    "            word_input = self.embedding(next_input).squeeze(1) # 1 x embedding size\n",
    "\n",
    "        return output_so_far\n",
    "\n",
    "    def beam_search_prediction(self, input, maximum_length=20, beam_width=5):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        SOS_token = Variable(self.SOS_token)\n",
    "        \n",
    "        word_input = self.embedding(SOS_token).squeeze(0) # 1 x embedding_size\n",
    "        et = Variable(self.et)\n",
    "        \n",
    "        decoder_input = torch.cat((word_input, et), dim=1)\n",
    "        word_inputs = []\n",
    "\n",
    "        for _ in range(beam_width):\n",
    "            word_inputs.append((0, [], True, [decoder_input, decoder_hiddens, decoder_cell_states]))\n",
    "\n",
    "        for _ in range(maximum_length):\n",
    "            new_word_inputs = []\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                if not word_inputs[i][2]:\n",
    "                    new_word_inputs.append(word_inputs[i])\n",
    "                    continue\n",
    "\n",
    "                decoder_input, decoder_hiddens, decoder_cell_states = word_inputs[i][3]\n",
    "                decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "                decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "                attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "                attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "                context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "                et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1))) # 1 x hidden_size\n",
    "                log_odds = self.output_log_odds(et).squeeze(0) # nclasses\n",
    "                log_probs = self.log_softmax(log_odds)\n",
    "\n",
    "                log_value, next_input = log_probs.topk(beam_width) # beam_width, beam_width\n",
    "                word_input = self.embedding(next_input.unsqueeze(1)) # beam_width x 1 x embedding size\n",
    "                decoder_input = torch.cat((word_input, et.unsqueeze(0).repeat(beam_width, 1, 1)), dim=2)\n",
    "\n",
    "                new_word_inputs.extend((word_inputs[i][0] + float(log_value[k]), word_inputs[i][1] + [int(next_input[k])],\n",
    "                                        int(next_input[k]) != self.EOS_value, [word_input[k], decoder_hiddens, decoder_cell_states])\n",
    "                                        for k in range(beam_width))\n",
    "            word_inputs = sorted(new_word_inputs, key=lambda word_input: word_input[0])[-beam_width:]\n",
    "        return word_inputs[-1][1]\n",
    "    \n",
    "    def attention_logits(self, attention_hidden_values, decoder_hidden):\n",
    "        if self.align_type == 0:\n",
    "            return self.attention_alignment_vector(self.tanh(self.attention_context(decoder_hidden) + attention_hidden_values))\n",
    "        else:\n",
    "            return (decoder_hidden * attention_hidden_values).sum(1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Tree_to_Sequence_Attention_ANC_Model(Tree_to_Sequence_Attention_Model):\n",
    "    def __init__(self, encoder, decoder, hidden_size, embedding_size, M, R,\n",
    "                 alignment_size=50, align_type=1, N=11, t_max=10):\n",
    "        # The 1 is for nclasses which is not used in this model.\n",
    "        super(Tree_to_Sequence_Attention_ANC_Model, self).__init__(encoder, decoder, hidden_size, 1, embedding_size,\n",
    "                                                                   alignment_size=alignment_size, align_type=align_type)\n",
    "        # the initial registers all have value 0 with probability 1\n",
    "        prob_dist = torch.zeros(R, M)\n",
    "        prob_dist[:, 0] = 1\n",
    "        \n",
    "        self.register_buffer('initial_registers', prob_dist)\n",
    "        \n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        self.N = N\n",
    "        self.t_max = t_max\n",
    "        \n",
    "        self.initial_word_input = nn.Parameter(torch.Tensor(1, N + 3*R))\n",
    "        self.output_log_odds = nn.Linear(hidden_size, N + 3*R)\n",
    "        \n",
    "    \"\"\"\n",
    "        input: The output of the encoder for the tree should have be a triple. The first \n",
    "               part of the triple should be the annotations and have dimensions, \n",
    "               number_of_nodes x hidden_size. The second triple of the pair should be the hidden \n",
    "               representations of the root and should have dimensions, num_layers x hidden_size.\n",
    "               The third part should correspond to the cell states of the root and should\n",
    "               have dimensions, num_layers x hidden_size.\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        annotations, decoder_hiddens, decoder_cell_states = self.encoder(input)\n",
    "        # align_size: 0 number_of_nodes x alignment_size or align_size: 1-2 bengio number_of_nodes x hidden_size\n",
    "        if self.align_type <= 1:\n",
    "            attention_hidden_values = self.attention_hidden(annotations)\n",
    "        else:\n",
    "            attention_hidden_values = annotations\n",
    "        \n",
    "        decoder_hiddens = decoder_hiddens.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "        decoder_cell_states = decoder_cell_states.unsqueeze(1) # num_layers x 1 x hidden_size\n",
    "\n",
    "        word_input = self.initial_word_input # 1 x N + 3*R\n",
    "        et = Variable(self.et)\n",
    "        \n",
    "        output_words = []\n",
    "\n",
    "        for i in range(self.M):\n",
    "            decoder_input = torch.cat((word_input, et), dim=1) # 1 x N + 3*R + hidden_size\n",
    "            decoder_hiddens, decoder_cell_states = self.decoder(decoder_input, (decoder_hiddens, decoder_cell_states))\n",
    "            decoder_hidden = decoder_hiddens[-1]\n",
    "            \n",
    "            attention_logits = self.attention_logits(attention_hidden_values, decoder_hidden)\n",
    "            attention_probs = self.softmax(attention_logits) # number_of_nodes x 1\n",
    "            context_vec = (attention_probs * annotations).sum(0).unsqueeze(0) # 1 x hidden_size\n",
    "            et = self.tanh(self.attention_presoftmax(torch.cat((decoder_hidden, context_vec), dim=1)))\n",
    "            word_input = self.output_log_odds(et)\n",
    "            \n",
    "            output_words.append(word_input)\n",
    "            \n",
    "        controller_params = torch.stack(output_words, dim=2).squeeze(0) # N + 3*R x M\n",
    "        instruction = controller_params[0:N]\n",
    "        first_arg = controller_params[N:N+R]\n",
    "        second_arg = controller_params[N+R:N+2*R]\n",
    "        output = controller_params[N+2*R:N + 3*R]\n",
    "        controller = Controller.Controller(first_arg=first_arg, second_arg=second_arg, output=output, \n",
    "                                           instruction=instruction, \n",
    "                                           initial_registers=Variable(self.initial_registers),\n",
    "                                           multiplier = 1, correctness_weight=1, halting_weight=1, \n",
    "                                           confidence_weight=0, efficiency_weight=0, t_max=self.t_max)\n",
    "        \n",
    "        return controller\n",
    "        \n",
    "    \"\"\"\n",
    "        controller: The controller for an ANC.\n",
    "        target: The target should be a list of triples, where the first element of any triple is\n",
    "                the input matrix, the second element is the output matrix corresponding to the expected\n",
    "                output based on the input and the third element is a mask that specifies the area\n",
    "                of memory where the output is.\n",
    "    \"\"\"\n",
    "    def compute_loss(self, controller, target):\n",
    "        loss = 0\n",
    "        input_memories = target[0]\n",
    "        output_memories = target[1]\n",
    "        output_masks = target[2]\n",
    "        \n",
    "        for i in range(len(input_memories)):\n",
    "            loss += controller.forward_train(input_memories[i], (output_memories[i], output_masks[i]))\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     19,
     27
    ]
   },
   "outputs": [],
   "source": [
    "class MultilayerLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, bias=True):\n",
    "        super(MultilayerLSTMCell, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        \n",
    "        if isinstance(hidden_sizes, int):\n",
    "            temp = []\n",
    "            \n",
    "            for _ in range(num_layers):\n",
    "                temp.append(hidden_sizes)\n",
    "            \n",
    "            hidden_sizes = temp\n",
    "            \n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            curr_lstm = nn.LSTMCell(hidden_sizes[i], hidden_sizes[i+1], bias=bias)\n",
    "            self.lstm_layers.append(curr_lstm)\n",
    "    \n",
    "    def initialize_forget_bias(self, bias_value):\n",
    "        for lstm_cell in self.lstm_layers:\n",
    "            n = lstm_cell.bias_ih.size(0)\n",
    "            start, end = n//4, n//2\n",
    "            b1 = lstm_cell.bias_ih\n",
    "            nn.init.constant(lstm_cell.bias_ih[start:end], bias_value)\n",
    "            nn.init.constant(lstm_cell.bias_hh[start:end], bias_value)\n",
    "    \n",
    "    def forward(self, input, past_states):\n",
    "        hiddens, cell_states = past_states\n",
    "        result_hiddens, result_cell_states = [], []\n",
    "        curr_input = input\n",
    "        \n",
    "        for lstm_cell, curr_hidden, curr_cell_state in zip(self.lstm_layers, hiddens, cell_states):\n",
    "            curr_input, new_cell_state = lstm_cell(curr_input, (curr_hidden, curr_cell_state))\n",
    "            result_hiddens.append(curr_input)\n",
    "            result_cell_states.append(new_cell_state)\n",
    "        \n",
    "        return torch.stack(result_hiddens), torch.stack(result_cell_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     19,
     36
    ]
   },
   "outputs": [],
   "source": [
    "num_vars = 10\n",
    "num_ints = 11\n",
    "\n",
    "for_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"Assign\": 7,\n",
    "    \"If\": 8,\n",
    "    \"Seq\": 9,\n",
    "    \"For\": 10\n",
    "}\n",
    "\n",
    "for_ops = {\"<\" + k.upper() + \">\": v for k,v in for_ops.items()}\n",
    "\n",
    "lambda_ops = {\n",
    "    \"Var\": 0,\n",
    "    \"Const\": 1,\n",
    "    \"Plus\": 2,\n",
    "    \"Minus\": 3,\n",
    "    \"EqualFor\": 4,\n",
    "    \"LeFor\": 5,\n",
    "    \"GeFor\": 6,\n",
    "    \"If\": 7,\n",
    "    \"Let\": 8,\n",
    "    \"Unit\": 9,\n",
    "    \"Letrec\": 10,\n",
    "    \"App\": 11\n",
    "}\n",
    "\n",
    "lambda_ops = {\"<\" + k.upper() + \">\": v for k,v in lambda_ops.items()}\n",
    "\n",
    "lambda_calculus_ops = {\n",
    "                \"<VARIABLE>\": 0,\n",
    "                \"<ABSTRACTION>\": 1,\n",
    "                \"<NUMBER>\": 2,\n",
    "                \"<BOOLEAN>\": 3,\n",
    "                \"<NIL>\": 4,\n",
    "                \"<IF>\": 5,\n",
    "                \"<CONS>\": 6,\n",
    "                \"<MATCH>\": 7,\n",
    "                \"<UNARYOPER>\": 8,\n",
    "                \"<BINARYOPER>\": 9,\n",
    "                \"<LET>\": 10,\n",
    "                \"<LETREC>\": 11,\n",
    "                \"<TRUE>\": 12,\n",
    "                \"<FALSE>\": 13,\n",
    "                \"<TINT>\": 14,\n",
    "                \"<TBOOL>\": 15,\n",
    "                \"<TINTLIST>\": 16,\n",
    "                \"<TFUN>\": 17,\n",
    "                \"<ARGUMENT>\": 18,\n",
    "                \"<NEG>\": 19,\n",
    "                \"<NOT>\": 20,\n",
    "                \"<PLUS>\": 21,\n",
    "                \"<MINUS>\": 22,\n",
    "                \"<TIMES>\": 23,\n",
    "                \"<DIVIDE>\": 24,\n",
    "                \"<AND>\": 25,\n",
    "                \"<OR>\": 26,\n",
    "                \"<EQUAL>\": 27,\n",
    "                \"<LESS>\": 28,\n",
    "                \"<APPLICATION>\": 29,\n",
    "                \"<HEAD>\": 30,\n",
    "                \"<TAIL>\": 31\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "input_eos_token = False\n",
    "input_as_seq = False\n",
    "use_embedding = True\n",
    "eos_bonus = 1 if input_eos_token and input_as_seq else 0\n",
    "long_base_case = True\n",
    "binarize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "is_lambda_calculus = False\n",
    "\n",
    "for_anc_dset = TreeANCDataset(\"ANC/Easy-arbitraryForListWithOutput.json\", is_lambda_calculus, binarize=binarize, input_eos_token=input_eos_token, \n",
    "                              use_embedding=use_embedding, long_base_case=long_base_case, \n",
    "                              input_as_seq=input_as_seq, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reset_all_parameters_uniform(model, stdev):\n",
    "    for param in model.parameters():\n",
    "        nn.init.uniform(param, -stdev, stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 30\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "alignment_size = 50\n",
    "align_type = 1\n",
    "M, R = 10, 3\n",
    "N = 11\n",
    "encoder_input_size = num_vars + num_ints + len(for_ops.keys()) + eos_bonus\n",
    "\n",
    "if input_as_seq:\n",
    "    encoder = SeqEncoder(encoder_input_size, hidden_size, num_layers, attention=True, use_embedding=use_embedding)\n",
    "else:\n",
    "    encoder = TreeEncoder(encoder_input_size, hidden_size, num_layers, [1, 2], attention=True, use_embedding=use_embedding)\n",
    "\n",
    "decoder = MultilayerLSTMCell(N + 3*R + hidden_size, hidden_size, num_layers)\n",
    "program_model = Tree_to_Sequence_Attention_ANC_Model(encoder, decoder, hidden_size, embedding_size, M, R, \n",
    "                                                     alignment_size=alignment_size, align_type=align_type)\n",
    "    \n",
    "reset_all_parameters_uniform(program_model, 0.1)\n",
    "encoder.initialize_forget_bias(3)\n",
    "decoder.initialize_forget_bias(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_model = program_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(program_model.parameters(), lr=0.5)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=100, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prog, target in for_anc_dset:\n",
    "    controller = program_model(prog)\n",
    "    controller.cuda()\n",
    "    loss = program_model.compute_loss(controller, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in program_model.named_parameters():\n",
    "        print(name)\n",
    "        print(param.grad)\n",
    "    optimizer.zero_grad()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = \\\n",
    "    training.train_model_tree_to_anc(program_model, for_anc_dset, optimizer, \n",
    "                                     lr_scheduler=lr_scheduler, \n",
    "                                     num_epochs=10, batch_size=1,\n",
    "                                     cuda=True,\n",
    "                                     plateau_lr=True,\n",
    "                                     print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_model.encoder.embedding.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
