{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains the two learnable parts of the model in four independent, fully connected layers.\n",
    "    First the initial values for the registers and instruction registers and second the \n",
    "    parameters that computes the required distributions. \n",
    "    \n",
    "    xerox\n",
    "    \"\"\"\n",
    "#     def __init(self, firstarglinear, secondarglinear, outputlinear, instructionlinear, initial_memory, \n",
    "#                initial_registers, instruction_register, stop_threshold, t_max, cmatrix, tjmatrix):\n",
    "#         \"\"\"\n",
    "#         Initializes registers, memory and register matrix and their dimensions \n",
    "#         Initializes four program matrices one of dimension NxM and three of dimension RxM\n",
    "#         \"\"\"\n",
    "    \n",
    "    def __init__(self, firstarglinear, secondarglinear, outputlinear, instructionlinear, initial_memory, \n",
    "               initial_registers, instruction_register, stop_threshold, blur, alpha, beta, gamma, delta):\n",
    "        \"\"\"\n",
    "        Initializes registers, memory and register matrix and their dimensions \n",
    "        Initializes four program matrices one of dimension BxNxM and three of dimension BxRxM\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Blur matrices:\n",
    "        if blur is not None:\n",
    "            firstarglinear = self.blur(firstarglinear, blur, 1)\n",
    "            secondarglinear = self.blur(secondarglinear, blur, 1)\n",
    "            outputlinear = self.blur(outputlinear, blur, 1)\n",
    "            instructionlinear = self.blur(instructionlinear, blur, 1)\n",
    "            initial_memory = self.blur(initial_memory, blur, 2)\n",
    "            initial_registers = self.blur(initial_registers, blur, 2)\n",
    "            instruction_register = self.blur(instruction_register, blur, 1)\n",
    "            \n",
    "        self.firstarglinear = nn.Parameter(firstarglinear.data)\n",
    "        self.secondarglinear = nn.Parameter(secondarglinear.data)\n",
    "        self.outputlinear = nn.Parameter(outputlinear.data)\n",
    "        self.instructionlinear = nn.Parameter(instructionlinear.data) \n",
    "        \n",
    "        # Memory matrix (M x M)\n",
    "        self.memory = nn.Parameter(initial_memory.data)\n",
    "        \n",
    "        # Register Matrix (R x M)\n",
    "        self.registers = nn.Parameter(initial_registers.data)\n",
    "        \n",
    "        # Instruction Register (M)\n",
    "        instruction_register = instruction_register.unsqueeze(2)\n",
    "        self.IR = nn.Parameter(instruction_register.data)\n",
    "        \n",
    "        self.stop_probability = 0\n",
    "        self.stop_threshold = stop_threshold\n",
    "        \n",
    "        \n",
    "        # Machine initialization\n",
    "        self.machine = Machine(B, M, R)\n",
    "    \n",
    "    def blur(self, matrix, scale_factor, dimension):\n",
    "        \"\"\"\n",
    "        Takes a matrix, each row (or column) of which is a one-hot vector.\n",
    "        Multiply each 1 by a gajillion and then softmax it, which \n",
    "        effectively \"blurs\" the matrix a little bit.\n",
    "        \"\"\"\n",
    "        matrix = scale_factor * matrix\n",
    "        softmax = nn.Softmax(dimension)\n",
    "        return softmax(Variable(matrix))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        efficiency_loss = 0\n",
    "        confidence_loss = 0\n",
    "        \n",
    "        t = 0 \n",
    "        t_max = 5 # TODO: pass in\n",
    "        while t < t_max and self.stop_probability < self.stop_threshold:\n",
    "            einput = torch.bmm(self.firstarglinear, self.IR)\n",
    "            ainstruction = torch.bmm(self.secondarglinear, self.IR)\n",
    "            binstruction = torch.bmm(self.outputlinear, self.IR)\n",
    "            outputin = torch.bmm(self.instructionlinear, self.IR)\n",
    "\n",
    "            # Updating memory, registers, and IR after machine operation\n",
    "            self.memory, self.registers, self.IR, stop_prob = self.machine(einput, ainstruction, binstruction, outputin, self.memory, self.registers, self.IR)\n",
    "            self.stop_probability = self.stop_probability + stop_prob\n",
    "            \n",
    "            new_efficiency, new_confidence = self.timestep_loss()\n",
    "            efficiency_loss += new_efficiency\n",
    "            confidence_loss += new_confidence\n",
    "            \n",
    "            \n",
    "            t += 1\n",
    "            \n",
    "        correctness_loss, halting_loss = self.final_loss()\n",
    "        total_loss  = alpha * correctness_loss + beta * halting_loss + gamma * confidence_loss + delta * efficiency_loss\n",
    "        return total_loss\n",
    "        \n",
    "    def timestep_loss():\n",
    "        return (1,1)\n",
    "    \n",
    "    def final_loss():\n",
    "        return (1,1)\n",
    "   \n",
    "\n",
    "    def lossfunctions(self, cmatrix, tjmatrix):\n",
    "        \"\"\" compute four diferent loss functions and return a weighted average of the four measuring correctness, \n",
    "        halting, efficiency, and confidence\"\"\"\n",
    "        \n",
    "        self.matrix1 = ((self.cmatrix)*(self.program_matrix4 - self.memory)^2)\n",
    "        self.correctness += self.matrix1\n",
    "        \n",
    "        \n",
    "            \n",
    "        self.efficiency += (1-self.stop_probability[self.t])\n",
    "        \n",
    "        self.confidence += torch.matmult(self.stop_probability[self.t] - self.stop_probability[self.t -1], matrix1)\n",
    "        \n",
    "        \n",
    "# HOW TO BLUR? ==> Add a constant, then softmax\n",
    "#TODO: Add in some fuzz factor????\n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    Parent class for our binary operations\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Initialize the memory length (needed so we can mod our answer in case it exceeds the range 0-M-1)\n",
    "        \n",
    "        :param M: Memory length\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M #TODO: Check this gets updated!\n",
    "        self.outputs = torch.zeros(M, M, M)\n",
    "        for i in range(M):\n",
    "            for j in range(M):\n",
    "                val = self.compute(i, j)\n",
    "                self.outputs[val][i][j] = 1\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        \"\"\" \n",
    "        Perform the binary operation.  The arguments may or may not be used.\n",
    "        \n",
    "        :param x: First argument\n",
    "        :param y: Second argument\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        return (x + y) % self.M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0 # Actual jump happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decrement(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Decrement, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x - 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Increment(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Increment, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x + 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Max, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return max(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Min(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Min, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Read, self).__init__(M)\n",
    "        self.outputs = torch.zeros(M, M, M) # Clear output matrix out since we're gonna do the reading elsewhere\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return 0 # Actual reading happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subtract(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Subtract, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return (x - y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Write(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Write, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return 0 # Actual write happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Zero, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    The Machine executes assembly instructions passed to it by the Controller.\n",
    "    It updates the given memory, registers, and instruction pointer.\n",
    "    The Machine doesn't have any learnable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, B, M, R):\n",
    "        \"\"\"\n",
    "        Initializes dimensions, operations, and counters\n",
    "        \n",
    "        :param M: Memory length.  Integer values also take on values 0-M-1.  M is also the program length.\n",
    "        :param R: Number of registers\n",
    "        GET RID OF THIS :stop_threshold: Accumulated probability of stopping after which the program terminates.\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        \n",
    "        # Store parameters as class variables\n",
    "        self.R = R # Number of registers\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.B = B # Batch size\n",
    "        \n",
    "        # Start off with 0 probability of stopping\n",
    "        self.stop_probability = torch.zeros(B)\n",
    "        \n",
    "        # A list of all our possible ops\n",
    "        self.ops = [\n",
    "            Jump(M), \n",
    "            Stop(M), \n",
    "            Write(M), \n",
    "            Read(M), \n",
    "#             Add(M), \n",
    "#             Subtract(M), \n",
    "#             Increment(M),\n",
    "#             Decrement(M),\n",
    "#             Min(M),\n",
    "#             Max(M),\n",
    "#             Zero(M)\n",
    "        ]\n",
    "        \n",
    "        # Number of instructions\n",
    "        self.N = len(self.ops)\n",
    "        \n",
    "        self.outputs = Variable(torch.zeros(self.N, M, M, M))\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            op = self.ops[i]\n",
    "            self.outputs[i] = op()\n",
    "            \n",
    "            \n",
    "        self.outputs = torch.unsqueeze(self.outputs, 0)\n",
    "        self.outputs = self.outputs.expand(B, -1, -1, -1, -1)\n",
    "        \n",
    "        # Keep track of the index of certain ops which are dealt with specially\n",
    "        self.jump_index = 0\n",
    "        self.stop_index = 1\n",
    "        self.write_index = 2\n",
    "        self.read_index = 3\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \n",
    "        \"\"\"\n",
    "        Run the Machine for one timestep (corresponding to the execution of one line of Assembly).\n",
    "        The first four parameter names correspond to the vector names used in the original ANC paper\n",
    "        \n",
    "        :param e: Probability distribution over the instruction being executed (length M)\n",
    "        :param a: Probability distribution over the first argument register (length R)\n",
    "        :param b: Probability distribution over the second argument register (length R)\n",
    "        :param o: Probability distribution over the first argument register (length R)\n",
    "        :param memory: Memory matrix (size M x M)\n",
    "        :param registers: Register matrix (size R x M)\n",
    "        :param IR: Instruction Register (length M)\n",
    "        \n",
    "        :return: The memory, registers, and instruction register after the timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Give all vectors an extra dimension\n",
    "        \n",
    "        # Dimensions B x 1 x R -> B x 1 x R\n",
    "        \n",
    "        a = torch.transpose(a, 1, 2)\n",
    "        b = torch.transpose(b, 1, 2)\n",
    "        \n",
    "        \n",
    "        # Calculate distributions over the two argument values by multiplying each \n",
    "        # register by the probability that register is being used.\n",
    "        arg1 = torch.bmm(a, registers)\n",
    "        arg2 = torch.bmm(b, registers)\n",
    "        \n",
    "        \n",
    "        # Arg1 dimensions: B x 1 x M --> B x 1 x 1 x 1 x 3\n",
    "        arg1_long = torch.unsqueeze(arg1, 1)\n",
    "        arg1_long = torch.unsqueeze(arg1_long, 1)\n",
    "        \n",
    "        \n",
    "        # A bunch of matrix-y stuff \n",
    "        #arg1: BxMx1; Outputs = NxMxMxM\n",
    "\n",
    "        x = torch.matmul(arg1_long, self.outputs)\n",
    "        \n",
    "        # x dimensions: B x N x M x 1 x M -> B x N x M x M\n",
    "        x = torch.squeeze(x, 3)\n",
    "        \n",
    "        # Arg2_long dimensions: B x 1 x M --> B x 1 x M x 1\n",
    "        arg2_long = torch.unsqueeze(arg2, 3)\n",
    "        \n",
    "        \n",
    "        y = torch.matmul(x, arg2_long)\n",
    "        \n",
    "        # y dimensions: B x N x M x 1 -> B x N x M\n",
    "        y = torch.squeeze(y, 3)\n",
    "        \n",
    "        # Dimensions B x N x 1 -> B x 1 x N\n",
    "        e = torch.transpose(e, 1, 2)\n",
    "        read_vec =  e[:, :, self.read_index]\n",
    "        # Dimensions B x 1 -> B x 1 x 1\n",
    "        read_vec = read_vec.unsqueeze(1)\n",
    "        \n",
    "        out_vec = torch.matmul(e, y) # Length M vector over the output of the operation\n",
    "        # Deal with memory reads separately\n",
    "        out_vec = out_vec + read_vec * torch.matmul(arg1, memory)        \n",
    "        torch.Size([4, 1, 3])\n",
    "        \n",
    "        # Update our memory, registers, instruction register, and stopping probability\n",
    "        memory = self.writeMemory(e, memory, arg1, arg2)\n",
    "        registers = self.writeRegisters(out_vec, o, registers)\n",
    "        IR = self.updateIR(e, IR, arg1, arg2)\n",
    "        stop_prob = self.getStop(e)\n",
    "        \n",
    "        return(memory, registers, IR, stop_prob)\n",
    "        \n",
    "        \n",
    "    def writeRegisters(self, out, o, registers):\n",
    "        \"\"\"\n",
    "        Write the result of our operation to our registers.\n",
    "        \n",
    "        :param out: probability distribution over the output value\n",
    "        :param o: probability distribution over the output register\n",
    "        :param registers: register matrix\n",
    "        \n",
    "        :return: the updated registers\n",
    "        \"\"\"\n",
    "        # Multiply probability of writing to each output register by the value \n",
    "        \n",
    "        new_register_vals = torch.matmul(o, out)\n",
    "        # Multiply each original register cell by the probabilty of not writing to that register\n",
    "        old_register_vals = (1-o).expand(self.B, self.R, self.M) * registers\n",
    "        \n",
    "        registers =  new_register_vals + old_register_vals\n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the instruction register\n",
    "        \n",
    "        :param e: distribution over the current instruction (length N)\n",
    "        :param IR: instruction register (length M)\n",
    "        :param arg1: distribution over the first argument value (length M)\n",
    "        :param arg2: distribution over the second argument value (length M)\n",
    "        \n",
    "        :return: the updated instruction register\n",
    "        \"\"\"\n",
    "        # IR - length M vector\n",
    "        jump_probability = e[:, :, self.jump_index]\n",
    "        \n",
    "        is_zero = arg1[:, :, 0]\n",
    "        # Slicing lost a dimension.  Let's add it back\n",
    "        jump_probability = torch.unsqueeze(jump_probability, 1)\n",
    "        is_zero = torch.unsqueeze(is_zero, 1)\n",
    "        \n",
    "        \n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        wraparound = IR[:, -1]\n",
    "        normal_instructions = IR[:, :-1]\n",
    "        \n",
    "        # for whatever reason, when you chop off one row/column, that dimension disappears\n",
    "        # add it back\n",
    "        wraparound = wraparound.unsqueeze(1)\n",
    "        IR_no_jump = torch.cat([wraparound, normal_instructions], 1)\n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        return IR\n",
    "    \n",
    "    def writeMemory(self, e, mem_orig, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the memory\n",
    "        \n",
    "        :param e: distribution over the current instruction (B x 1 x M)\n",
    "        :param mem_orig: current memory matrix (B x M x M)\n",
    "        :param arg1: distribution over the first argument value (B x 1 x M)\n",
    "        :param arg2: distribution over the second argument value (B x 1 x M)\n",
    "        \n",
    "        :return: the updated memory matrix\n",
    "        \"\"\"\n",
    "        write_probability = e[:,:, self.write_index]\n",
    "        # Write_prob dimensions: B x 1 x 1\n",
    "        write_probability = torch.unsqueeze(write_probability, 1)\n",
    "        \n",
    "        # Arg1 dimensions: B x 1 x M -> B x M x 1\n",
    "        arg1 = torch.transpose(arg1, 1, 2)\n",
    "        \n",
    "        # If we are on a write instruction, write the value arg2 in register arg1. Otherwise, leave memory as is.\n",
    "        mem_write = torch.bmm(arg1, arg2) \n",
    "        temp3 = 1 - write_probability\n",
    "        memory = mem_orig * (1 - write_probability) + mem_write * write_probability\n",
    "        return memory\n",
    "        \n",
    "    def getStop(self, e):\n",
    "        \"\"\"\n",
    "        Obtain the probability that we will stop at this timestep based on the probability that we are running the STOP op.\n",
    "        \n",
    "        :param e: distribution over the current instruction (length M)\n",
    "        \n",
    "        :return: probability representing whether the controller should stop.\n",
    "        \"\"\"\n",
    "        return e[:, :, self.stop_index].data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dce6cfc4417a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2081edc9d294>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, firstarglinear, secondarglinear, outputlinear, instructionlinear, initial_memory, initial_registers, instruction_register, stop_threshold, blur, alpha, beta, gamma, delta)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[1;32m     22\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mController\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_registers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Controller test\n",
    "\n",
    "# M=3, R=2, N=4, B=5 # NOTE: Must comment out all but 4 ops\n",
    "\n",
    "# BxNxM\n",
    "instructions = torch.FloatTensor([[[0, 0, 1],\n",
    "                                            [0, 1, 0],\n",
    "                                            [1, 0, 0],\n",
    "                                            [0, 0, 0]],\n",
    "                                           [[0, 0, 0],\n",
    "                                            [1, 1, 0],\n",
    "                                            [0, 0, 1],\n",
    "                                            [0, 0, 0]],\n",
    "                                           [[1, 0, 0],\n",
    "                                            [0, 0, 0],\n",
    "                                            [0, 0, 1],\n",
    "                                            [0, 1, 0]],\n",
    "                                          [[1, 0, 0],\n",
    "                                            [0, 0, 0],\n",
    "                                            [0, 0, 1],\n",
    "                                            [0, 1, 0]],\n",
    "                                          [[1, 0, 0],\n",
    "                                            [0, 0, 0],\n",
    "                                            [0, 0, 1],\n",
    "                                            [0, 1, 0]]])\n",
    "# BxRxM\n",
    "arg1 = torch.FloatTensor([[[0, 1, 1],\n",
    "                                    [1, 0, 0]],\n",
    "                                   [[1, 1, 1],\n",
    "                                    [0, 0, 0]],\n",
    "                                   [[0, 0, 1],\n",
    "                                    [1, 1, 0]],\n",
    "                                   [[1, 1, 0],\n",
    "                                    [0, 0, 1]],\n",
    "                                   [[1, 0, 1],\n",
    "                                    [0, 1, 0]]])\n",
    "\n",
    "# BxRxM\n",
    "arg2 = torch.FloatTensor([[[0, 1, 1],\n",
    "                                    [1, 0, 0]],\n",
    "                                   [[1, 1, 1],\n",
    "                                    [0, 0, 0]],\n",
    "                                   [[0, 0, 1],\n",
    "                                    [1, 1, 0]],\n",
    "                                   [[1, 1, 0],\n",
    "                                    [0, 0, 1]],\n",
    "                                   [[1, 0, 1],\n",
    "                                    [0, 1, 0]]])\n",
    "\n",
    "# BxRxM\n",
    "out = torch.FloatTensor([[[0, 1, 1],\n",
    "                                    [1, 0, 0]],\n",
    "                                   [[1, 1, 1],\n",
    "                                    [0, 0, 0]],\n",
    "                                   [[0, 0, 1],\n",
    "                                    [1, 1, 0]],\n",
    "                                   [[1, 1, 0],\n",
    "                                    [0, 0, 1]],\n",
    "                                   [[1, 0, 1],\n",
    "                                    [0, 1, 0]]])\n",
    "\n",
    "# BxMxM\n",
    "memory = torch.FloatTensor([[[1,0,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[.5,.5,0], [1,0,0], [0,0,1]]])\n",
    "\n",
    "# BxRxM\n",
    "registers = torch.FloatTensor([[[.4, .5, .1], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .5, .1], [.6, .2, .2]]])\n",
    "\n",
    "#BxM\n",
    "IR = torch.FloatTensor([[.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .4, .5]])\n",
    "                                            \n",
    "    \n",
    "c = Controller(instructions, arg1, arg2, out, memory, registers, IR, 0.5, 3, .3, .3, .3, .1)\n",
    "output = c()\n",
    "print(output)\n",
    "\n",
    "# def __init(self, instructions, arg1, arg2, out, memory, \n",
    "#                registers, IR, 0.5):\n",
    "\n",
    "# kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mini-test\n",
    "# M=3, R=2, N=11, B=4\n",
    "machine = Machine(4, 3, 2)\n",
    "e = Variable(torch.FloatTensor([[.1,.1,.1,.1,.1,.1,.1,.1,.1,.05,.05],\n",
    "                                [0,0,.6,.05,.05,.05,.05,.05,.05,.05,.05],\n",
    "                                [0,0,.6,.05,.05,.05,.05,.05,.05,.05,.05],\n",
    "                                [0,0,.05,.05,.05,.05,.6,.05,.05,.05,.05]])) \n",
    "a = Variable(torch.FloatTensor([[.1, .9],\n",
    "                                [.3, .7],\n",
    "                                [.3, .7],\n",
    "                                [.7, .3]]))\n",
    "b = Variable(torch.FloatTensor([[.8, .2],\n",
    "                                [.5, .5],\n",
    "                                [.5, .5],\n",
    "                                [.9, .1]]))\n",
    "o = Variable(torch.FloatTensor([[.6, .4],\n",
    "                                [.6, .4],\n",
    "                                [.6, .4],\n",
    "                                [.6, .4]]))\n",
    "memory = Variable(torch.FloatTensor([[[1,0,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[.5,.5,0], [1,0,0], [0,0,1]]]))\n",
    "registers = Variable(torch.FloatTensor([[[.4, .5, .1], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .5, .1], [.6, .2, .2]]]))\n",
    "IR = Variable(torch.FloatTensor([[.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .4, .5]]))\n",
    "mem, regs, ir, stop = machine(e, a, b, o, memory, registers, IR)\n",
    "print(\"MEM\", mem)\n",
    "print(\"REGS\", regs)\n",
    "print(\"IR\", ir)\n",
    "print(\"STOP\", stop)\n",
    "\n",
    "# # M=4, R=2, N=11\n",
    "# machine = Machine(3, 2, .5)\n",
    "# e = Variable(torch.FloatTensor([.1,.1,.1,.1,.1,.1,.1,.1,.1,.05,.05])) \n",
    "# a = Variable(torch.FloatTensor([.1, .9]))\n",
    "# b = Variable(torch.FloatTensor([.8, .2]))\n",
    "# o = Variable(torch.FloatTensor([.6, .4]))\n",
    "# memory = Variable(torch.FloatTensor([[1,0,0], [1,0,0], [0,0,1]]))\n",
    "# registers = Variable(torch.FloatTensor([[.4, .5, .1], [.2, .6, .2]]))\n",
    "# IR = Variable(torch.FloatTensor([.1, .9, .1]))\n",
    "# mem, regs, ir = machine(e, a, b, o, memory, registers, IR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASKS \n",
    "# - Compilation\n",
    "# - Train function\n",
    "# - Blurring\n",
    "# - Loss\n",
    "# - Running the tests they ran, verifying that we get similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Controller()\n",
    "# lower_seq_length = 3\n",
    "# upper_seq_length = 10\n",
    "# num_batches = 10000\n",
    "\n",
    "# dataset = CopyTaskDataset(num_batches, batch_size, lower_seq_length, upper_seq_length, seq_size)\n",
    "# data_loader = data.DataLoader(dataset, batch_size=batch_size)\n",
    "# def train_model(model, dset_loader, training_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
