{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains the two learnable parts of the model in four independent, fully connected layers.\n",
    "    First the initial values for the registers and instruction registers and second the \n",
    "    parameters that computes the required distributions. \n",
    "    \"\"\"\n",
    "    def __init(self, program_matrix1, program_matrix2, program_matrix3, program_matrix4, initial_memory, \n",
    "               initial_registers, instruction_register, stop_threshold):\n",
    "        \"\"\"\n",
    "        Initializes registers, memory and register matrix and their dimensions \n",
    "        Initializes four program matrices one of dimension NxM and three of dimension RxM\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        self.program_matrix1 = nn.Parameter(program_matrix1)\n",
    "        self.program_matrix2 = nn.Parameter(program_matrix2)\n",
    "        self.program_matrix3 = nn.Parameter(program_matrix3)\n",
    "        self.program_matrix4 = nn.Parameter(program_matrix4)    \n",
    "        \n",
    "        # Memory matrix (M x M)\n",
    "        self.memory = initial_memory\n",
    "        \n",
    "        # Register Matrix (R x M)\n",
    "        self.registers = initial_registers\n",
    "        \n",
    "        # Instruction Register (M)\n",
    "        self.IR = instruction_register\n",
    "        \n",
    "        # Machine initialization\n",
    "        self.Machine = Machine(M, R, stop_threshold)\n",
    "                \n",
    "    def forward(self):\n",
    "        einput = torch.bmm(self.program_matrix1, self.IR)\n",
    "        ainstruction = torch.bmm(self.program_matrix2, self.IR)\n",
    "        binstruction = torch.bmm(self.program_matrix3, self.IR)\n",
    "        outputin = torch.bmm(self.program_matrix4, self.IR)\n",
    "        \n",
    "        # Updating memory, registers, and IR after machine operation\n",
    "        self.memory, self.registers, self.IR, self.stop = self.Machine\n",
    "        (einput, ainstruction, binstruction, outputin, memory, registers, IR)\n",
    "                \n",
    "        \n",
    "    def lossfunctions(self, cmatrix, tjmatrix):\n",
    "        \"\"\" compute four different loss functions and return a weighted average of the four measuring correctness, \n",
    "        halting, efficiency, and confidence\"\"\"\n",
    "        sum ((cmatrix)*(self.program_matrix4 - self.memory)^2)\n",
    "        ### need to add loss functions::: mehdi需要帮我们\n",
    "        救命\n",
    "        \n",
    "        \n",
    "# HOW TO BLUR? ==> Add a constant, then softmax\n",
    "#TODO: Add in some fuzz factor????\n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    Parent class for our binary operations\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Initialize the memory length (needed so we can mod our answer in case it exceeds the range 0-M-1)\n",
    "        \n",
    "        :param M: Memory length\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M #TODO: Check this gets updated!\n",
    "        self.outputs = torch.zeros(M, M, M)\n",
    "        for i in range(M):\n",
    "            for j in range(M):\n",
    "                val = self.compute(i, j)\n",
    "                self.outputs[val][i][j] = 1\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        \"\"\" \n",
    "        Perform the binary operation.  The arguments may or may not be used.\n",
    "        \n",
    "        :param x: First argument\n",
    "        :param y: Second argument\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        return (x + y) % self.M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0 # Actual jump happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decrement(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Decrement, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x - 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Increment(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Increment, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x + 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Max, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return max(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Min(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Min, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Read, self).__init__(M)\n",
    "        self.outputs = torch.zeros(M, M, M) # Clear output matrix out since we're gonna do the reading elsewhere\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return 0 # Actual reading happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subtract(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Subtract, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return (x - y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Write(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Write, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return 0 # Actual write happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Zero, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    The Machine executes assembly instructions passed to it by the Controller.\n",
    "    It updates the given memory, registers, and instruction pointer.\n",
    "    The Machine doesn't have any learnable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, B, M, R, stop_threshold):\n",
    "        \"\"\"\n",
    "        Initializes dimensions, operations, and counters\n",
    "        \n",
    "        :param M: Memory length.  Integer values also take on values 0-M-1.  M is also the program length.\n",
    "        :param R: Number of registers\n",
    "        :stop_threshold: Accumulated probability of stopping after which the program terminates.\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        \n",
    "        # Store parameters as class variables\n",
    "        self.R = R # Number of registers\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.B = B # Batch size\n",
    "        self.stop_threshold = stop_threshold\n",
    "        \n",
    "        # Start off with 0 probability of stopping\n",
    "        self.stop_probability = torch.zeros(B)\n",
    "        \n",
    "        # A list of all our possible ops\n",
    "        self.ops = [\n",
    "            Jump(M), \n",
    "            Stop(M), \n",
    "            Write(M), \n",
    "            Read(M), \n",
    "            Add(M), \n",
    "            Subtract(M), \n",
    "            Increment(M),\n",
    "            Decrement(M),\n",
    "            Min(M),\n",
    "            Max(M),\n",
    "            Zero(M)\n",
    "        ]\n",
    "        \n",
    "        # Number of instructions\n",
    "        self.N = len(self.ops)\n",
    "        \n",
    "        self.outputs = Variable(torch.zeros(self.N, M, M, M))\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            op = self.ops[i]\n",
    "            self.outputs[i] = op()\n",
    "            \n",
    "            \n",
    "        self.outputs = torch.unsqueeze(self.outputs, 0)\n",
    "        self.outputs = self.outputs.expand(B, -1, -1, -1, -1)\n",
    "        \n",
    "        # Keep track of the index of certain ops which are dealt with specially\n",
    "        self.jump_index = 0\n",
    "        self.stop_index = 1\n",
    "        self.write_index = 2\n",
    "        self.read_index = 3\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \n",
    "        \"\"\"\n",
    "        Run the Machine for one timestep (corresponding to the execution of one line of Assembly).\n",
    "        The first four parameter names correspond to the vector names used in the original ANC paper\n",
    "        \n",
    "        :param e: Probability distribution over the instruction being executed (length M)\n",
    "        :param a: Probability distribution over the first argument register (length R)\n",
    "        :param b: Probability distribution over the second argument register (length R)\n",
    "        :param o: Probability distribution over the first argument register (length R)\n",
    "        :param memory: Memory matrix (size M x M)\n",
    "        :param registers: Register matrix (size R x M)\n",
    "        :param IR: Instruction Register (length M)\n",
    "        \n",
    "        :return: The memory, registers, and instruction register after the timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Give all vectors an extra dimension\n",
    "        \n",
    "        # Dimensions B x R -> B x 1 x R\n",
    "        a = torch.unsqueeze(a, 1)\n",
    "        b = torch.unsqueeze(b, 1)\n",
    "        \n",
    "        \n",
    "        # Calculate distributions over the two argument values by multiplying each \n",
    "        # register by the probability that register is being used.\n",
    "        arg1 = torch.bmm(a, registers)\n",
    "        arg2 = torch.bmm(b, registers)\n",
    "        \n",
    "        \n",
    "        # Arg1 dimensions: B x 1 x M --> B x 1 x 1 x 1 x 3\n",
    "        arg1_long = torch.unsqueeze(arg1, 1)\n",
    "        arg1_long = torch.unsqueeze(arg1_long, 1)\n",
    "        \n",
    "        \n",
    "        # A bunch of matrix-y stuff \n",
    "        #arg1: BxMx1; Outputs = NxMxMxM\n",
    "\n",
    "        x = torch.matmul(arg1_long, self.outputs)\n",
    "        \n",
    "        # x dimensions: B x N x M x 1 x M -> B x N x M x M\n",
    "        x = torch.squeeze(x, 3)\n",
    "        \n",
    "        # Arg2 dimensions: B x 1 x M --> B x 1 x M x 1\n",
    "        arg2_long = torch.unsqueeze(arg2, 3)\n",
    "        \n",
    "        \n",
    "        y = torch.matmul(x, arg2_long)\n",
    "        \n",
    "        # y dimensions: B x N x M x 1 -> B x N x M\n",
    "        y = torch.squeeze(y, 3)\n",
    "        \n",
    "        # Dimensions B x N -> B x 1 x N\n",
    "        e = torch.unsqueeze(e, 1)\n",
    "        read_vec =  e[:, :, self.read_index]\n",
    "        # Dimensions B x 1 -> B x 1 x 1\n",
    "        read_vec = read_vec.unsqueeze(1)\n",
    "        \n",
    "        out_vec = torch.matmul(e, y) # Length M vector over the output of the operation\n",
    "        # Deal with memory reads separately\n",
    "        out_vec = out_vec + read_vec * torch.matmul(arg1, memory)        \n",
    "        torch.Size([4, 1, 3])\n",
    "        \n",
    "        # Update our memory, registers, instruction register, and stopping probability\n",
    "        memory = self.writeMemory(e, memory, arg1, arg2)\n",
    "        registers = self.writeRegisters(out_vec, o, registers)\n",
    "        IR = self.updateIR(e, IR, arg1, arg2)\n",
    "        should_stop = self.updateStop(e)\n",
    "        \n",
    "        return(memory, registers, IR, should_stop)\n",
    "        \n",
    "        \n",
    "    def writeRegisters(self, out, o, registers):\n",
    "        \"\"\"\n",
    "        Write the result of our operation to our registers.\n",
    "        \n",
    "        :param out: probability distribution over the output value\n",
    "        :param o: probability distribution over the output register\n",
    "        :param registers: register matrix\n",
    "        \n",
    "        :return: the updated registers\n",
    "        \"\"\"\n",
    "        # Multiply probability of writing to each output register by the value \n",
    "        \n",
    "        # o dimensions: B x R -> B x R x 1\n",
    "        o = torch.unsqueeze(o, 2)\n",
    "        \n",
    "        new_register_vals = torch.matmul(o, out)\n",
    "        # Multiply each original register cell by the probabilty of not writing to that register\n",
    "        old_register_vals = (1-o).expand(self.B, self.R, self.M) * registers\n",
    "        \n",
    "        registers =  new_register_vals + old_register_vals\n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the instruction register\n",
    "        \n",
    "        :param e: distribution over the current instruction (length N)\n",
    "        :param IR: instruction register (length M)\n",
    "        :param arg1: distribution over the first argument value (length M)\n",
    "        :param arg2: distribution over the second argument value (length M)\n",
    "        \n",
    "        :return: the updated instruction register\n",
    "        \"\"\"\n",
    "        # IR - length M vector\n",
    "        jump_probability = e[:, :, self.jump_index]\n",
    "        \n",
    "        is_zero = arg1[:, :, 0]\n",
    "        # Slicing lost a dimension.  Let's add it back\n",
    "        jump_probability = torch.unsqueeze(jump_probability, 1)\n",
    "        is_zero = torch.unsqueeze(is_zero, 1)\n",
    "        \n",
    "        \n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        wraparound = IR[:, -1]\n",
    "        normal_instructions = IR[:, :-1]\n",
    "        \n",
    "        # for whatever reason, when you chop off one row/column, that dimension disappears\n",
    "        # add it back\n",
    "        wraparound = wraparound.unsqueeze(1)\n",
    "        IR_no_jump = torch.cat([wraparound, normal_instructions], 1)\n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        return IR\n",
    "    \n",
    "    def writeMemory(self, e, mem_orig, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the memory\n",
    "        \n",
    "        :param e: distribution over the current instruction (B x 1 x M)\n",
    "        :param mem_orig: current memory matrix (B x M x M)\n",
    "        :param arg1: distribution over the first argument value (B x 1 x M)\n",
    "        :param arg2: distribution over the second argument value (B x 1 x M)\n",
    "        \n",
    "        :return: the updated memory matrix\n",
    "        \"\"\"\n",
    "        write_probability = e[:,:, self.write_index]\n",
    "        # Write_prob dimensions: B x 1 x 1\n",
    "        write_probability = torch.unsqueeze(write_probability, 1)\n",
    "        \n",
    "        # Arg1 dimensions: B x 1 x M -> B x M x 1\n",
    "        arg1 = torch.transpose(arg1, 1, 2)\n",
    "        \n",
    "        # If we are on a write instruction, write the value arg2 in register arg1. Otherwise, leave memory as is.\n",
    "        mem_write = torch.bmm(arg1, arg2) \n",
    "        temp3 = 1 - write_probability\n",
    "        memory = mem_orig * (1 - write_probability) + mem_write * write_probability\n",
    "        return memory\n",
    "        \n",
    "    def updateStop(self, e):\n",
    "        \"\"\"\n",
    "        Update the probability that we will stop at this timestep based on the probability that we are running the STOP op.\n",
    "        \n",
    "        :param e: distribution over the current instruction (length M)\n",
    "        \n",
    "        :return: boolean representing whether the controller should stop.\n",
    "        \"\"\"\n",
    "        self.stop_probability += e[:, :, self.stop_index].data[0]\n",
    "        return (self.stop_probability > self.stop_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n",
      "\n",
      "AAAAAA\n",
      "\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "0.5\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.ByteTensor of size 4]\n",
      "\n",
      "MEM Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.9079  0.0114  0.0026\n",
      "  0.9212  0.0307  0.0071\n",
      "  0.0068  0.0099  0.9023\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0468  0.4546  0.0546\n",
      "  0.4810  0.0945  0.0945\n",
      "  0.0522  0.0609  0.4609\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.0468  0.4546  0.0546\n",
      "  0.4810  0.0945  0.0945\n",
      "  0.0522  0.0609  0.4609\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.4847  0.4858  0.0025\n",
      "  0.9586  0.0096  0.0023\n",
      "  0.0027  0.0031  0.9507\n",
      "[torch.FloatTensor of size 4x3x3]\n",
      "\n",
      "REGS Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.5373  0.3134  0.1493\n",
      "  0.3715  0.4356  0.1929\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.6227  0.1080  0.2693\n",
      "  0.4285  0.4053  0.1662\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.6227  0.1080  0.2693\n",
      "  0.4285  0.4053  0.1662\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.3457  0.4234  0.2309\n",
      "  0.4838  0.2689  0.2473\n",
      "[torch.FloatTensor of size 4x2x3]\n",
      "\n",
      "IR Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.1057  0.1092  0.8828\n",
      "  0.1057  0.1092  0.8828\n",
      "  0.1057  0.1092  0.8828\n",
      "  0.4969  0.1092  0.3938\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.5000  0.1000  0.4000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.5000  0.1000  0.4000\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.1000  0.1000  0.9000\n",
      "  0.5000  0.1000  0.4000\n",
      "[torch.FloatTensor of size 4x4x3]\n",
      "\n",
      "STOP \n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.ByteTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mini-test\n",
    "# M=3, R=2, N=11, B=4\n",
    "machine = Machine(4, 3, 2, .5)\n",
    "e = Variable(torch.FloatTensor([[.1,.1,.1,.1,.1,.1,.1,.1,.1,.05,.05],\n",
    "                                [0,0,.6,.05,.05,.05,.05,.05,.05,.05,.05],\n",
    "                                [0,0,.6,.05,.05,.05,.05,.05,.05,.05,.05],\n",
    "                                [0,0,.05,.05,.05,.05,.6,.05,.05,.05,.05]])) \n",
    "a = Variable(torch.FloatTensor([[.1, .9],\n",
    "                                [.3, .7],\n",
    "                                [.3, .7],\n",
    "                                [.7, .3]]))\n",
    "b = Variable(torch.FloatTensor([[.8, .2],\n",
    "                                [.5, .5],\n",
    "                                [.5, .5],\n",
    "                                [.9, .1]]))\n",
    "o = Variable(torch.FloatTensor([[.6, .4],\n",
    "                                [.6, .4],\n",
    "                                [.6, .4],\n",
    "                                [.6, .4]]))\n",
    "memory = Variable(torch.FloatTensor([[[1,0,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[0,1,0], [1,0,0], [0,0,1]],\n",
    "                                     [[.5,.5,0], [1,0,0], [0,0,1]]]))\n",
    "registers = Variable(torch.FloatTensor([[[.4, .5, .1], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .1, .5], [.2, .6, .2]],\n",
    "                                        [[.4, .5, .1], [.6, .2, .2]]]))\n",
    "IR = Variable(torch.FloatTensor([[.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .9, .1],\n",
    "                                 [.1, .4, .5]]))\n",
    "mem, regs, ir, stop = machine(e, a, b, o, memory, registers, IR)\n",
    "print(\"MEM\", mem)\n",
    "print(\"REGS\", regs)\n",
    "print(\"IR\", ir)\n",
    "print(\"STOP\", stop)\n",
    "\n",
    "# # M=4, R=2, N=11\n",
    "# machine = Machine(3, 2, .5)\n",
    "# e = Variable(torch.FloatTensor([.1,.1,.1,.1,.1,.1,.1,.1,.1,.05,.05])) \n",
    "# a = Variable(torch.FloatTensor([.1, .9]))\n",
    "# b = Variable(torch.FloatTensor([.8, .2]))\n",
    "# o = Variable(torch.FloatTensor([.6, .4]))\n",
    "# memory = Variable(torch.FloatTensor([[1,0,0], [1,0,0], [0,0,1]]))\n",
    "# registers = Variable(torch.FloatTensor([[.4, .5, .1], [.2, .6, .2]]))\n",
    "# IR = Variable(torch.FloatTensor([.1, .9, .1]))\n",
    "# mem, regs, ir = machine(e, a, b, o, memory, registers, IR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASKS \n",
    "# - Compilation\n",
    "# - Train function\n",
    "# - Blurring\n",
    "# - Running the tests they ran, verifying that we get similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Controller()\n",
    "# lower_seq_length = 3\n",
    "# upper_seq_length = 10\n",
    "# num_batches = 10000\n",
    "\n",
    "# dataset = CopyTaskDataset(num_batches, batch_size, lower_seq_length, upper_seq_length, seq_size)\n",
    "# data_loader = data.DataLoader(dataset, batch_size=batch_size)\n",
    "# def train_model(model, dset_loader, training_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
