{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/oliviawatkins/Documents/Schoolwork/NN/neural_nets_research\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets_library import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains the two learnable parts of the model in four independent, fully connected layers.\n",
    "    First the initial values for the registers and instruction registers and second the \n",
    "    parameters that computes the required distributions. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 first_arg = None, \n",
    "                 second_arg = None, \n",
    "                 output = None, \n",
    "                 instruction = None, \n",
    "                 initial_registers = None, \n",
    "                 stop_threshold = .99, \n",
    "                 blur = 3, \n",
    "                 correctness_weight = .25, \n",
    "                 halting_weight = .25, \n",
    "                 confidence_weight = .25, \n",
    "                 efficiency_weight = .25,\n",
    "                 t_max = 100):\n",
    "        #TODO: Read over ANC paper, check if there are more reasonable default initial values.\n",
    "        \"\"\"\n",
    "        Initialize a bunch of constants and pass in matrices defining a program.\n",
    "        \n",
    "        :param first_arg: Matrix with the 1st register argument for each timestep stored in the columns (1xRxM)\n",
    "        :param second_arg: Matrix with the 2nd register argument for each timestep stored in the columns (1xRxM)\n",
    "        :param output: Matrix with the output register for each timestep stored in the columns (1xRxM)\n",
    "        :param instruction: Matrix with the instruction for each timestep stored in the columns (1xNxM)\n",
    "        :param initial_registers: Matrix where each row is a distribution over the value in one register (1xRxM)\n",
    "        :param stop_threshold: The stop probability threshold at which the controller should stop running\n",
    "        :param blur: The factor our one-hot vectors are be multiplied by before they're softmaxed to add blur\n",
    "        :param correctness_weight: Weight given to the correctness component of the loss function\n",
    "        :param halting_weight: Weight given to the halting component of the loss function\n",
    "        :param confidence_weight: Weight given to the confidence component of the loss function\n",
    "        :param efficiency_weight: Weight given to the efficiency component of the loss function\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        \n",
    "        # Initialize dimension constants\n",
    "        B, R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        # Initialize loss function weights\n",
    "        # In the ANC paper, these scalars are called, alpha, beta, gamma, and delta\n",
    "        self.correctness_weight = correctness_weight\n",
    "        self.halting_weight = halting_weight\n",
    "        self.confidence_weight = confidence_weight\n",
    "        self.efficiency_weight = efficiency_weight\n",
    "        \n",
    "        # And yet more initialized constants... yeah, there are a bunch, I know.\n",
    "        self.t_max = t_max\n",
    "        self.blur_factor = blur\n",
    "        self.stop_threshold = stop_threshold\n",
    "        \n",
    "        # Blur matrices - i.e. give each different operation/argument/register value some nonzero probability\n",
    "        if blur is not None:\n",
    "            first_arg = self.blur(first_arg, blur, 1)\n",
    "            second_arg = self.blur(second_arg, blur, 1)\n",
    "            output = self.blur(output, blur, 1)\n",
    "            instruction = self.blur(instruction, blur, 1)\n",
    "            initial_registers = self.blur(initial_registers, blur, 2)\n",
    "            \n",
    "        # Initialize parameters.  These are the things that are going to be optimized. \n",
    "        self.first_arg = nn.Parameter(first_arg.data)\n",
    "        self.second_arg = nn.Parameter(second_arg.data)\n",
    "        self.output = nn.Parameter(output.data)\n",
    "        self.instruction = nn.Parameter(instruction.data) \n",
    "        self.registers = nn.Parameter(initial_registers.data)\n",
    "        \n",
    "        # Machine initialization\n",
    "        self.machine = Machine(B, M, R)\n",
    "    \n",
    "    def blur(self, matrix, scale_factor, dimension):\n",
    "        \"\"\"\n",
    "        Takes a matrix, each row (or column) of which is a one-hot vector.\n",
    "        Multiply each 1 by a constant and then softmax it, which \n",
    "        effectively \"blurs\" the matrix a little bit.\n",
    "        \n",
    "        :param matrix: Matrix to blur\n",
    "        :param scale_factor: Constant to multiply the matrix by before it's softmaxed\n",
    "        :param dimension: Dimension to softmax over\n",
    "        \n",
    "        :return: Blurred matrix\n",
    "        \"\"\"\n",
    "        matrix = scale_factor * matrix\n",
    "        softmax = nn.Softmax(dimension)\n",
    "        return softmax(Variable(matrix))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, input, train):\n",
    "        \"\"\"\n",
    "        Runs the controller on a certain input memory matrix.\n",
    "        It either returns the loss or the output memory.\n",
    "        \n",
    "        :param input: A three-tuple of three MxM matrices: (memory matrix, output_memory, output_mask)\n",
    "        \n",
    "        :return: If train is true, return the loss. Otherwise, return the output matrix\n",
    "        \"\"\"\n",
    "        # Program's initial memory\n",
    "        self.memory = input[0]\n",
    "        # Desired output memory\n",
    "        self.output_memory = input[1]\n",
    "        # Mask with 1's in the rows of the output memory matrix which actually contain the answer.\n",
    "        self.output_mask = input[2]\n",
    "        \n",
    "        # Initialize instruction regiser (1xMx1)\n",
    "        self.register_buffer('IR', torch.zeros(1, M, 1))\n",
    "        self.IR[0, 0, 0] = 1\n",
    "        \n",
    "        # Blur memory and instruction register\n",
    "        if self.blur_factor is not None:\n",
    "            self.memory = self.blur(self.memory, self.blur_factor, 2) \n",
    "            IR = self.blur(self.IR, self.blur_factor, 1)\n",
    "        \n",
    "        efficiency_loss = 0\n",
    "        confidence_loss = 0\n",
    "        self.stop_probability = 0\n",
    "        \n",
    "        # Copy registers so we aren't using the values from the previous iteration.\n",
    "        registers = self.registers\n",
    "        \n",
    "        t = 0 \n",
    "        # Run the program, one timestep at a time, until the program terminates or whe time out\n",
    "        while t < self.t_max and self.stop_probability < self.stop_threshold: \n",
    "            a = torch.bmm(self.first_arg, IR)\n",
    "            b = torch.bmm(self.second_arg, IR)\n",
    "            o = torch.bmm(self.output, IR)\n",
    "            e = torch.bmm(self.instruction, IR)\n",
    "            \n",
    "            # Update memory, registers, and IR after machine operation\n",
    "            self.memory, registers, IR, stop_prob = self.machine(e, a, b, o, self.memory, registers, IR)\n",
    "            self.stop_probability = self.stop_probability + stop_prob[0]            \n",
    "            \n",
    "            # If we're training, calculate loss\n",
    "            if train:\n",
    "                new_efficiency, new_confidence = self.timestep_loss()\n",
    "                efficiency_loss += new_efficiency\n",
    "                confidence_loss += new_confidence\n",
    "            \n",
    "            t += 1\n",
    "        \n",
    "        # If we're training, return loss.  Otherwise return memory.\n",
    "        if train:\n",
    "            correctness_loss, halting_loss = self.final_loss()\n",
    "            total_loss  = (\n",
    "                self.correctness_weight * correctness_loss + \n",
    "                self.halting_weight * halting_loss + \n",
    "                self.confidence_weight * confidence_loss + \n",
    "                self.efficiency_weight * efficiency_loss)\n",
    "            return (self.memory, torch.sum(self.registers)) #total_loss #TODO: Aditya @ Rakia - implement loss, then replace this\n",
    "        else:\n",
    "            return (self.memory, None)\n",
    "        \n",
    "        \n",
    "    def timestep_loss(self):\n",
    "        \"\"\"\n",
    "        @ Rakia @ Aditya feel free to use this function definition or not.  My main thought was that this would \n",
    "        compute the types of loss which get updated every timestep.\n",
    "        \"\"\"\n",
    "        # TODO: Insert losses\n",
    "        return (1,1)\n",
    "    \n",
    "    def final_loss(self):\n",
    "        \"\"\"\n",
    "        @ Rakia @ Aditya feel free to use this function definition or not.  My main thought was that this would \n",
    "        compute the types of loss which get updated every timestep.\n",
    "        \"\"\"\n",
    "        # TODO: insert losses\n",
    "        return (1,1)\n",
    "   \n",
    "\n",
    "    def lossfunctions(self, cmatrix, tjmatrix):\n",
    "        \"\"\" compute four diferent loss functions and return a weighted average of the four measuring correctness, \n",
    "        halting, efficiency, and confidence\"\"\"\n",
    "        \n",
    "        self.matrix1 = ((cmatrix)*(self.program_matrix4 - self.memory)^2)\n",
    "        self.correctness += self.matrix1\n",
    "        \n",
    "        \n",
    "            \n",
    "        self.efficiency += (1-self.stop_probability[self.t])\n",
    "        \n",
    "        self.confidence += torch.matmult(self.stop_probability[self.t] - self.stop_probability[self.t -1], matrix1)\n",
    "        \n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    Parent class for our binary operations\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Initialize the memory length (needed so we can mod our answer in case it exceeds the range 0-M-1)\n",
    "        Also calculate the output matrix for the operation\n",
    "        \n",
    "        :param M: Memory length\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M\n",
    "        \n",
    "        # Create a MxMxM matrix where the (i,j,k) cell is 1 iff operation(i,j) = k.\n",
    "        self.outputs = Variable(torch.zeros(M, M, M))\n",
    "        for i in range(M):\n",
    "            for j in range(M):\n",
    "                val = self.compute(i, j)\n",
    "                self.outputs[val][i][j] = 1\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        \"\"\" \n",
    "        Perform the binary operation.  The arguments may or may not be used.\n",
    "        \n",
    "        :param x: First argument\n",
    "        :param y: Second argument\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        :return: The output matrix\n",
    "        \"\"\"\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        return (x + y) % self.M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0 # Actual jump happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decrement(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Decrement, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x - 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Increment(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Increment, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x + 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Max, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return max(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Min(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Min, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Read, self).__init__(M)\n",
    "        self.outputs = Variable(torch.zeros(M, M, M)) # Leave output matrix blank since we're gonna do the reading elsewhere\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return 0 # Actual reading happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subtract(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Subtract, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return (x - y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Write(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Write, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return 0 # Actual write happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Zero, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    The Machine executes assembly instructions passed to it by the Controller.\n",
    "    It updates the given memory, registers, and instruction pointer.\n",
    "    The Machine doesn't have any learnable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, B, M, R):\n",
    "        \"\"\"\n",
    "        Initializes dimensions, operations, and counters\n",
    "        \n",
    "        :param B: Batch size (meant to be 1)\n",
    "        :param M: Memory length.  Integer values also take on values 0-M-1.  M is also the program length.\n",
    "        :param R: Number of registers\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        \n",
    "        # Store parameters as class variables\n",
    "        self.R = R # Number of registers\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.B = B # Batch size\n",
    "        \n",
    "        # Start off with 0 probability of stopping\n",
    "        self.stop_probability = torch.zeros(B)\n",
    "        \n",
    "        # List of ops (must be in same order as the original ANC paper so compilation works right)\n",
    "        self.ops = [ \n",
    "            Stop(M),\n",
    "            Zero(M),\n",
    "            Increment(M),\n",
    "            Add(M),\n",
    "            Subtract(M),\n",
    "            Decrement(M),\n",
    "            Min(M),\n",
    "            Max(M),\n",
    "            Read(M),\n",
    "            Write(M),\n",
    "            Jump(M)\n",
    "        ]\n",
    "        \n",
    "        # Number of instructions\n",
    "        self.N = len(self.ops)\n",
    "        \n",
    "        # Create a 4D matrix composed of the output matrices of each of the ops\n",
    "        self.outputs = Variable(torch.zeros(self.N, M, M, M))\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            op = self.ops[i]\n",
    "            self.outputs[i] = op()\n",
    "            \n",
    "        # Add an extra batch dimension\n",
    "        self.outputs = torch.unsqueeze(self.outputs, 0)\n",
    "        self.outputs = self.outputs.expand(B, -1, -1, -1, -1)\n",
    "        \n",
    "        # Keep track of ops which will be handled specially\n",
    "        self.jump_index = 10\n",
    "        self.stop_index = 0\n",
    "        self.write_index = 9\n",
    "        self.read_index = 8\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \n",
    "        \"\"\"\n",
    "        Run the Machine for one timestep (corresponding to the execution of one line of Assembly).\n",
    "        The first four parameter names correspond to the vector names used in the original ANC paper\n",
    "        \n",
    "        :param e: Probability distribution over the instruction being executed (BxMx1)\n",
    "        :param a: Probability distribution over the first argument register (length BxRx1)\n",
    "        :param b: Probability distribution over the second argument register (length BxRx1)\n",
    "        :param o: Probability distribution over the first argument register (length BxRx1)\n",
    "        :param memory: Memory matrix (size BxMxM)\n",
    "        :param registers: Register matrix (size BxRxM)\n",
    "        :param IR: Instruction Register (length BxM)\n",
    "        \n",
    "        :return: The memory, registers, and instruction register after the timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dimensions B x 1 x R -> B x 1 x R\n",
    "        a = torch.transpose(a, 1, 2)\n",
    "        b = torch.transpose(b, 1, 2)\n",
    "        \n",
    "        # Calculate distributions over the two argument values by multiplying each \n",
    "        # register by the probability that register is being used.\n",
    "        arg1 = torch.bmm(a, registers)\n",
    "        arg2 = torch.bmm(b, registers)\n",
    "        \n",
    "        # Multiply the output matrix by the arg1 and arg2 vectors to take into account\n",
    "        # Before we do this, we're going to have to do a bunch of dimension squishing.\n",
    "        \n",
    "        # arg1_long dimensions: B x 1 x M --> B x 1 x 1 x 1 x M\n",
    "        arg1_long = torch.unsqueeze(arg1, 1)\n",
    "        arg1_long = torch.unsqueeze(arg1_long, 1)\n",
    "        \n",
    "        outputs_x_arg1 = torch.matmul(arg1_long, self.outputs)\n",
    "        \n",
    "        # outputs_x_arg1 dimensions: B x N x M x 1 x M -> B x N x M x M\n",
    "        outputs_x_arg1 = torch.squeeze(outputs_x_arg1, 3)\n",
    "        \n",
    "        # arg2_long dimensions: B x 1 x M --> B x 1 x M x 1\n",
    "        arg2_long = torch.unsqueeze(arg2, 3)\n",
    "        \n",
    "        outputs_x_args = torch.matmul(outputs_x_arg1, arg2_long)\n",
    "        \n",
    "        # outputs_x_args dimensions: B x N x M x 1 -> B x N x M\n",
    "        outputs_x_args = torch.squeeze(outputs_x_args, 3)\n",
    "        \n",
    "        # e dimensions B x N x 1 -> B x 1 x N\n",
    "        e = torch.transpose(e, 1, 2)\n",
    "        \n",
    "        # read_vec dimensions B x 1 -> B x 1 x 1\n",
    "        read_vec =  e[:, :, self.read_index]\n",
    "        read_vec = read_vec.unsqueeze(1)\n",
    "        \n",
    "        # Length Bx1xM vector over the output of the operation\n",
    "        out_vec = torch.matmul(e, outputs_x_args)\n",
    "        \n",
    "        # Deal with memory reads separately\n",
    "        out_vec = out_vec + read_vec * torch.matmul(arg1, memory)        \n",
    "        \n",
    "        # Update our memory, registers, instruction register, and stopping probability\n",
    "        memory = self.writeMemory(e, o, memory, arg1, arg2)\n",
    "        registers = self.writeRegisters(out_vec, o, registers)\n",
    "        IR = self.updateIR(e, IR, arg1, arg2)\n",
    "        stop_prob = self.getStop(e)\n",
    "        \n",
    "        return(memory, registers, IR, stop_prob)\n",
    "        \n",
    "        \n",
    "    def writeRegisters(self, out, o, registers):\n",
    "        \"\"\"\n",
    "        Write the result of our operation to our registers.\n",
    "        \n",
    "        :param out: Probability distribution over the output value (Bx1xM)\n",
    "        :param o: Probability distribution over the output register (BxRx1)\n",
    "        :param Registers: register matrix (BxRxM)\n",
    "        \n",
    "        :return: The updated registers (BxRxM)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Multiply probability of writing to each output register by the distribution over the value we're writing there.\n",
    "        new_register_vals = torch.matmul(o, out)\n",
    "        \n",
    "        # Multiply each original register cell by the probabilty of not writing to that register\n",
    "        old_register_vals = (1-o).expand(self.B, self.R, self.M) * registers\n",
    "        \n",
    "        # Take a weighted sum over the old and new register values\n",
    "        registers =  new_register_vals + old_register_vals\n",
    "        \n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the instruction register\n",
    "        \n",
    "        :param e: Distribution over the current instruction (BxNx1)\n",
    "        :param IR: Instruction register (length BxMx1)\n",
    "        :param arg1: Distribution over the first argument value (length BxMx1)\n",
    "        :param arg2: Distribution over the second argument value (length BxMx1)\n",
    "        \n",
    "        :return: The updated instruction register (BxMx1)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dimensions B x 1 x M -> B x M x 1\n",
    "        arg2 = arg2.transpose(1, 2)\n",
    "        \n",
    "        # Probability that we're on the jump instruction\n",
    "        jump_probability = e[:, :, self.jump_index]\n",
    "        \n",
    "        # Probability that the first argument is 0\n",
    "        is_zero = arg1[:, :, 0]\n",
    "        \n",
    "        # Slicing lost a dimension.  Let's add it back\n",
    "        jump_probability = torch.unsqueeze(jump_probability, 1)\n",
    "        is_zero = torch.unsqueeze(is_zero, 1)\n",
    "        \n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        wraparound = IR[:, -1]\n",
    "        normal_instructions = IR[:, :-1]\n",
    "        \n",
    "        # For whatever reason, when you chop off one row/column, that dimension disappears.  Add it back.\n",
    "        wraparound = wraparound.unsqueeze(1)\n",
    "        IR_no_jump = torch.cat([wraparound, normal_instructions], 1)\n",
    "        \n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        # Take a weighted sum of the instruction register with and without jumping\n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        \n",
    "        return IR\n",
    "    \n",
    "    def writeMemory(self, e, o, mem_orig, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the memory\n",
    "        \n",
    "        :param e: Distribution over the current instruction (B x1xM)\n",
    "        :param mem_orig: Current memory matrix (BxMxM)\n",
    "        :param arg1: Distribution over the first argument value (Bx1xM)\n",
    "        :param arg2: Distribution over the second argument value (Bx1xM)\n",
    "        \n",
    "        :return: The updated memory matrix (BxMxM)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Probability that we're on the write instruction\n",
    "        write_probability = e[:,:, self.write_index]\n",
    "        \n",
    "        # write_probability dimensions: Bx1 -> B x 1 x 1\n",
    "        write_probability = torch.unsqueeze(write_probability, 1)\n",
    "        \n",
    "        # arg1 dimensions: B x 1 x M -> B x M x 1\n",
    "        arg1 = torch.transpose(arg1, 1, 2)\n",
    "        \n",
    "        # If we are on a write instruction, write the value arg2 in register arg1. Otherwise, leave memory as is.\n",
    "        mem_changed = torch.bmm(arg1, arg2)\n",
    "        mem_unchanged = mem_orig * (1-arg1).expand(-1, -1, self.M)\n",
    "        mem_write = mem_changed + mem_unchanged\n",
    "        \n",
    "        # Take a weighted sum over the new memory and old memory\n",
    "        memory = mem_orig * (1 - write_probability) + mem_write * write_probability\n",
    "\n",
    "        return memory\n",
    "        \n",
    "    def getStop(self, e):\n",
    "        \"\"\"\n",
    "        Obtain the probability that we will stop at this timestep based on the probability that we are running the STOP op.\n",
    "        \n",
    "        :param e: distribution over the current instruction (length Bx1xM)\n",
    "        \n",
    "        :return: probability representing whether the controller should stop.\n",
    "        \"\"\"\n",
    "        return e[:, :, self.stop_index].data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hotify(vec, length, dimension):\n",
    "    \"\"\"\n",
    "    Turn a tensor of integers into a matrix of one-hot vectors.\n",
    "    \n",
    "    :param vec: The vector to be converted.\n",
    "    :param length: One dimension of the matrix (the other is the length of vec)\n",
    "    :param dimension: Which dimension stores the elements of vec.  If 0, they're stored in the rows.  If 1, the columns.\n",
    "    \n",
    "    :return A matrix of one-hot vectors, each row or column corresponding to one element of vec\n",
    "    \"\"\"\n",
    "    x = vec.size()[0]\n",
    "    if dimension == 0:\n",
    "        binary_vec = torch.zeros(x, length)\n",
    "        for i in range(x):\n",
    "            binary_vec[i][vec[i]] = 1\n",
    "        return binary_vec\n",
    "    elif dimension == 1:\n",
    "        binary_vec = torch.zeros(length, x)\n",
    "        for i in range(x):\n",
    "            binary_vec[vec[i]][i] = 1\n",
    "        return binary_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition task\n",
    "# Generate this by running the instructions here (but with the addition program file): https://github.com/aditya-khant/neural-assembly-compiler\n",
    "# Then get rid of the .cuda in each of the tensors since we (or at least I) don't have cuda\n",
    "init_registers = torch.IntTensor([6,2,0,1,0,0]) # Length R, should be RxM\n",
    "first_arg = torch.IntTensor([4,3,3,3,4,2,2,5]) # Length M, should be RxM\n",
    "second_arg = torch.IntTensor([5,5,0,5,5,1,4,5]) # Length M, should be RxM\n",
    "target = torch.IntTensor([4,3,5,3,4,5,5,5]) # Length M, should be RxM\n",
    "instruction = torch.IntTensor([8,8,10,5,2,10,9,0]) # Length M, should be NxM\n",
    "\n",
    "# Get dimensions we'll need\n",
    "M = first_arg.size()[0]\n",
    "R = init_registers.size()[0]\n",
    "N = 11\n",
    "\n",
    "# Turn the given tensors into matrices of one-hot vectors.\n",
    "init_registers = one_hotify(init_registers, M, 0)\n",
    "first_arg = one_hotify(first_arg, R, 1)\n",
    "second_arg = one_hotify(second_arg, R, 1)\n",
    "target = one_hotify(target, R, 1)\n",
    "instruction = one_hotify(instruction, N, 1)\n",
    "\n",
    "# Add a fake first batch\n",
    "init_registers = init_registers.unsqueeze(0)\n",
    "first_arg = first_arg.unsqueeze(0)\n",
    "second_arg = second_arg.unsqueeze(0)\n",
    "target = target.unsqueeze(0)\n",
    "instruction = instruction.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# An example starting memory.  In this case, we're adding 3+4 and expect 7.\n",
    "initial_memory = torch.IntTensor([3,4,0,0,0,0,0,0])\n",
    "initial_memory = one_hotify(initial_memory, M, 0)\n",
    "output_memory = torch.zeros(M, M)\n",
    "output_memory[0][7] = 1\n",
    "\n",
    "# Output mask has ones in the rows of the memory matrix where the answer will be stored.\n",
    "output_mask = torch.zeros(M, M)\n",
    "output_mask[0] = torch.ones(M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTaskDataset(data.Dataset):\n",
    "    def __init__(self, M, num_examples):\n",
    "        \"\"\"\n",
    "        Generate a dataset for the addition task by randomly choosing two numbers in the allowed range\n",
    "        and creating the initial/final matrices for adding them.\n",
    "        \n",
    "        :param M: The allowable range of integers (from 0 to M-1)\n",
    "        :param num_examples: The number of training examples to be generated\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_list = []\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            # An example starting memory.  In this case, we're adding 3+4 and expect 7.\n",
    "            first_addend = random.randint(0, M-1)\n",
    "            second_addend = random.randint(0, M-1)\n",
    "            initial_memory = torch.zeros(M, M)\n",
    "            initial_memory[0][first_addend] = 1\n",
    "            initial_memory[1][second_addend] = 1\n",
    "            \n",
    "            output_memory = torch.zeros(M, M)\n",
    "            output_memory[0][(first_addend + second_addend) % M] = 1\n",
    "\n",
    "            # Output mask has ones in the rows of the memory matrix where the answer will be stored.\n",
    "            output_mask = torch.zeros(M, M)\n",
    "            output_mask[0] = torch.ones(M)\n",
    "            \n",
    "            self.input_list.append((initial_memory, output_memory, output_mask))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.input_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Get the i^th element of the dataset.\n",
    "        \n",
    "        :param i: The index of the element to be returned.\n",
    "        :return A tuple containing i^th element of the dataset.\n",
    "        \"\"\"\n",
    "        return self.input_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.001\n",
      "Epoch Number: 0, Batch Number: 1, Training Loss: 6.0000\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 0, Batch Number: 2, Training Loss: 6.0000\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 0, Batch Number: 3, Training Loss: 6.0000\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 0, Batch Number: 4, Training Loss: 6.0000\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 0, Batch Number: 5, Training Loss: 6.0000\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "Epoch Number: 1, Batch Number: 1, Training Loss: 5.9520\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 1, Batch Number: 2, Training Loss: 5.9520\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 1, Batch Number: 3, Training Loss: 5.9520\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 1, Batch Number: 4, Training Loss: 5.9520\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 1, Batch Number: 5, Training Loss: 5.9520\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "Epoch Number: 2, Batch Number: 1, Training Loss: 5.9040\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 2, Batch Number: 2, Training Loss: 5.9040\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 2, Batch Number: 3, Training Loss: 5.9040\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 2, Batch Number: 4, Training Loss: 5.9040\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 2, Batch Number: 5, Training Loss: 5.9040\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "Epoch Number: 3, Batch Number: 1, Training Loss: 5.8560\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 3, Batch Number: 2, Training Loss: 5.8560\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 3, Batch Number: 3, Training Loss: 5.8560\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 3, Batch Number: 4, Training Loss: 5.8560\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 3, Batch Number: 5, Training Loss: 5.8560\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "Epoch Number: 4, Batch Number: 1, Training Loss: 5.8080\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 4, Batch Number: 2, Training Loss: 5.8080\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 4, Batch Number: 3, Training Loss: 5.8080\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 4, Batch Number: 4, Training Loss: 5.8080\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 4, Batch Number: 5, Training Loss: 5.8080\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "Epoch Number: 5, Batch Number: 1, Training Loss: 5.7600\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 5, Batch Number: 2, Training Loss: 5.7600\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 5, Batch Number: 3, Training Loss: 5.7600\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 5, Batch Number: 4, Training Loss: 5.7600\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 5, Batch Number: 5, Training Loss: 5.7600\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "Epoch Number: 6, Batch Number: 1, Training Loss: 5.7120\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 6, Batch Number: 2, Training Loss: 5.7120\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 6, Batch Number: 3, Training Loss: 5.7120\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 6, Batch Number: 4, Training Loss: 5.7120\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 6, Batch Number: 5, Training Loss: 5.7120\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "Epoch Number: 7, Batch Number: 1, Training Loss: 5.6640\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 7, Batch Number: 2, Training Loss: 5.6640\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 7, Batch Number: 3, Training Loss: 5.6640\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 7, Batch Number: 4, Training Loss: 5.6640\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 7, Batch Number: 5, Training Loss: 5.6640\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "Epoch Number: 8, Batch Number: 1, Training Loss: 5.6592\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 8, Batch Number: 2, Training Loss: 5.6592\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 8, Batch Number: 3, Training Loss: 5.6592\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 8, Batch Number: 4, Training Loss: 5.6592\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 8, Batch Number: 5, Training Loss: 5.6592\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "Epoch Number: 9, Batch Number: 1, Training Loss: 5.6544\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 9, Batch Number: 2, Training Loss: 5.6544\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 9, Batch Number: 3, Training Loss: 5.6544\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 9, Batch Number: 4, Training Loss: 5.6544\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 9, Batch Number: 5, Training Loss: 5.6544\n",
      "Time so far is 0m 0s\n",
      "\n",
      "Training complete in 0m 0s\n",
      "Best loss: 6.000000\n"
     ]
    }
   ],
   "source": [
    "M = 8 # Don't change this (as long as we're using the add-task)\n",
    "num_examples = 5\n",
    "\n",
    "dataset = AddTaskDataset(M, num_examples)\n",
    "data_loader = data.DataLoader(dataset, batch_size = 1) # Don't change this batch size.  You have been warned.\n",
    "\n",
    "def anc_validation_criterion(output, label):\n",
    "    target_memory = label[1]\n",
    "    target_mask = label[2]\n",
    "    \n",
    "    output = output.data * target_mask\n",
    "    target_memory = target_memory * target_mask\n",
    "    _, target_indices = torch.max(target_memory, 2)\n",
    "    _, output_indices = torch.max(output, 2)\n",
    "    return torch.equal(output_indices, target_indices)\n",
    "\n",
    "# Initialize our controller\n",
    "controller = Controller(first_arg = first_arg, \n",
    "                        second_arg = second_arg, \n",
    "                        output = target, \n",
    "                        instruction = instruction, \n",
    "                        initial_registers = init_registers, \n",
    "                        stop_threshold = .9, \n",
    "                        blur = 1, \n",
    "                        correctness_weight = .3, \n",
    "                        halting_weight = .3, \n",
    "                        confidence_weight = .3, \n",
    "                        efficiency_weight = .1, \n",
    "                        t_max = 10) \n",
    "\n",
    "# Learning rate is a tunable hyperparameter\n",
    "# The paper didn't mention which one they used\n",
    "optimizer = optim.Adam(controller.parameters(), lr = 0.01)\n",
    "\n",
    "plot_every = 1\n",
    "\n",
    "best_model, train_plot_losses, validation_plot_losses = training.train_model_anc(\n",
    "    controller, \n",
    "    data_loader,  \n",
    "    optimizer, \n",
    "    num_epochs = 10, \n",
    "    print_every = 1, \n",
    "    plot_every = plot_every, \n",
    "    deep_copy_desired = False, \n",
    "    validation_criterion = anc_validation_criterion, \n",
    "    forward_train = True, \n",
    "    batch_size = 5) # In the paper, they used batch sizes of 1 or 5\n",
    "    \n",
    "    #kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11401e518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x * plot_every for x in range(len(train_plot_losses))], train_plot_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142db1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x * plot_every for x in range(len(validation_plot_losses))], validation_plot_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
