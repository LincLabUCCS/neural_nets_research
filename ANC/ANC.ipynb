{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains the two learnable parts of the model in four independent, fully connected layers.\n",
    "    First the initial values for the registers and instruction registers and second the \n",
    "    parameters that computes the required distributions. \n",
    "    \"\"\"\n",
    "    def __init(self, program_matrix1, program_matrix2, program_matrix3, program_matrix4, initial_memory, \n",
    "               initial_registers, instruction_register, stop_threshold):\n",
    "        \"\"\"\n",
    "        Initializes registers, memory and register matrix and their dimensions \n",
    "        Initializes four program matrices one of dimension NxM and three of dimension RxM\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        self.program_matrix1 = nn.Parameter(program_matrix1)\n",
    "        self.program_matrix2 = nn.Parameter(program_matrix2)\n",
    "        self.program_matrix3 = nn.Parameter(program_matrix3)\n",
    "        self.program_matrix4 = nn.Parameter(program_matrix4)    \n",
    "        \n",
    "        # Memory matrix (M x M)\n",
    "        self.memory = initial_memory\n",
    "        \n",
    "        # Register Matrix (R x M)\n",
    "        self.registers = initial_registers\n",
    "        \n",
    "        # Instruction Register (M)\n",
    "        self.IR = instruction_register\n",
    "        \n",
    "        # Machine initialization\n",
    "        self.Machine = Machine(M, R, stop_threshold)\n",
    "                \n",
    "    def forward(self):\n",
    "        einput = torch.matmul(self.program_matrix1, self.IR)\n",
    "        ainstruction = torch.matmul(self.program_matrix2, self.IR)\n",
    "        binstruction = torch.matmul(self.program_matrix3, self.IR)\n",
    "        outputin = torch.matmul(self.program_matrix4, self.IR)\n",
    "        \n",
    "        # Updating memory, registers, and IR after machine operation\n",
    "        self.memory, self.registers, self.IR = self.Machine\n",
    "        (einput, ainstruction, binstruction, outputin, memory, registers, IR)\n",
    "                \n",
    "        \n",
    "    def lossfunctions(self, cmatrix, tjmatrix):\n",
    "        \"\"\" compute four diferent loss functions and return a weighted average of the four measuring correctness, \n",
    "        halting, efficiency, and confidence\"\"\"\n",
    "        sum ((cmatrix)*(self.program_matrix4 - self.memory)^2)\n",
    "        ### need to add loss functions::: mehdi需要帮我们\n",
    "        救命\n",
    "        \n",
    "        \n",
    "# HOW TO BLUR? ==> Add a constant, then softmax\n",
    "#TODO: Add in some fuzz factor????\n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    The Machine executes assembly instructions passed to it by the Controller.\n",
    "    It updates the given memory, registers, and instruction pointer.\n",
    "    The Machine doesn't have any learnable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, M, R, stop_threshold):\n",
    "        \"\"\"\n",
    "        Initializes dimensions, operations, and counters\n",
    "        \n",
    "        :param M: Memory length.  Integer values also take on values 0-M-1.  M is also the program length.\n",
    "        :param R: Number of registers\n",
    "        :stop_threshold: Accumulated probability of stopping after which the program terminates.\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        \n",
    "        # Store parameters as class variables\n",
    "        self.R = R\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.stop_threshold = stop_threshold\n",
    "        \n",
    "        # Start off with 0 probability of stopping\n",
    "        self.stop_probability = 0\n",
    "        \n",
    "        # A list of all our possible ops\n",
    "        N = \n",
    "        self.ops = [\n",
    "            Jump(M), \n",
    "            Stop(M), \n",
    "            Write(M), \n",
    "            Read(M), \n",
    "            Add(M), \n",
    "            Subtract(M), \n",
    "            Increment(M),\n",
    "            Decrement(M),\n",
    "            Min(M),\n",
    "            Max(M),\n",
    "            Zero(M)\n",
    "        ]\n",
    "#         self.ops = [\n",
    "            \n",
    "#         ]\n",
    "        \n",
    "        # Number of instructions\n",
    "        self.N = len(self.ops)\n",
    "        \n",
    "        # Keep track of the index of certain ops which are dealt with specially\n",
    "        self.jump_index = 0\n",
    "        self.stop_index = 1\n",
    "        self.write_index = 2\n",
    "        self.read_index = 3\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \"\"\"\n",
    "        Run the Machine for one timestep (corresponding to the execution of one line of Assembly).\n",
    "        The first four parameter names correspond to the vector names used in the original ANC paper\n",
    "        \n",
    "        :param e: Probability distribution over the instruction being executed (length M)\n",
    "        :param a: Probability distribution over the first argument register (length R)\n",
    "        :param b: Probability distribution over the second argument register (length R)\n",
    "        :param o: Probability distribution over the first argument register (length R)\n",
    "        :param memory: Memory matrix (size M x M)\n",
    "        :param registers: Register matrix (size R x M)\n",
    "        :param IR: Instruction Register (length M)\n",
    "        \n",
    "        :return: The memory, registers, and instruction register after the timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate distributions over the two argument values by multiplying each \n",
    "        # register by the probability that register is being used.\n",
    "        arg1 = torch.matmul(a, registers)\n",
    "        arg2 = torch.matmul(b, registers)\n",
    "        \n",
    "        # Would be kinda nice to not have to for-loop this\n",
    "        # Or maybe do this once\n",
    "        # CUUUUUDAAAA\n",
    "        \n",
    "        # N x M Matrix of output values.  The i,j cell represents the probability\n",
    "        # of getting value j by running instruction i.\n",
    "        out = Variable(torch.zeros(self.N, self.M))\n",
    "        \n",
    "#         # Loop through all possible instructions\n",
    "#         for k in range(self.N):\n",
    "#             # Loop through all possible first arguments\n",
    "#             for i in range(self.M):\n",
    "#                 # Loop through all possible second arguments\n",
    "#                 for j in range(self.M):\n",
    "#                     if k == self.read_index:\n",
    "                        \n",
    "#                         mem_val = memory[i]\n",
    "#                         # Loop through distribution of memory values, throw these into the matrix.\n",
    "#                         for int_val in range(mem_val.size()[0]):\n",
    "#                             out[k, int_val] = out[k, int_val] + arg1[i] * arg2[j] * mem_val[int_val].data[0]\n",
    "#                     else:\n",
    "#                         val = self.ops[k](i,j)\n",
    "#                         # Store output in the appropriate matrix cell.\n",
    "#                         out[k, val] = out[k, val] + arg1[i] * arg2[j]\n",
    "\n",
    "        out_vec = torch.zeros(1, N)\n",
    "        for op_index in range(self.N):\n",
    "#             out_vec = out_vec + e[op_index] * torch.matmul(torch.matmul(torch.t(arg1), self.ops[op_index]), arg2)\n",
    "            out_vec = torch.matmul(torch.t(e), ops) \n",
    "            \n",
    "        \n",
    "            \n",
    "#         # Take a weighted sum over the output distributions from each instruction\n",
    "#         out_vec = torch.matmul(e, out)\n",
    "        \n",
    "#         # Update our memory, registers, instruction register, and stopping probability\n",
    "#         memory = self.writeMemory(e, memory, arg1, arg2)\n",
    "#         registers = self.writeRegisters(out_vec, o, registers)\n",
    "#         IR = self.updateIR(e, IR, arg1, arg2)\n",
    "#         should_stop = self.updateStop(e)\n",
    "        \n",
    "        return(memory, registers, IR)\n",
    "        \n",
    "        \n",
    "    def writeRegisters(self, out, o, registers):\n",
    "        \"\"\"\n",
    "        Write the result of our operation to our registers.\n",
    "        \n",
    "        :param out: probability distribution over the output value\n",
    "        :param o: probability distribution over the output register\n",
    "        :param registers: register matrix\n",
    "        \n",
    "        :return: the updated registers\n",
    "        \"\"\"\n",
    "        # Multiply probability of writing to each output register by the value \n",
    "        new_register_vals = torch.matmul(torch.unsqueeze(o,1), torch.unsqueeze(out,0))\n",
    "        # Multiply each original register cell by the probabilty of not writing to that register\n",
    "        old_register_vals = torch.unsqueeze((1-o),1).expand(self.R, self.M) * registers\n",
    "        \n",
    "        registers =  new_register_vals + old_register_vals\n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the instruction register\n",
    "        \n",
    "        :param e: distribution over the current instruction (length N)\n",
    "        :param IR: instruction register (length M)\n",
    "        :param arg1: distribution over the first argument value (length M)\n",
    "        :param arg2: distribution over the second argument value (length M)\n",
    "        \n",
    "        :return: the updated instruction register\n",
    "        \"\"\"\n",
    "        # IR - length M vector\n",
    "        jump_probability = e[self.jump_index]\n",
    "        is_zero = arg1[0]\n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        IR_no_jump = torch.cat([IR[-1], IR[:-1]])\n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        return IR\n",
    "    \n",
    "    def writeMemory(self, e, mem_orig, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the memory\n",
    "        \n",
    "        :param e: distribution over the current instruction (length M)\n",
    "        :param mem_orig: current memory matrix (size M x M)\n",
    "        :param arg1: distribution over the first argument value (length M)\n",
    "        :param arg2: distribution over the second argument value (length M)\n",
    "        \n",
    "        :return: the updated memory matrix\n",
    "        \"\"\"\n",
    "        write_probability = e[self.write_index]\n",
    "        # If we are on a write instruction, write the value arg2 in register arg1. Otherwise, leave memory as is.\n",
    "        mem_write = torch.matmul(torch.unsqueeze(arg1,1), torch.unsqueeze(arg2,0))        \n",
    "        memory = mem_orig * (1 - write_probability) + mem_write * write_probability\n",
    "        return memory\n",
    "        \n",
    "    def updateStop(self, e):\n",
    "        \"\"\"\n",
    "        Update the probability that we will stop at this timestep based on the probability that we are running the STOP op.\n",
    "        \n",
    "        :param e: distribution over the current instruction (length M)\n",
    "        \n",
    "        :return: boolean representing whether the controller should stop.\n",
    "        \"\"\"\n",
    "        self.stop_probability += e[self.stop_index].data[0]\n",
    "        if self.stop_probability > self.stop_threshold:\n",
    "            return True #should stop\n",
    "        return False #shouldn't stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    Parent class for our binary operations\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Initialize the memory length (needed so we can mod our answer in case it exceeds the range 0-M-1)\n",
    "        \n",
    "        :param M: Memory length\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M #TODO: Check this gets updated!\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \"\"\" \n",
    "        Perform the binary operation.  The arguments may or may not be used.\n",
    "        \n",
    "        :param x: First argument\n",
    "        :param y: Second argument\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return (x + y) % self.M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def forward(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def forward(self, _1, _2):\n",
    "        return 0 # Actual jump happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decrement(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Decrement, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, _):\n",
    "        return (x - 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Increment(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Increment, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, _):\n",
    "        return (x + 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Max(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Max, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return max(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Min(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Min, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Read(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Read, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, _):\n",
    "        return self.memory[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subtract(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Subtract, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return (x - y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Write(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Write, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return 0 # Actual write happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Zero(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Zero, self).__init__(M)\n",
    "\n",
    "    def forward(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEM Variable containing:\n",
      " 0.9079  0.0114  0.0026\n",
      " 0.9212  0.0307  0.0071\n",
      " 0.0068  0.0099  0.9023\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n",
      "REGS Variable containing:\n",
      " 0.5373  0.3134  0.1493\n",
      " 0.3715  0.4356  0.1929\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "IR Variable containing:\n",
      " 0.1057\n",
      " 0.1092\n",
      " 0.8828\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mini-test\n",
    "# M=4, R=2, N=11\n",
    "machine = Machine(3, 2, .5)\n",
    "e = Variable(torch.FloatTensor([.1,.1,.1,.1,.1,.1,.1,.1,.1,.05,.05]))\n",
    "a = Variable(torch.FloatTensor([.1, .9]))\n",
    "b = Variable(torch.FloatTensor([.8, .2]))\n",
    "o = Variable(torch.FloatTensor([.6, .4]))\n",
    "memory = Variable(torch.FloatTensor([[1,0,0], [1,0,0], [0,0,1]]))\n",
    "registers = Variable(torch.FloatTensor([[.4, .5, .1], [.2, .6, .2]]))\n",
    "IR = Variable(torch.FloatTensor([.1, .9, .1]))\n",
    "mem, regs, ir = machine(e, a, b, o, memory, registers, IR)\n",
    "print(\"MEM\", mem)\n",
    "print(\"REGS\", regs)\n",
    "print(\"IR\", ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASKS \n",
    "# - Compilation\n",
    "# - Rest of the operations\n",
    "# - Train function\n",
    "# - Controller\n",
    "# - Cuda\n",
    "# - Blurring\n",
    "# - Running the tests they ran, verifying that we get similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PUT THE TRAINING FUNCTION HERE.  COPY AND PASTE A BUNCHA STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
