{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/oliviawatkins/Documents\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets_library import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains the two learnable parts of the model in four independent, fully connected layers.\n",
    "    First the initial values for the registers and instruction registers and second the \n",
    "    parameters that computes the required distributions. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 first_arg = None, \n",
    "                 second_arg = None, \n",
    "                 output = None, \n",
    "                 instruction = None, \n",
    "                 initial_registers = None, \n",
    "                 stop_threshold = .99, \n",
    "                 multiplier = 10,\n",
    "                 correctness_weight = .2, \n",
    "                 halting_weight = .2, \n",
    "                 confidence_weight = .2, \n",
    "                 efficiency_weight = .4,\n",
    "                 t_max = 100):\n",
    "        #TODO: Read over ANC paper, check if there are more reasonable default initial values.\n",
    "        \"\"\"\n",
    "        Initialize a bunch of constants and pass in matrices defining a program.\n",
    "        \n",
    "        :param first_arg: Matrix with the 1st register argument for each timestep stored in the columns (1xRxM)\n",
    "        :param second_arg: Matrix with the 2nd register argument for each timestep stored in the columns (1xRxM)\n",
    "        :param output: Matrix with the output register for each timestep stored in the columns (1xRxM)\n",
    "        :param instruction: Matrix with the instruction for each timestep stored in the columns (1xNxM)\n",
    "        :param initial_registers: Matrix where each row is a distribution over the value in one register (1xRxM)\n",
    "        :param stop_threshold: The stop probability threshold at which the controller should stop running\n",
    "        :param multiplier: The factor our one-hot vectors are be multiplied by before they're softmaxed to add blur\n",
    "        :param correctness_weight: Weight given to the correctness component of the loss function\n",
    "        :param halting_weight: Weight given to the halting component of the loss function\n",
    "        :param confidence_weight: Weight given to the confidence component of the loss function\n",
    "        :param efficiency_weight: Weight given to the efficiency component of the loss function\n",
    "        \n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        \n",
    "        # Initialize dimension constants\n",
    "        B, R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        # Initialize loss function weights\n",
    "        # In the ANC paper, these scalars are called, alpha, beta, gamma, and delta\n",
    "        self.correctness_weight = correctness_weight\n",
    "        self.halting_weight = halting_weight\n",
    "        self.confidence_weight = confidence_weight\n",
    "        self.efficiency_weight = efficiency_weight\n",
    "        \n",
    "        \n",
    "        # And yet more initialized constants... yeah, there are a bunch, I know.\n",
    "        self.t_max = t_max\n",
    "        self.stop_threshold = stop_threshold\n",
    "        \n",
    "\n",
    "        # Initialize parameters.  These are the things that are going to be optimized. \n",
    "        self.first_arg = nn.Parameter(multiplier * first_arg)\n",
    "        self.second_arg = nn.Parameter(multiplier * second_arg)\n",
    "        self.output = nn.Parameter(multiplier * output)\n",
    "        self.instruction = nn.Parameter(multiplier * instruction) \n",
    "        initial_registers = self.blur(initial_registers, multiplier, 2)\n",
    "        self.registers = nn.Parameter(initial_registers.data)\n",
    "        \n",
    "#         print(\"INITIAL REGS\", initial_registers)\n",
    "        \n",
    "        \n",
    "        # Machine initialization\n",
    "        self.machine = Machine(B, M, R)\n",
    "    \n",
    "    def blur(self, matrix, scale_factor, dimension):\n",
    "        \"\"\"\n",
    "        Takes a matrix, each row (or column) of which is a one-hot vector.\n",
    "        Multiply each 1 by a constant and then softmax it, which \n",
    "        effectively \"blurs\" the matrix a little bit.\n",
    "        \n",
    "        :param matrix: Matrix to blur\n",
    "        :param scale_factor: Constant to multiply the matrix by before it's softmaxed\n",
    "        :param dimension: Dimension to softmax over\n",
    "        \n",
    "        :return: Blurred matrix\n",
    "        \"\"\"\n",
    "        matrix = scale_factor * matrix\n",
    "        softmax = nn.Softmax(dimension)\n",
    "        return softmax(Variable(matrix))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, input, train):\n",
    "        \"\"\"\n",
    "        Runs the controller on a certain input memory matrix.\n",
    "        It either returns the loss or the output memory.\n",
    "        \n",
    "        :param input: A three-tuple of three MxM matrices: (memory matrix, output_memory, output_mask)\n",
    "        \n",
    "        :return: If train is true, return the loss. Otherwise, return the output matrix\n",
    "        \"\"\"\n",
    "        # Program's initial memory\n",
    "        self.memory = input[0]\n",
    "        # Desired output memory\n",
    "        self.output_memory = Variable(input[1])\n",
    "        # Mask with 1's in the rows of the output memory matrix which actually contain the answer.\n",
    "        self.output_mask = Variable(input[2])\n",
    "    \n",
    "        \n",
    "        # Initialize instruction regiser (1xMx1)\n",
    "        self.register_buffer('IR', torch.DoubleTensor(1, M, 1).zero_())\n",
    "        self.IR[0, 0, 0] = 1\n",
    "        \n",
    "        IR = Variable(self.IR)\n",
    "        self.memory = Variable(self.memory)\n",
    "        \n",
    "#         print(\"INITIAL MEMORY\", self.memory)\n",
    "        \n",
    "        efficiency_loss = 0\n",
    "        confidence_loss = 0\n",
    "        self.stop_probability = 0\n",
    "        \n",
    "        # Copy registers so we aren't using the values from the previous iteration.\n",
    "        registers = self.registers\n",
    "        \n",
    "        # loss initialization\n",
    "        self.confidence = 0\n",
    "        self.efficiency = 0\n",
    "        self.halting = 0\n",
    "        self.correctness = 0\n",
    "        \n",
    "        t = 0 \n",
    "        # Run the program, one timestep at a time, until the program terminates or whe time out\n",
    "        while t < self.t_max and self.stop_probability < self.stop_threshold: \n",
    "            \n",
    "            softmax = nn.Softmax(1)\n",
    "            \n",
    "            a = softmax(torch.bmm(self.first_arg, IR))\n",
    "            b = softmax(torch.bmm(self.second_arg, IR))\n",
    "            o = softmax(torch.bmm(self.output, IR))\n",
    "            e = softmax(torch.bmm(self.instruction, IR))\n",
    "            \n",
    "            old_mem = self.memory\n",
    "            \n",
    "            # Update memory, registers, and IR after machine operation\n",
    "            self.old_stop_probability = self.stop_probability\n",
    "            self.memory, registers, IR, new_stop_prob = self.machine(e, a, b, o, self.memory, registers, IR) \n",
    "            \n",
    "            self.stop_probability += new_stop_prob[0]\n",
    "            \n",
    "            # If we're training, calculate loss\n",
    "            if train:\n",
    "                self.timestep_loss(t)\n",
    "            \n",
    "            t += 1\n",
    "        \n",
    "        # If we're training, return loss.  Otherwise return memory.\n",
    "        if train:\n",
    "            self.final_loss(t)\n",
    "            total_loss  = self.total_loss()\n",
    "            return (self.memory, total_loss)\n",
    "        else:\n",
    "            return (self.memory, None)\n",
    "        \n",
    "        \n",
    "    def timestep_loss(self, t):\n",
    "        \"\"\"\n",
    "        @ Rakia @ Aditya feel free to use this function definition or not.  My main thought was that this would \n",
    "        compute the types of loss which get updated every timestep.\n",
    "        \"\"\"\n",
    "        # Confidence Loss \n",
    "        mem_diff = self.output_memory - self.memory\n",
    "        correctness = torch.sum((self.output_mask) * mem_diff * mem_diff)\n",
    "        self.confidence += (self.stop_probability - self.old_stop_probability) * correctness\n",
    "        \n",
    "        # Efficiency Loss\n",
    "        if t < self.t_max and self.stop_probability < self.stop_threshold: # don't add efficiency loss on the last timestep\n",
    "            self.efficiency += (1 - self.stop_probability)\n",
    "            \n",
    "    \n",
    "    def final_loss(self, t):\n",
    "        \"\"\"\n",
    "        @ Rakia @ Aditya feel free to use this function definition or not.  My main thought was that this would \n",
    "        compute the types of loss which get updated every timestep.\n",
    "        \"\"\"\n",
    "        # Correctness loss\n",
    "        mem_diff = self.output_memory - self.memory\n",
    "        self.correctness = torch.sum((self.output_mask) * mem_diff * mem_diff)\n",
    "\n",
    "        # Halting loss\n",
    "        if t == self.t_max:\n",
    "            self.halting = (1 - self.stop_probability)\n",
    "\n",
    "    def total_loss(self):\n",
    "        \"\"\" compute four diferent loss functions and return a weighted average of the four measuring correctness, \n",
    "        halting, efficiency, and confidence\"\"\"\n",
    "        return  (self.correctness*self.correctness_weight) + (self.confidence_weight*self.confidence) + (self.halting_weight*self.halting) + (self.efficiency_weight*self.efficiency) \n",
    "        \n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    Parent class for our binary operations\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Initialize the memory length (needed so we can mod our answer in case it exceeds the range 0-M-1)\n",
    "        Also calculate the output matrix for the operation\n",
    "        \n",
    "        :param M: Memory length\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M\n",
    "        \n",
    "        # Create a MxMxM matrix where the (i,j,k) cell is 1 iff operation(i,j) = k.\n",
    "        self.outputs = torch.IntTensor(M, M, M).zero_()\n",
    "        for i in range(M):\n",
    "            for j in range(M):\n",
    "                val = self.compute(i, j)\n",
    "                self.outputs[val][i][j] = 1\n",
    "                \n",
    "        self.outputs = Variable(self.outputs)\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        \"\"\" \n",
    "        Perform the binary operation.  The arguments may or may not be used.\n",
    "        \n",
    "        :param x: First argument\n",
    "        :param y: Second argument\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        :return: The output matrix\n",
    "        \"\"\"\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        return (x + y) % self.M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0 # Actual jump happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decrement(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Decrement, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x - 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Increment(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Increment, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return (x + 1) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Max, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return max(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Min(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Min, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return min(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Read, self).__init__(M)\n",
    "        # Leave output matrix blank since we're gonna do the reading elsewhere\n",
    "        self.outputs = torch.DoubleTensor(M, M, M).zero_()\n",
    "\n",
    "    def compute(self, x, _):\n",
    "        return 0 # Actual reading happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subtract(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Subtract, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return (x - y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Write(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Write, self).__init__(M)\n",
    "\n",
    "    def compute(self, x, y):\n",
    "        return 0 # Actual write happens in the Machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Zero, self).__init__(M)\n",
    "\n",
    "    def compute(self, _1, _2):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    The Machine executes assembly instructions passed to it by the Controller.\n",
    "    It updates the given memory, registers, and instruction pointer.\n",
    "    The Machine doesn't have any learnable parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, B, M, R):\n",
    "        \"\"\"\n",
    "        Initializes dimensions, operations, and counters\n",
    "        \n",
    "        :param B: Batch size (meant to be 1)\n",
    "        :param M: Memory length.  Integer values also take on values 0-M-1.  M is also the program length.\n",
    "        :param R: Number of registers\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        \n",
    "        # Store parameters as class variables\n",
    "        self.R = R # Number of registers\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.B = B # Batch size\n",
    "        \n",
    "        # Start off with 0 probability of stopping\n",
    "        self.stop_probability = 0 \n",
    "        \n",
    "        # List of ops (must be in same order as the original ANC paper so compilation works right)\n",
    "        self.ops = [ \n",
    "            Stop(M),\n",
    "            Zero(M),\n",
    "            Increment(M),\n",
    "            Add(M),\n",
    "            Subtract(M),\n",
    "            Decrement(M),\n",
    "            Min(M),\n",
    "            Max(M),\n",
    "            Read(M),\n",
    "            Write(M),\n",
    "            Jump(M)\n",
    "        ]\n",
    "        \n",
    "        # Number of instructions\n",
    "        self.N = len(self.ops)\n",
    "        \n",
    "        # Create a 4D matrix composed of the output matrices of each of the ops\n",
    "        self.outputs = Variable(torch.DoubleTensor(self.N, M, M, M)).zero_()\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            op = self.ops[i]\n",
    "            self.outputs[i] = op()\n",
    "            \n",
    "        # Add an extra batch dimension\n",
    "        self.outputs = torch.unsqueeze(self.outputs, 0)\n",
    "        self.outputs = self.outputs.expand(B, -1, -1, -1, -1)\n",
    "        \n",
    "        # Keep track of ops which will be handled specially\n",
    "        self.jump_index = 10\n",
    "        self.stop_index = 0\n",
    "        self.write_index = 9\n",
    "        self.read_index = 8\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \n",
    "        \"\"\"\n",
    "        Run the Machine for one timestep (corresponding to the execution of one line of Assembly).\n",
    "        The first four parameter names correspond to the vector names used in the original ANC paper\n",
    "        \n",
    "        :param e: Probability distribution over the instruction being executed (BxMx1)\n",
    "        :param a: Probability distribution over the first argument register (length BxRx1)\n",
    "        :param b: Probability distribution over the second argument register (length BxRx1)\n",
    "        :param o: Probability distribution over the first argument register (length BxRx1)\n",
    "        :param memory: Memory matrix (size BxMxM)\n",
    "        :param registers: Register matrix (size BxRxM)\n",
    "        :param IR: Instruction Register (length BxM)\n",
    "        \n",
    "        :return: The memory, registers, and instruction register after the timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dimensions B x 1 x R -> B x 1 x R\n",
    "        a = torch.transpose(a, 1, 2)\n",
    "        b = torch.transpose(b, 1, 2)\n",
    "        \n",
    "        # Calculate distributions over the two argument values by multiplying each \n",
    "        # register by the probability that register is being used.\n",
    "        arg1 = torch.bmm(a, registers)\n",
    "        arg2 = torch.bmm(b, registers)\n",
    "        \n",
    "#         print(\"A\", a)\n",
    "#         print(\"REG\", registers)\n",
    "        \n",
    "        # Multiply the output matrix by the arg1 and arg2 vectors to take into account\n",
    "        # Before we do this, we're going to have to do a bunch of dimension squishing.\n",
    "        \n",
    "        # arg1_long dimensions: B x 1 x M --> B x 1 x 1 x 1 x M\n",
    "        arg1_long = torch.unsqueeze(arg1, 1)\n",
    "        arg1_long = torch.unsqueeze(arg1_long, 1)\n",
    "        \n",
    "        outputs_x_arg1 = torch.matmul(arg1_long, self.outputs)\n",
    "        \n",
    "        # outputs_x_arg1 dimensions: B x N x M x 1 x M -> B x N x M x M\n",
    "        outputs_x_arg1 = torch.squeeze(outputs_x_arg1, 3)\n",
    "        \n",
    "        # arg2_long dimensions: B x 1 x M --> B x 1 x M x 1\n",
    "        arg2_long = torch.unsqueeze(arg2, 3)\n",
    "        \n",
    "        outputs_x_args = torch.matmul(outputs_x_arg1, arg2_long)\n",
    "        \n",
    "        # outputs_x_args dimensions: B x N x M x 1 -> B x N x M\n",
    "        outputs_x_args = torch.squeeze(outputs_x_args, 3)\n",
    "        \n",
    "        # e dimensions B x N x 1 -> B x 1 x N\n",
    "        e = torch.transpose(e, 1, 2)\n",
    "        \n",
    "        # read_vec dimensions B x 1 -> B x 1 x 1\n",
    "        read_vec =  e[:, :, self.read_index]\n",
    "        read_vec = read_vec.unsqueeze(1)\n",
    "        \n",
    "        # Length Bx1xM vector over the output of the operation\n",
    "        out_vec = torch.matmul(e, outputs_x_args)\n",
    "        \n",
    "        # Deal with memory reads separately\n",
    "        out_vec = out_vec + read_vec * torch.matmul(arg1, memory)        \n",
    "        \n",
    "        # Update our memory, registers, instruction register, and stopping probability\n",
    "        mem_old = memory\n",
    "        memory = self.writeMemory(e, o, memory, arg1, arg2)\n",
    "        registers = self.writeRegisters(out_vec, o, registers)\n",
    "        IR = self.updateIR(e, IR, arg1, arg2)\n",
    "        stop_prob = self.getStop(e)\n",
    "        \n",
    "        return(memory, registers, IR, stop_prob)\n",
    "        \n",
    "        \n",
    "    def writeRegisters(self, out, o, registers):\n",
    "        \"\"\"\n",
    "        Write the result of our operation to our registers.\n",
    "        \n",
    "        :param out: Probability distribution over the output value (Bx1xM)\n",
    "        :param o: Probability distribution over the output register (BxRx1)\n",
    "        :param Registers: register matrix (BxRxM)\n",
    "        \n",
    "        :return: The updated registers (BxRxM)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Multiply probability of writing to each output register by the distribution over the value we're writing there.\n",
    "        new_register_vals = torch.matmul(o, out)\n",
    "        \n",
    "        # Multiply each original register cell by the probabilty of not writing to that register\n",
    "        old_register_vals = (1-o).expand(self.B, self.R, self.M) * registers\n",
    "        \n",
    "        # Take a weighted sum over the old and new register values\n",
    "        registers =  new_register_vals + old_register_vals\n",
    "     #         print(\"SIZE\", o.size())\n",
    "#         print(\"NEW\", new_register_vals)\n",
    "#         print(\"OLD\", old_register_vals)\n",
    "        \n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the instruction register\n",
    "        \n",
    "        :param e: Distribution over the current instruction (BxNx1)\n",
    "        :param IR: Instruction register (length BxMx1)\n",
    "        :param arg1: Distribution over the first argument value (length BxMx1)\n",
    "        :param arg2: Distribution over the second argument value (length BxMx1)\n",
    "        \n",
    "        :return: The updated instruction register (BxMx1)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dimensions B x 1 x M -> B x M x 1\n",
    "        arg2 = arg2.transpose(1, 2)\n",
    "        \n",
    "        # Probability that we're on the jump instruction\n",
    "        jump_probability = e[:, :, self.jump_index]\n",
    "        \n",
    "        # Probability that the first argument is 0\n",
    "        is_zero = arg1[:, :, 0]\n",
    "        \n",
    "        # Slicing lost a dimension.  Let's add it back\n",
    "        jump_probability = torch.unsqueeze(jump_probability, 1)\n",
    "        is_zero = torch.unsqueeze(is_zero, 1)\n",
    "        \n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        wraparound = IR[:, -1]\n",
    "        normal_instructions = IR[:, :-1]\n",
    "        \n",
    "        # For whatever reason, when you chop off one row/column, that dimension disappears.  Add it back.\n",
    "        wraparound = wraparound.unsqueeze(1)\n",
    "        IR_no_jump = torch.cat([wraparound, normal_instructions], 1)\n",
    "        \n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        # Take a weighted sum of the instruction register with and without jumping\n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        \n",
    "        return IR\n",
    "    \n",
    "    def writeMemory(self, e, o, mem_orig, arg1, arg2):\n",
    "        \"\"\"\n",
    "        Update the memory\n",
    "        \n",
    "        :param e: Distribution over the current instruction (B x1xM)\n",
    "        :param mem_orig: Current memory matrix (BxMxM)\n",
    "        :param arg1: Distribution over the first argument value (Bx1xM)\n",
    "        :param arg2: Distribution over the second argument value (Bx1xM)\n",
    "        \n",
    "        :return: The updated memory matrix (BxMxM)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Probability that we're on the write instruction\n",
    "        write_probability = e[:,:, self.write_index]\n",
    "        \n",
    "        # write_probability dimensions: Bx1 -> B x 1 x 1\n",
    "        write_probability = torch.unsqueeze(write_probability, 1)\n",
    "        \n",
    "        # arg1 dimensions: B x 1 x M -> B x M x 1\n",
    "        arg1 = torch.transpose(arg1, 1, 2)\n",
    "        \n",
    "        # If we are on a write instruction, write the value arg2 in register arg1. Otherwise, leave memory as is.\n",
    "        mem_changed = torch.bmm(arg1, arg2)\n",
    "#         print(\"ARG1\", arg1)\n",
    "#         print(\"ARG2\", arg2)\n",
    "#         print(\"MEM CHANGED\", mem_changed)\n",
    "        mem_unchanged = mem_orig * (1-arg1).expand(-1, -1, self.M)\n",
    "        mem_write = mem_changed + mem_unchanged\n",
    "        \n",
    "        \n",
    "        # Take a weighted sum over the new memory and old memory\n",
    "        memory = mem_orig * (1 - write_probability) + mem_write * write_probability\n",
    "        return memory\n",
    "        \n",
    "    def getStop(self, e):\n",
    "        \"\"\"\n",
    "        Obtain the probability that we will stop at this timestep based on the probability that we are running the STOP op.\n",
    "        \n",
    "        :param e: distribution over the current instruction (length Bx1xM)\n",
    "        \n",
    "        :return: probability representing whether the controller should stop.\n",
    "        \"\"\"\n",
    "        return e[:, :, self.stop_index].data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hotify(vec, length, dimension):\n",
    "    \"\"\"\n",
    "    Turn a tensor of integers into a matrix of one-hot vectors.\n",
    "    \n",
    "    :param vec: The vector to be converted.\n",
    "    :param length: One dimension of the matrix (the other is the length of vec)\n",
    "    :param dimension: Which dimension stores the elements of vec.  If 0, they're stored in the rows.  If 1, the columns.\n",
    "    \n",
    "    :return A matrix of one-hot vectors, each row or column corresponding to one element of vec\n",
    "    \"\"\"\n",
    "    x = vec.size()[0]\n",
    "    if dimension == 0:\n",
    "        binary_vec = torch.DoubleTensor(x, length).zero_()\n",
    "        for i in range(x):\n",
    "            binary_vec[i][vec[i]] = 1\n",
    "        return binary_vec\n",
    "    elif dimension == 1:\n",
    "        binary_vec = torch.DoubleTensor(length, x).zero_()\n",
    "        for i in range(x):\n",
    "            binary_vec[vec[i]][i] = 1\n",
    "        return binary_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Addition task\n",
    "# # Generate this by running the instructions here (but with the addition program file): https://github.com/aditya-khant/neural-assembly-compiler\n",
    "# # Then get rid of the .cuda in each of the tensors since we (or at least I) don't have cuda\n",
    "# init_registers = torch.IntTensor([6,2,0,1,0,0]) # Length R, should be RxM\n",
    "# first_arg = torch.IntTensor([4,3,3,3,4,2,2,5]) # Length M, should be RxM\n",
    "# second_arg = torch.IntTensor([5,5,0,5,5,1,4,5]) # Length M, should be RxM\n",
    "# target = torch.IntTensor([4,3,5,3,4,5,5,5]) # Length M, should be RxM\n",
    "# instruction = torch.IntTensor([8,8,10,5,2,10,9,0]) # Length M, should be NxM\n",
    "\n",
    "# Increment task\n",
    "init_registers = torch.IntTensor([6,0,0,0,0,0,0])\n",
    "first_arg = torch.IntTensor([5,1,1,5,5,4,6])\n",
    "second_arg = torch.IntTensor([6,0,6,3,6,2,6])\n",
    "target = torch.IntTensor([1,6,3,6,5,6,6])\n",
    "instruction = torch.IntTensor([8,10,2,9,2,10,0])\n",
    "\n",
    "\n",
    "\n",
    "# Get dimensions we'll need\n",
    "M = first_arg.size()[0]\n",
    "R = init_registers.size()[0]\n",
    "N = 11\n",
    "\n",
    "# Turn the given tensors into matrices of one-hot vectors.\n",
    "init_registers = one_hotify(init_registers, M, 0)\n",
    "first_arg = one_hotify(first_arg, R, 1)\n",
    "second_arg = one_hotify(second_arg, R, 1)\n",
    "target = one_hotify(target, R, 1)\n",
    "instruction = one_hotify(instruction, N, 1)\n",
    "\n",
    "# Add a fake first batch\n",
    "init_registers = init_registers.unsqueeze(0)\n",
    "first_arg = first_arg.unsqueeze(0)\n",
    "second_arg = second_arg.unsqueeze(0)\n",
    "target = target.unsqueeze(0)\n",
    "instruction = instruction.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTaskDataset(data.Dataset):\n",
    "    def __init__(self, M, num_examples):\n",
    "        \"\"\"\n",
    "        Generate a dataset for the addition task by randomly choosing two numbers in the allowed range\n",
    "        and creating the initial/final matrices for adding them.\n",
    "        \n",
    "        :param M: The allowable range of integers (from 0 to M-1)\n",
    "        :param num_examples: The number of training examples to be generated\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_list = []\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            first_addend = random.randint(0, M-1)\n",
    "            second_addend = random.randint(0, M-1)\n",
    "            initial_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            initial_memory[0][first_addend] = 1\n",
    "            initial_memory[1][second_addend] = 1\n",
    "            for j in range(2, M):\n",
    "                initial_memory[j][0] = 1\n",
    "\n",
    "            \n",
    "            output_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            output_memory[0][(first_addend + second_addend) % M] = 1\n",
    "\n",
    "            # Output mask has ones in the rows of the memory matrix where the answer will be stored.\n",
    "            output_mask = torch.DoubleTensor(M, M).zero_()\n",
    "            output_mask[0] = torch.ones(M)\n",
    "            \n",
    "            self.input_list.append((initial_memory, output_memory, output_mask))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.input_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Get the i^th element of the dataset.\n",
    "        \n",
    "        :param i: The index of the element to be returned.\n",
    "        :return A tuple containing i^th element of the dataset.\n",
    "        \"\"\"\n",
    "        return self.input_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrivialAddTaskDataset(data.Dataset):\n",
    "    def __init__(self, M, num_examples):\n",
    "        \"\"\"\n",
    "        Generate a dataset for the addition task by randomly choosing two numbers in the allowed range\n",
    "        and creating the initial/final matrices for adding them.\n",
    "        \n",
    "        :param M: The allowable range of integers (from 0 to M-1)\n",
    "        :param num_examples: The number of training examples to be generated\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_list = []\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            first_addend = random.randint(0, M-1)\n",
    "            second_addend = random.randint(0, M-1)\n",
    "            initial_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            initial_memory[0][first_addend] = 1\n",
    "            initial_memory[1][second_addend] = 1\n",
    "            for j in range(2, M):\n",
    "                initial_memory[j][0] = 1\n",
    "\n",
    "            \n",
    "            output_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            output_memory[0][(first_addend + second_addend) % M] = 1\n",
    "\n",
    "            # Output mask has ones in the rows of the memory matrix where the answer will be stored.\n",
    "            output_mask = torch.DoubleTensor(M, M).zero_()\n",
    "            output_mask[2] = torch.ones(M)\n",
    "            \n",
    "            self.input_list.append((initial_memory, output_memory, output_mask))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.input_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Get the i^th element of the dataset.\n",
    "        \n",
    "        :param i: The index of the element to be returned.\n",
    "        :return A tuple containing i^th element of the dataset.\n",
    "        \"\"\"\n",
    "        return self.input_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncTaskDataset(data.Dataset):\n",
    "    def __init__(self, M, list_len, num_examples):\n",
    "        \"\"\"\n",
    "        Generate a dataset for the list task by randomly choosing two numbers in the allowed range\n",
    "        and creating the initial/final matrices for adding them.\n",
    "        \n",
    "        :param M: The allowable range of integers (from 0 to M-1)\n",
    "        :param list_len: The list length\n",
    "        :param num_examples: The number of training examples to be generated\n",
    "        \"\"\"\n",
    "        \n",
    "        if list_len > M:\n",
    "            raise ValueError(\"Cannot have a list longer than M\")\n",
    "        \n",
    "        self.input_list = []\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            list_val = random.randint(0, M-1)\n",
    "            initial_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            output_memory = torch.DoubleTensor(M, M).zero_()\n",
    "            # Output mask is length of the list itself\n",
    "            output_mask = torch.DoubleTensor(M, M).zero_()\n",
    "            for i in range(list_len):\n",
    "                initial_memory[i][list_val] = 1\n",
    "                output_memory[i][(list_val + 1 ) % M] = 1\n",
    "                output_mask[i] = torch.ones(M)\n",
    "            for j in range(list_len, M):\n",
    "                initial_memory[j][0] = 1\n",
    "            \n",
    "            self.input_list.append((initial_memory, output_memory, output_mask))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.input_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Get the i^th element of the dataset.\n",
    "        \n",
    "        :param i: The index of the element to be returned.\n",
    "        :return A tuple containing i^th element of the dataset.\n",
    "        \"\"\"\n",
    "        return self.input_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "LR is set to 0.001\n",
      "Epoch Number: 0, Batch Number: 10, Training Loss: 57.5008\n",
      "Time so far is 0m 0s\n",
      "Epoch Number: 0, Batch Number: 20, Training Loss: 55.6127\n",
      "Time so far is 0m 1s\n",
      "Epoch Number: 0, Batch Number: 30, Training Loss: 68.1300\n",
      "Time so far is 0m 1s\n",
      "Epoch Number: 0, Batch Number: 40, Training Loss: 76.7411\n",
      "Time so far is 0m 1s\n",
      "Epoch Number: 0, Batch Number: 50, Training Loss: 69.5903\n",
      "Time so far is 0m 1s\n",
      "Epoch Number: 0, Batch Number: 60, Training Loss: 73.6385\n",
      "Time so far is 0m 2s\n",
      "Epoch Number: 0, Batch Number: 70, Training Loss: 87.3383\n",
      "Time so far is 0m 2s\n",
      "Epoch Number: 0, Batch Number: 80, Training Loss: 94.7380\n",
      "Time so far is 0m 3s\n",
      "Epoch Number: 0, Batch Number: 90, Training Loss: 104.0892\n",
      "Time so far is 0m 3s\n",
      "Epoch Number: 0, Batch Number: 100, Training Loss: 122.4506\n",
      "Time so far is 0m 4s\n",
      "Epoch Number: 0, Batch Number: 110, Training Loss: 193939387845070796090642634094574539597244333017216434388685614401414234112.0000\n",
      "Time so far is 0m 4s\n",
      "Epoch Number: 0, Batch Number: 120, Training Loss: 6122320340795795297377897025836928208994304.0000\n",
      "Time so far is 0m 5s\n",
      "Epoch Number: 0, Batch Number: 130, Training Loss: 11104309055159260.0000\n",
      "Time so far is 0m 5s\n",
      "Epoch Number: 0, Batch Number: 140, Training Loss: 106.7406\n",
      "Time so far is 0m 6s\n",
      "Epoch Number: 0, Batch Number: 150, Training Loss: 98.7197\n",
      "Time so far is 0m 6s\n",
      "Epoch Number: 0, Batch Number: 160, Training Loss: 208985990977030777799247186712669277325170235354311032832.0000\n",
      "Time so far is 0m 7s\n",
      "Epoch Number: 0, Batch Number: 170, Training Loss: 35060352011602589088306996796695589993578496.0000\n",
      "Time so far is 0m 7s\n",
      "Epoch Number: 0, Batch Number: 180, Training Loss: 560524303120394417484741027126804129775616.0000\n",
      "Time so far is 0m 8s\n",
      "Epoch Number: 0, Batch Number: 190, Training Loss: 73.2006\n",
      "Time so far is 0m 8s\n",
      "Epoch Number: 0, Batch Number: 200, Training Loss: 98.1799\n",
      "Time so far is 0m 9s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type double without overflow: inf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-dc9249afd5c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mvalidation_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manc_validation_criterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mforward_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     batch_size = 1) # In the paper, they used batch sizes of 1 or 5\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#     #kangaroo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Schoolwork/NN/neural_nets_research/neural_nets_library/training.py\u001b[0m in \u001b[0;36mtrain_model_anc\u001b[0;34m(model, dset_loader, optimizer, lr_scheduler, num_epochs, print_every, plot_every, deep_copy_desired, validation_criterion, forward_train, batch_size)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_criterion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-5b42afb333db>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, train)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# If we're training, calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-5b42afb333db>\u001b[0m in \u001b[0;36mtimestep_loss\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Confidence Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mmem_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_memory\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mcorrectness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem_diff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfidence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_probability\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_stop_probability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrectness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type double without overflow: inf"
     ]
    }
   ],
   "source": [
    "num_examples = 7200\n",
    "\n",
    "# M = 8 # Don't change this (as long as we're using the add-task)\n",
    "# dataset = AddTaskDataset(M, num_examples)\n",
    "\n",
    "# M = 8 # Don't change this (as long as we're using the add-task)\n",
    "# dataset = TrivialAddTaskDataset(M, num_examples)\n",
    "\n",
    "M = 7 # Don't change this (as long as we're using the add-task)\n",
    "dataset = IncTaskDataset(M, M - 2, num_examples)\n",
    "\n",
    "data_loader = data.DataLoader(dataset, batch_size = 1) # Don't change this batch size.  You have been warned.\n",
    "\n",
    "def anc_validation_criterion(output, label):\n",
    "    target_memory = label[1]\n",
    "    target_mask = label[2]\n",
    "    \n",
    "    output = output.data * target_mask\n",
    "    target_memory = target_memory * target_mask\n",
    "    _, target_indices = torch.max(target_memory, 2)\n",
    "    _, output_indices = torch.max(output, 2)\n",
    "    \n",
    "    return 1 - torch.equal(output_indices, target_indices)\n",
    "\n",
    "# Initialize our controller\n",
    "controller = Controller(first_arg = first_arg, \n",
    "                        second_arg = second_arg, \n",
    "                        output = target, \n",
    "                        instruction = instruction, \n",
    "                        initial_registers = init_registers, \n",
    "                        stop_threshold = .9, \n",
    "                        multiplier = 5,\n",
    "                        correctness_weight = 1, \n",
    "                        halting_weight = 0, \n",
    "                        confidence_weight = .1, \n",
    "                        efficiency_weight = 5, \n",
    "                        t_max = 50) \n",
    "\n",
    "# Learning rate is a tunable hyperparameter\n",
    "# The paper didn't mention which one they used\n",
    "optimizer = optim.Adam(controller.parameters(), lr = 0.1)\n",
    "\n",
    "plot_every = 10\n",
    "\n",
    "best_model, train_plot_losses, validation_plot_losses = training.train_model_anc(\n",
    "    controller, \n",
    "    data_loader,  \n",
    "    optimizer, \n",
    "    num_epochs = 1, \n",
    "    print_every = 10, \n",
    "    plot_every = plot_every, \n",
    "    deep_copy_desired = False, \n",
    "    validation_criterion = anc_validation_criterion, \n",
    "    forward_train = True, \n",
    "    batch_size = 1) # In the paper, they used batch sizes of 1 or 5\n",
    "    \n",
    "#     #kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGaFJREFUeJzt3X+QHOV95/H3Z2Z2tUISSMAiZIQjHDgoSAVBrXW4cFEGysQQxyYVh8KX8+liruRcyBUup2Igqbqy/0jV+So29tVdkchgR5XDCQSbg5DENsePu+N+YK9ACIGss4zFARHS4iBLAvRjd7/3Rz+7mp2d3W1JOzvT3Z9X1dR0P9M9/R3N6rPPPv1LEYGZmRVfrdsFmJnZ/HCgm5mVhAPdzKwkHOhmZiXhQDczKwkHuplZSTjQzcxKwoFuZlYSDnQzs5JoLOTGzjzzzFizZs1CbtLMrPA2b978ZkQMzrVcrkCXtBy4B/glIIBPAzuA+4E1wC7gpoh4a7b3WbNmDcPDw3k2aWZmiaRX8iyXd8jla8B3I+Ii4FJgO3AH8HhEXAA8nubNzKxL5gx0SacBVwH3AkTEkYjYB3wc2JQW2wTc2Kkizcxsbnl66OcBI8A3JT0n6R5JS4CVEbE7LfMGsLJTRZqZ2dzyBHoDuBy4OyIuA96mZXglsmvwtr0Or6QNkoYlDY+MjJxsvWZmNoM8gf4a8FpEPJPmHyQL+D2SVgGk573tVo6IjRExFBFDg4Nz7qQ1M7MTNGegR8QbwKuSLkxN1wIvAY8A61PbeuDhjlRoZma55D0O/d8A90nqB14Gfpvsl8EDkm4BXgFu6kyJZmaWR65Aj4gtwFCbl66d33Lae3z7HnbsOcDvfuj8hdicmVkhFeLU/6d2jPD1//5yt8swM+tphQj0ek2Mjvtm1mZmsylMoI870M3MZlWYQB8LB7qZ2WyKE+juoZuZzaoYgS4HupnZXAoR6LWaGA8ID7uYmc2oEIHeqAnAvXQzs1kUItDrE4HuHrqZ2YwKEeg1ZYE+Pt7lQszMelghAr3hHrqZ2ZwKEei1FOh/PfxqlysxM+tdhQj0epbnfPFvXupuIWZmPawYgV4vRJlmZl1ViKSsp52iZmY2s2IEelOVt37rWTa/8lb3ijEz61G5Al3SLkkvSNoiaTi1fUHS66lti6QbOlVkvXaszL/dupvP/MVwpzZlZlZYeW9BB3B1RLzZ0nZXRPzJfBbUzvQhdA/BmJm1KsSQS61lDN1D6mZm0+UN9AC+L2mzpA1N7b8naaukb0ha0YH6AGjUCvF7x8ysq/Im5Qcj4nLgeuBWSVcBdwO/CKwFdgNfbreipA2ShiUNj4yMnFCRrUMu7qCbmU2XK9Aj4vX0vBd4CFgXEXsiYiwixoGvA+tmWHdjRAxFxNDg4OCJFekxFjOzOc0Z6JKWSFo2MQ1cB2yTtKppsV8HtnWmRGjUPYZuZjaXPEe5rAQeUpaiDeBbEfFdSX8haS3Z+Pou4DOdKtI9dDOzuc0Z6BHxMnBpm/ZPdaSiNiauhz5BHkU3M5umkIePuMNuZjZdIQK99c5zznMzs+kKEuhTE13uopuZTVOIQA/fqcjMbE6FCHTfS9TMbG7FCHT30M3M5lSQQJ867yF0M7PpChHo71k+0O0SzMx6XiEC/ZdXL+eqf3LsOjDuoZuZTVeIQAe4eNWpk9M+U9TMbLrCBHrzJXTdQzczm64wge4LdJmZza6Qge5oNzObrpiB7t66mdk0BQr0bldgZtbbihPoNQ+5mJnNpjiB7mEWM7NZ5bkFHZJ2AQeAMWA0IoYknQ7cD6whuwXdTRHxVmfKbBlycbabmU1zPD30qyNibUQMpfk7gMcj4gLg8TTfMc2Xc3Gem5lNdzJDLh8HNqXpTcCNJ1/OzMaartDlo1zMzKbLG+gBfF/SZkkbUtvKiNidpt8AVrZbUdIGScOShkdGRk640PGmQN+59yBP7dh7wu9lZlZGeQP9gxFxOXA9cKukq5pfjOyWQm0vWh4RGyNiKCKGBgcH2y2Sy1jLNdEfGH71hN/LzKyMcgV6RLyenvcCDwHrgD2SVgGk5452mcdbLoq+/93RTm7OzKxw5gx0SUskLZuYBq4DtgGPAOvTYuuBhztVJEzvoe8/dLSTmzMzK5w8hy2uBB5KOyIbwLci4ruSfgg8IOkW4BXgps6VCWMt9xV998hYJzdnZlY4cwZ6RLwMXNqm/WfAtZ0oqp3W+4r2NwpzTpSZ2YIoTCqOtYyh99ULU7qZ2YIoTCq2BnrrvJlZ1RU20I+2DqqbmVVccQI9jaF/+srzOHNpP0cc6GZmUxQm0CeOQz//rKVcdcEgL4+8zd79h7pclZlZ7yhMoE8MudRrx3aIfuRr/6ObJZmZ9ZTCBPo5KxYDMLhsEX2N7OJc//j2kW6WZGbWU3JdD70X3Hr1+Vy86lSuvvAs/tuOE7/Il5lZWRWmh95Xr3HdJWcjacplADa/8o9drMrMrHcUJtCbNR/C+Bt3/+8uVmJm1jsKH+hmZpYpZKCPtgR6hAPezKyQgd56bfTDoz7JyMyskIE+1tIh97XRzcyKGujjU3vkBw757kVmZoUM9NGx1tvRuYduZpY70CXVJT0n6dE0/+eSfippS3qs7VyZUy3ur0+ZP3jYPXQzs+Ppod8GbG9p+4OIWJseW+axrll94dcumTJ/xDtFzczyBbqk1cCvAvd0tpx8Vizp55L3nDo570A3M8vfQ/8q8HmgNTn/WNJWSXdJWtRuRUkbJA1LGh4Zmb9rsNSym1YD+NroZmbkCHRJHwX2RsTmlpfuBC4C3g+cDtzebv2I2BgRQxExNDg4eLL1TqrVjgW6j0M3M8vXQ78S+JikXcBfAddI+s8RsTsyh4FvAus6WOc0TXnuIRczM3IEekTcGRGrI2INcDPwRET8c0mrACQJuBHY1tFKW9Sbh1wc6GZmJ3U99PskDQICtgC/Mz8l5eMxdDOzqY4r0CPiKeCpNH1NB+rJTR5yMTObopBnigLUax5yMTNrVthAbx5yOTw61sVKzMx6Q3ED3T10M7MpihvozWPo3ilqZlbkQPeJRWZmzUoR6B5yMTMrdKAfm3YP3cyswIHefNjizw4e7mIlZma9obCB3jzk8uz/28c/+/r/6WI1ZmbdV9hAbz5TFOB//eRn3SnEzKxHFDbQm4dcJoyPR5slzcyqobCBPjHkcvapA5NtPh7dzKqs8IG+esXiyTYHuplVWYEDPXueEug+fNHMKqzAgZ4l+rKBvsm2o+6hm1mFFTfQUxe9Jvjyb14KuIduZtWWO9Al1SU9J+nRNH+epGck7ZR0v6T+zpU53cSQiyT6G9nHcKCbWZUdTw/9NmB70/yXgLsi4nzgLeCW+SxsLvXJHvqxQPclAMysynIFuqTVwK8C96R5AdcAD6ZFNpHdKHrBTIyh18RkoHsM3cyqLG8P/avA54GJxDwD2BcRo2n+NeCcditK2iBpWNLwyMjISRU79X2z53pNLKp7yMXMbM5Al/RRYG9EbD6RDUTExogYioihwcHBE3mLtuop0aeMobuHbmYV1sixzJXAxyTdAAwApwJfA5ZLaqRe+mrg9c6VOV3zUS597qGbmc3dQ4+IOyNidUSsAW4GnoiI3wKeBD6RFlsPPNyxKts4Nobuo1zMzODkjkO/HficpJ1kY+r3zk9J+Uwctti8U9RDLmZWZXmGXCZFxFPAU2n6ZWDd/JeUz8RO0VpN9Nd92KKZWWHPFBWafF6yKPu99O6RsW6WZGbWVYUN9IG+iWGWMZYsqgNw8PDobKuYmZVaYQP9lP6sV/724TEWNer012scOORAN7PqKnCgZ73yd45kIb50oMHb7qGbWYUVN9DTuPk7adx86aKGh1zMrNKKG+h9Ez30Y4HuIRczq7LiBnraEToxzLJ0oMHBw0e7WZKZWVcVNtCX9HvIxcysWWEDfdXyAQCueN/pQAp0D7mYWYUd15miveSsZQM8ffvVnH1qFuzZkIsD3cyqq7CBDrB6xSmT08u8U9TMKq6wQy6tli5qcHh03HctMrPKKk2gT1zPxScXmVlVlSbQlw5kge5hFzOrqtIE+rLUQ99/yMeim1k1lSbQVy1fDMDfvbC7y5WYmXVHnptED0j6gaTnJb0o6Yup/c8l/VTSlvRY2/lyZ3bp6tN4z2kD7HrznW6WYWbWNXkOWzwMXBMRByX1AU9L+vv02h9ExIOdKy8/SSwb6GN03Ee5mFk1zRnoERHAwTTblx7RyaJOVL0mfNSimVVVrjF0SXVJW4C9wGMR8Ux66Y8lbZV0l6RFM6y7QdKwpOGRkZF5Kru9LNCd6GZWTbkCPSLGImItsBpYJ+mXgDuBi4D3A6cDt8+w7saIGIqIocHBwXkqu716TYz15N8OZmadd1xHuUTEPuBJ4CMRsTsyh4FvAus6UeDxcA/dzKosz1Eug5KWp+nFwIeBH0laldoE3Ahs62SheWSB7i66mVVTnqNcVgGbJNXJfgE8EBGPSnpC0iAgYAvwOx2sM5e65KNczKyy8hzlshW4rE37NR2p6CQ06uLQqHvoZlZNpTlTFLIhl3EPuZhZRZUr0CVGHehmVlHlCnTvFDWzCnOgm5mVRPkCPRzoZlZN5Qt099DNrKIc6GZmJVGuQJcD3cyqq1SB3qg70M2sukoV6DX30M2swkoV6I2aTywys+oqVaDXfOq/mVVYqQLdPXQzq7JSBXq9VvOJRWZWWSULdLxT1Mwqq2SBXmNsPAj30s2sgvLcgm5A0g8kPS/pRUlfTO3nSXpG0k5J90vq73y5s6tLALiTbmZVlKeHfhi4JiIuBdYCH5F0BfAl4K6IOB94C7ilc2Xm06hnge5hFzOrojkDPTIH02xfegRwDfBgat9EdqPorqrJgW5m1ZVrDF1SXdIWYC/wGPATYF9EjKZFXgPO6UyJ+TVqKdA9hm5mFZQr0CNiLCLWAquBdcBFeTcgaYOkYUnDIyMjJ1hmPrWJQB9zoJtZ9RzXUS4RsQ94EvgAsFxSI720Gnh9hnU2RsRQRAwNDg6eVLFzWdxXB+DgkdE5ljQzK588R7kMSlqephcDHwa2kwX7J9Ji64GHO1VkXmvOOAWAV958u8uVmJktvDw99FXAk5K2Aj8EHouIR4Hbgc9J2gmcAdzbuTLzOW9wCQAvO9DNrIIacy0QEVuBy9q0v0w2nt4zzj51AIC9Bw53uRIzs4VXqjNFJdFXF6Nj490uxcxswZUq0MH3FTWz6ipdoPfVar6ErplVUukCve4hFzOrqNIFum9yYWZVVcJAr3kM3cwqqXSBXq+Joz7138wqqHSB3qiLsXGPoZtZ9ZQv0GviqIdczKyCShjoNV9t0cwqqXSBXvdRLmZWUaUL9L66GPUYuplVUOkC3af+m1lVlS7QG7UaR32mqJlVUPkCve4euplVU+kC3TtFzayq8tyC7lxJT0p6SdKLkm5L7V+Q9LqkLelxQ+fLnVtfvcaoD1s0swqa845FwCjw+xHxrKRlwGZJj6XX7oqIP+lcecfPPXQzq6o8t6DbDexO0wckbQfO6XRhJ6pR8+VzzayajmsMXdIasvuLPpOafk/SVknfkLRinms7IY26r7ZoZtWUO9AlLQW+DXw2IvYDdwO/CKwl68F/eYb1NkgaljQ8MjIyDyXPztdDN7OqyhXokvrIwvy+iPgOQETsiYixiBgHvg6sa7duRGyMiKGIGBocHJyvumdU95CLmVVUnqNcBNwLbI+IrzS1r2pa7NeBbfNf3vHLTv13D93MqifPUS5XAp8CXpC0JbX9IfBJSWuBAHYBn+lIhcfJR7mYWVXlOcrlaUBtXvq7+S/n5PXVaxwZ9ZCLmVVP6c4UXdxX59DRsW6XYWa24EoX6AN9dUbHwztGzaxyShjo2Uc65GEXM6uYEgZ6HYB3j3jYxcyqpbSB7nF0M6ua0gb64VEHuplVS/kCvZHG0I96DN3MqqV8gT4xhu4hFzOrmNIF+uJ+j6GbWTWVLtAHGhOB7iEXM6uW8gV6Og7dQy5mVjWlC/RTF/cBsP/do12uxMxsYZUu0E9Lgf5zB7qZVUzpAn2gr86iRs2BbmaVU7pAB1h+Sh/73jnS7TLMzBZUOQN9cT/73nEP3cyqJc8t6M6V9KSklyS9KOm21H66pMck/Tg9r+h8ufmcdkqfA93MKidPD30U+P2IuBi4ArhV0sXAHcDjEXEB8Hia7wkrTx3gjf2Hul2GmdmCmjPQI2J3RDybpg8A24FzgI8Dm9Jim4AbO1Xk8Vq9YjH/sO9dxnxvUTOrkOMaQ5e0BrgMeAZYGRG700tvACvntbKTsHrFYkbHg9fferfbpZiZLZg5bxI9QdJS4NvAZyNiv3TsvtEREZLadoclbQA2ALz3ve89uWpzWnvucmqCX/uPT3Ppucs5a9kili5qsGwgeyzubzDQqLG4v85Ao85AX52Bvlp6njrdVxd9tRq1Wrv7ZHdfRKRniNa21J5Nx+Q0Le3t1o/m5Y5j2Ti28Kw1REvt7epqu+yU5drV01Jnzs8/te3YZ2uen1przLBO87Ltap7+bzTbMq3v37au2T7LfH+mGZeZ/t9/xs/S9nMfx2ea4/2nvE/rC8z02ad/jtZPNG3Zaa/PPiLwK5eczbmnnzLrMicrV6BL6iML8/si4jupeY+kVRGxW9IqYG+7dSNiI7ARYGhoaEHGQC55z2l841++n4e3/AM/euMAO/cc4MDhUQ4eHp32peRVEzTqNfpqolGvUa+pfXA2/2DOEEizhSmtgTTR3GZ9MyuO889a2v1AV9YVvxfYHhFfaXrpEWA98O/S88MdqfAEfejCs/jQhWdNaRsfD94+Msq7R8Y4dHScQ6NjHDqaTb97dGJ6jMNNrx0dC46OjTM6Fhwdz55Hx8YZi0CIiT9UBDT/1QIggVDTdFN7WnZyjdmWbWqfXKdp/WPtU+tp3RZ5lm3ZFulzadr6TZ9BzZ+j3bKt/07H2plWg1pqn/4eM9U1078fbdun19lac3NhzZtu/e5a15nyfi0Tbb/L1vdt8720Lj19mZafpznqml5ny7ZzfKbWumb9TDPUNFtdx/OZ2vwTzb6NNjW2f611vVneaI7tLE6X9u6kPD30K4FPAS9I2pLa/pAsyB+QdAvwCnBTZ0qcP7WaWDbQx7KBvm6XYmY27+YM9Ih4mmm/hyZdO7/lmJnZiSrlmaJmZlXkQDczKwkHuplZSTjQzcxKwoFuZlYSDnQzs5JwoJuZlYTmuv7AvG5MGiE7CelEnAm8OY/ldEpR6oTi1Oo6519RanWdmV+IiMG5FlrQQD8ZkoYjYqjbdcylKHVCcWp1nfOvKLW6zuPjIRczs5JwoJuZlUSRAn1jtwvIqSh1QnFqdZ3zryi1us7jUJgxdDMzm12ReuhmZjaLQgS6pI9I2iFpp6Q7urD9b0jaK2lbU9vpkh6T9OP0vCK1S9J/SLVulXR50zrr0/I/lrS+A3WeK+lJSS9JelHSbb1Yq6QBST+Q9Hyq84up/TxJz6R67pfUn9oXpfmd6fU1Te91Z2rfIelX5rPOpm3UJT0n6dEer3OXpBckbZE0nNp66rtP779c0oOSfiRpu6QP9GidF6Z/y4nHfkmf7cVaJ0VETz+AOvAT4H1AP/A8cPEC13AVcDmwrant3wN3pOk7gC+l6RuAvye7hvwVwDOp/XTg5fS8Ik2vmOc6VwGXp+llwP8FLu61WtP2lqbpPrKbjl8BPADcnNr/FPjXafp3gT9N0zcD96fpi9PPwyLgvPRzUu/A9/854FvAo2m+V+vcBZzZ0tZT333axibgX6XpfmB5L9bZUnMdeAP4hV6utSMffp7/IT8AfK9p/k7gzi7UsYapgb4DWJWmVwE70vSfAZ9sXQ74JPBnTe1TlutQzQ8DH+7lWoFTgGeBf0p2Ykaj9XsHvgd8IE030nJq/VloXm4e61sNPA5cAzyatttzdab33cX0QO+p7x44Dfgpaf9dr9bZpu7rgP/Z67UWYcjlHODVpvnXUlu3rYyI3Wn6DWBlmp6p3gX9HOnP/cvIer89V2saxthCdnPxx8h6rfsiYrTNNifrSa//HDhjIeoEvgp8HhhP82f0aJ2Q3UP8+5I2S9qQ2nrtuz8PGAG+mYax7pG0pAfrbHUz8JdpumdrLUKg97zIfu32zOFCkpYC3wY+GxH7m1/rlVojYiwi1pL1gNcBF3W5pGkkfRTYGxGbu11LTh+MiMuB64FbJV3V/GKPfPcNsuHLuyPiMuBtsmGLST1S56S0j+RjwF+3vtZrtRYh0F8Hzm2aX53aum2PpFUA6Xlvap+p3gX5HJL6yML8voj4Ti/XChAR+4AnyYYulkuauM9t8zYn60mvnwb8bAHqvBL4mKRdwF+RDbt8rQfrBCAiXk/Pe4GHyH5R9tp3/xrwWkQ8k+YfJAv4Xquz2fXAsxGxJ833bK1FCPQfAhekIwv6yf70eaTLNUFWw8Te6vVk49UT7f8i7fG+Avh5+vPse8B1klakveLXpbZ5I0nAvcD2iPhKr9YqaVDS8jS9mGycfztZsH9ihjon6v8E8ETqGT0C3JyOLjkPuAD4wXzVGRF3RsTqiFhD9nP3RET8Vq/VCSBpiaRlE9Nk39k2euy7j4g3gFclXZiargVe6rU6W3ySY8MtEzX1Zq2d2okwzzskbiA7YuMnwB91Yft/CewGjpL1MG4hGxt9HPgx8F+B09OyAv5TqvUFYKjpfT4N7EyP3+5AnR8k+/NvK7AlPW7otVqBXwaeS3VuA/5tan8fWdDtJPvzdlFqH0jzO9Pr72t6rz9K9e8Aru/gz8CHOHaUS8/VmWp6Pj1enPh/0mvffXr/tcBw+v7/C9mRHz1XZ9rGErK/sk5rauvJWiPCZ4qamZVFEYZczMwsBwe6mVlJONDNzErCgW5mVhIOdDOzknCgm5mVhAPdzKwkHOhmZiXx/wFPstA8zeZxxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113beb7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x * plot_every for x in range(len(train_plot_losses))], train_plot_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116357828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x * plot_every for x in range(len(validation_plot_losses))], validation_plot_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 = 6\n",
      "R2 = 2\n",
      "R3 = 0\n",
      "R4 = 1\n",
      "R5 = None\n",
      "R6 = 0\n",
      "\n",
      "R5 = READ(R5, R6)\n",
      "R4 = READ(R4, R6)\n",
      "R6 = JEZ(R4, R1)\n",
      "R4 = DEC(R4, R6)\n",
      "R5 = INC(R5, R6)\n",
      "R6 = JEZ(R3, R2)\n",
      "R6 = WRITE(R3, R5)\n",
      "R6 = STOP(R6, R6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(controller.first_arg)\n",
    "# print(controller.second_arg)\n",
    "# print(controller.output)\n",
    "# print(controller.instruction)\n",
    "# print(controller.registers)\n",
    "\n",
    "cutoff = 0.7\n",
    "\n",
    "def getBest(vec):\n",
    "    maxVal, index = torch.max(vec, 0)\n",
    "    if maxVal.data[0] > cutoff:\n",
    "        return index.data[0]\n",
    "\n",
    "def bestRegister(vec):\n",
    "    index = getBest(vec)\n",
    "    if index is not None:\n",
    "        return \"R\" + str(1 + index)\n",
    "    return \"??\"\n",
    "    \n",
    "def bestInstruction(vec):\n",
    "    ops = [ \n",
    "        \"STOP\",\n",
    "        \"ZERO\",\n",
    "        \"INC\",\n",
    "        \"ADD\",\n",
    "        \"SUB\",\n",
    "        \"DEC\",\n",
    "        \"MIN\",\n",
    "        \"MAX\",\n",
    "        \"READ\",\n",
    "        \"WRITE\",\n",
    "        \"JEZ\"\n",
    "    ]\n",
    "    index = getBest(vec)\n",
    "    if index is not None:\n",
    "        return ops[index]\n",
    "    return \"??\"\n",
    "    \n",
    "# registers = controller.registers\n",
    "orig_register = [6,2,0,1,0,0]\n",
    "orig_output = [4,3,5,3,4,5,5,5]\n",
    "orig_instruction = [8,8,10,5,2,10,9,0]\n",
    "orig_first = [4,3,3,3,4,2,2,5]\n",
    "orig_second = [5,5,0,5,5,1,4,5]\n",
    "# print(controller.output)\n",
    "# print(controller.first_arg)\n",
    "# output = controller.output\n",
    "# first = controller.first_arg\n",
    "# second = controller.second_arg\n",
    "instruction = controller.instruction\n",
    "_, R, M = controller.registers.size()\n",
    "    \n",
    "def printProgram():   \n",
    "    # Print registers\n",
    "    for i in range(R):\n",
    "        print(\"R\" + str(i + 1) + \" = \" + str(getBest(controller.registers[0, i,:])))\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Print the actual program\n",
    "    for i in range (M):\n",
    "        print(bestRegister(controller.output[0, :, i]) + \" = \" + \n",
    "              bestInstruction(controller.instruction[0, :, i]) + \"(\" +\n",
    "              bestRegister(controller.first_arg[0, :, i]) + \", \" +\n",
    "              bestRegister(controller.second_arg[0, :, i]) + \")\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def compareOutput():\n",
    "    # compare our output to theirs\n",
    "    # we get one point for every matching number\n",
    "    match_count = 0\n",
    "    softmax = nn.Softmax(1)\n",
    "    for i in range(R):\n",
    "        if getBest(controller.registers[0, i,:]) == orig_register[i]:\n",
    "            match_count += 1\n",
    "    for i in range (M):\n",
    "        if getBest(softmax(controller.output)[0, :, i]) == orig_output[i]:\n",
    "            match_count += 1\n",
    "        if getBest(softmax(controller.instruction)[0, :, i]) == orig_instruction[i]:\n",
    "            match_count += 1\n",
    "        if getBest(softmax(controller.first_arg)[0, :, i]) == orig_first[i]:\n",
    "            match_count += 1\n",
    "        if getBest(softmax(controller.second_arg)[0, :, i]) == orig_second[i]:\n",
    "            match_count += 1\n",
    "\n",
    "    percent_orig = match_count / (len(orig_register) + len(orig_output) + \n",
    "                                           len(orig_instruction) + len(orig_first) + len(orig_second))\n",
    "    return percent_orig\n",
    "    print(\"PERCENT MATCH\", percent_orig)\n",
    "    \n",
    "printProgram()\n",
    "compareOutput()\n",
    "\n",
    "# Original Add Program   \n",
    "# R1 = 6\n",
    "# R2 = 2\n",
    "# R3 = 0\n",
    "# R4 = 1\n",
    "# R5 = 0\n",
    "# R6 = 0\n",
    "\n",
    "\n",
    "# R5 = READ(R5, R6)\n",
    "# R4 = READ(R4, R6)\n",
    "# R6 = JEZ(R4, R1)\n",
    "# R4 = DEC(R4, R6)\n",
    "# R5 = INC(R5, R6)\n",
    "# R6 = JEZ(R3, R2)\n",
    "# R6 = WRITE(R3, R5)\n",
    "# R6 = STOP(R6, R6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  0\n",
      "Epoch 0/0\n",
      "----------\n",
      "LR is set to 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-34ee204a75ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mvalidation_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manc_validation_criterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mforward_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         batch_size = 5) # In the paper, they used batch sizes of 1 or 5\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpercent_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompareOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpercent_orig\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Schoolwork/NN/neural_nets_research/neural_nets_library/training.py\u001b[0m in \u001b[0;36mtrain_model_anc\u001b[0;34m(model, dset_loader, optimizer, lr_scheduler, num_epochs, print_every, plot_every, deep_copy_desired, validation_criterion, forward_train, batch_size)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_criterion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-5b42afb333db>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, train)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# Update memory, registers, and IR after machine operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_stop_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_stop_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_probability\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_stop_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8583370fe4e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, e, a, b, o, memory, registers, IR)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mregisters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteRegisters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateIR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mstop_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetStop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8583370fe4e4>\u001b[0m in \u001b[0;36mupdateIR\u001b[0;34m(self, e, IR, arg1, arg2)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Take a weighted sum of the instruction register with and without jumping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIR_no_jump\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mjump_probability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mIR_jump\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjump_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test a bunch of times\n",
    "num_trials = 20\n",
    "\n",
    "num_original_convergences = 0\n",
    "num_0_losses = 0\n",
    "num_better_convergences = 0\n",
    "for i in range(num_trials):\n",
    "    print(\"Trial \", i)\n",
    "    best_model, train_plot_losses, validation_plot_losses = training.train_model_anc(\n",
    "        controller, \n",
    "        data_loader,  \n",
    "        optimizer, \n",
    "        num_epochs = 1, \n",
    "        print_every = 10000, \n",
    "        plot_every = plot_every, \n",
    "        deep_copy_desired = False, \n",
    "        validation_criterion = anc_validation_criterion, \n",
    "        forward_train = True, \n",
    "        batch_size = 5) # In the paper, they used batch sizes of 1 or 5\n",
    "    percent_orig = compareOutput()\n",
    "    if percent_orig > .99:\n",
    "        num_original_convergences += 1\n",
    "    end_losses = validation_plot_losses[-2:]\n",
    "    if sum(end_losses) < .01:\n",
    "        num_0_losses += 1\n",
    "    if percent_orig < .99 and sum(end_losses) < .01:\n",
    "        num_\n",
    "print(\"LOSS CONVERGENCES\", num_0_losses * 1.0 / num_trials)\n",
    "print(\"ORIG CONVERGENCES\", num_original_convergences * 1.0 / num_trials)\n",
    "print(\"BETTER CONVERGENCES\", num_better_convergences * 1.0 / num_trials)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(1)\n",
    "print(softmax(controller.instruction))\n",
    "print(controller.memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
