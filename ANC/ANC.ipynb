{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8133dba17c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mInsert\u001b[0m \u001b[0menlightening\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Insert enlightening comment here.\n",
    "    \"\"\"\n",
    "    def __init(self, program_matrix, initial_memory, initial_registers, instruction_register):\n",
    "        \"\"\"\n",
    "        Setup, etc. etc.\n",
    "        TODO: Check what dimensions program_matrix would be, say that here\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        R, M = initial_registers.size()\n",
    "        self.M = M\n",
    "        self.R = R\n",
    "        \n",
    "        # TODO: INSERT DIMENSIONS\n",
    "        self.program_matrix = program_matrix\n",
    "        # TODO: What's the difference between Variable and Parameter again?\n",
    "        \n",
    "        # Memory matrix (M x M)\n",
    "        self.memory = initial_memory\n",
    "        \n",
    "        # Register Matrix (R x M)\n",
    "        self.registers = initial_registers\n",
    "        \n",
    "        # Instruction Register (M)\n",
    "        self.IR = instruction_register\n",
    "        \n",
    "        #TODO: Add in some fuzz factor????\n",
    "         \n",
    "    def forward(self):\n",
    "        print(\"HI\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# HOW TO BLUR? ==> Add a constant, then softmax\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(nn.Module):\n",
    "    \"\"\"\n",
    "    Insert exquisitely eloquent comment here.\n",
    "    \"\"\"\n",
    "    def __init__(self, M, R, stop_threshold):\n",
    "        \"\"\"\n",
    "        Maybe stuff here?  I'm not actually sure what needs to be set up.\n",
    "        \"\"\"\n",
    "        super(Machine, self).__init__()\n",
    "        self.R = R\n",
    "        self.M = M # Memory length (also largest number)\n",
    "        self.N = 3 # Number of instructions\n",
    "        self.ops = [Jump(M), Stop(M), Add(M)]\n",
    "        self.jump_index = 0 # TODO: Switch this later\n",
    "        self.stop_index = 1 # TODO: Switch this later\n",
    "        self.stop_threshold = stop_threshold\n",
    "        self.stop_probability = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, e, a, b, o, memory, registers, IR):\n",
    "        \"\"\"\n",
    "        At this point, Mudd CS profs would probably be freaking out about bad variable names.\n",
    "        But e,a,b,o are what the paper used, so yeah.\n",
    "        a,b,o = Rx1\n",
    "        e = Nx1 => N = # instructions\n",
    "        \"\"\"\n",
    "        \n",
    "        arg1 = torch.matmul(a, registers)\n",
    "        arg2 = torch.matmul(b, registers)\n",
    "        \n",
    "        # Would be kinda nice to not have to for-loop this\n",
    "        # Or maybe do this once\n",
    "        # CUUUUUDAAAA\n",
    "        out = Variable(torch.zeros(self.N, self.M))\n",
    "        for k in range(self.N):\n",
    "            for i in range(self.M):\n",
    "                for j in range(self.M):\n",
    "                    val = self.ops[k](i,j)\n",
    "                    out[k, val] = out[k, val] + arg1[i] * arg2[j]\n",
    "            \n",
    "        out_vec = torch.matmul(e, out)\n",
    "        registers = self.write(out_vec, o, registers)\n",
    "        IR = self.updateIR(e, IR, arg1, arg2)\n",
    "        should_stop = self.updateStop(e)\n",
    "        \n",
    "        return(memory, registers, IR)\n",
    "        \n",
    "        \n",
    "    def write(self, out, o, registers):\n",
    "        \n",
    "        ugh = 1-o\n",
    "        ugh = torch.unsqueeze((1-o),1)\n",
    "        ugh = ugh.expand(self.R, self.M)\n",
    "        ugh = ugh * registers\n",
    "        registers = torch.matmul(torch.unsqueeze(o,1), torch.unsqueeze(out,0)) + ugh\n",
    "        return registers\n",
    "    \n",
    "    def updateIR(self, e, IR, arg1, arg2):\n",
    "        # IR - length M vector\n",
    "        jump_probability = e[self.jump_index]\n",
    "        is_zero = arg1[0]\n",
    "        # If we're not jumping, just shift IR by one slot\n",
    "        IR_no_jump = torch.cat([IR[-1], IR[:-1]])\n",
    "        # If we are on a jump instruction, check whether the argument's 0.\n",
    "        # If it is, jump to the location specified by arg2.  Otherwise, increment like normal.\n",
    "        IR_jump = arg2 * is_zero + (1 - is_zero) * IR_no_jump\n",
    "        \n",
    "        IR = IR_no_jump * (1 - jump_probability) + IR_jump * jump_probability\n",
    "        return IR\n",
    "        \n",
    "    def updateStop(self, e):\n",
    "        self.stop_probability += e[self.stop_index].data[0]\n",
    "        print(\"PROB\", self.stop_probability)\n",
    "        if self.stop_probability > self.stop_threshold:\n",
    "            return True #should stop\n",
    "        return False #shouldn't stop\n",
    "    \n",
    "    \n",
    "    \n",
    "    #TODO: Add write operation!\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(nn.Module):\n",
    "    \"\"\"\n",
    "    COOOOOOOMMMMMMMENNNNNT.  This is what happens when I code at 2 a.m.\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Do the things that neeeeeeeed to work.\n",
    "        \"\"\"\n",
    "        super(Operation, self).__init__()\n",
    "        self.M = M\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "#     def makeOneHotVec(self, num):\n",
    "#         new_vec = nn.Variable(torch.zeros(self.M))\n",
    "#         new_vec[num] = 1\n",
    "#         return new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "    \"\"\"\n",
    "    x+y\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        super(Add, self).__init__(M)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return (x + y) % self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stop(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Stop, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jump(Operation):\n",
    "    \n",
    "    def __init__(self, M):\n",
    "        super(Jump, self).__init__(M)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROB 0.30000001192092896\n",
      "MEM Variable containing:\n",
      " 1  0  0  0\n",
      " 1  1  0  0\n",
      " 1  0  1  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "REGS Variable containing:\n",
      " 0.5742  0.2465  0.0633  0.1160\n",
      " 0.3962  0.0310  0.4022  0.1707\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "IR Variable containing:\n",
      " 0.1172\n",
      " 0.1198\n",
      " 0.8485\n",
      " 0.1013\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine = Machine(4, 2, .5)\n",
    "e = Variable(torch.FloatTensor([.3,.3,.4]))\n",
    "a = Variable(torch.FloatTensor([.1, .9]))\n",
    "b = Variable(torch.FloatTensor([.8, .2]))\n",
    "o = Variable(torch.FloatTensor([.6, .4]))\n",
    "memory = Variable(torch.FloatTensor([[1,0,0,0], [1,1,0,0], [1,0,1,0]]))\n",
    "registers = Variable(torch.FloatTensor([[.4, .5, 0, .1], [.2, 0, .6, .2]]))\n",
    "IR = Variable(torch.FloatTensor([.1, .9, .1, .1]))\n",
    "mem, regs, ir = machine(e, a, b, o, memory, registers, IR)\n",
    "print(\"MEM\", mem)\n",
    "print(\"REGS\", regs)\n",
    "print(\"IR\", ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASKS\n",
    "# - Compilation\n",
    "# - Rest of the operations\n",
    "# - Train function\n",
    "# - Controller\n",
    "# - Cuda\n",
    "# - Blurring\n",
    "# - Running the tests they ran, verifying that we get similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PUT THE TRAINING FUNCTION HERE.  COPY AND PASTE A BUNCHA STUFF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
